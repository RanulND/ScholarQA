{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from Scripts.prompt import get_prompt_template\n",
    "from Scripts.chatbot_utils import load_llm,load_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = load_llm()\n",
    "retriever = load_retriever()\n",
    "prompt,memory = get_prompt_template()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ques = \"Who is Rahul Venkatesh?\"\n",
    "candidate_1 = \"Software engineer Rahul Venkatesh is our highlight today. The Kanchana 1.0 invented by him was on a song\"\n",
    "candidate_2 = \"Sanjana Rao married Rahul Venkatesh back in 2023. He is a good father\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []\n",
    "formatted_prompt = prompt.format(candidate_1=candidate_1, candidate_2=candidate_2,history=chat_history,question=ques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_chain = RetrievalQA.from_chain_type(llm,\n",
    "                                              retriever=retriever,\n",
    "                                              chain_type=\"stuff\",\n",
    "                                              chain_type_kwargs={\n",
    "                                                  \"prompt\": formatted_prompt,\n",
    "                                                  \"memory\": memory\n",
    "                                              },\n",
    "                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the mathematical formulation of Naive Bayes\"\n",
    "retrieval_chain.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'  Based on the information provided in the context and question, I can summarize the capabilities of large language models as follows:\\n1. Elimination of need for end-to-end fine-tuning: Large language models can eliminate the need for specializing large language models using end-to-end fine-tuning, which can significantly reduce costs.\\n2. Improved performance compared to existing automated program separation techniques: Directly applying state-of-the-art large language models can already substantially outperform all existing automated program separation techniques on all datasets studied.\\n3. Capability to generate code from natural language specifications: Large pre-trained language models such as GPT-3, Codex, and Coogle Language Model are now capable of generating code from natural language specifications of programmer intent.\\n4. Potential to improve productivity: Large language models have the potential to improve productivity by providing an automated artificial intelligence pair programmer for every programmer in the world.\\n5. Boosting capabilities: Large language model-based automated program separation can be further substantially boosted by increasing the sample size and incorporating fix template information.\\nOverall, large language models have shown remarkable capabilities in generating code and automating program separation tasks, which can significantly improve productivity and reduce costs in software development. However, it is important to approach these developments with caution and consider potential limitations and challenges in implementing these models in real-world scenarios.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{"Title": "Deep-Reinforcement-Learning-Based Distributed Computation Offloading in Vehicular Edge Computing Networks", "Doi": "10.1109/JIOT.2023.3247013", "Authors": ["l. geng", "h. zhao", "j. wang", "a. kaushik", "s. yuan", "w. feng"], "Key Words": ["computation offloading", "deep reinforcement learning (drl)", "mobile-edge computing (mec)", "vehicular edge computing networks (vecns)"], "Abstract": "vehicular edge computing has emerged as a promising paradigm by offloading computation intensive latency sensitive tasks to mobile edge computing  mec  servers. however it is difficult to provide users with excellent quality of service  qos  by relying only on these server resources. therefore in this article we propose to formulate the computation offloading policy based on deep reinforcement learning  drl  in a vehicle assisted vehicular edge computing network  vaen  where idle resources of vehicles are deemed as edge resources. specifically each task is represented by a directed acyclic graph  dag  and offloaded to edge nodes according to our proposed subtask scheduling priority algorithm. further we formalize the computation offloading problem under the constraints of candidate service vehicle models which aims to minimize the long term system cost including delay and energy consumption. to this end we propose a distributed computation offloading algorithm based on multiagent drl  dcom  where an improved actor\u201a\u00e4\u00eccritic network  iacn  is devised to extract features and a joint mechanism of prioritized experience replay and adaptive  $n$  step learning  jmpa  is proposed to enhance learning efficiency. the numerical simulations demonstrate that in vaen scenario dcom achieves significant decrements in the latency and energy consumption compared with other advanced benchmark algorithms.", "Pub Date": "2023-07-06"}
{"Title": "Large Language Models in AWS", "Doi": "10.1109/RESTCON60981.2024.10463557", "Authors": ["r. k. kodali", "y. prasad upreti", "l. boppana"], "Key Words": ["amazon web services", "large language model", "transformers"], "Abstract": "large language models  large language model  have become a transformative milestone in natural language processing. the deployment of large language model on cloud platforms like amazon web services  aws  plays a pivotal role in making their capabilities accessible to a wider audience contributing to the democratization of advanced language processing technology. this paper reviews the evolution of cloud application architectures focusing on transferring cloud applications across various infrastructures offering insight for cloud engineers and architects. throughout this paper we dive into the intricacies of deploying llama 2 on various aws instance types each tailored to specific use cases and computational requirements. the analysis highlighted trade offs between factors such as computational speed cost efficiency and resource utilization all of which play a crucial role when working with the large language model model. additionally we compared instance performance emphasizing the role of max batch prefill tokens in enhancing response generation efficiency. the results provide a clear understanding of the impact of instance type selection on the model\u201a\u00e4\u00f4s performance allowing informed decisions to be made based on specific language processing requirements.", "Pub Date": "2024-03-19"}
{"Title": "Energy-Efficient Task Transfer in Wireless Computing Power Networks", "Doi": "10.1109/JIOT.2022.3223690", "Authors": ["y. lu", "b. ai", "z. zhong", "y. zhang"], "Key Words": ["digital twin", "energy efficiency", "multiagent deep reinforcement learning (drl)", "wireless computing power networks (wcpns)"], "Abstract": "the sixth generation  6g  wireless communication aims to enable ubiquitous intelligent connectivity in future space\u201a\u00e4\u00ecair\u201a\u00e4\u00ecground\u201a\u00e4\u00ecocean integrated networks with extremely low latency and enhanced global coverage. however the explosive growth in internet of things devices poses new challenges for smart devices to process the generated tremendous data with limited resources. in 6g networks conventional mobile edge computing  mec  systems encounter serious problems to satisfy the requirements of ubiquitous computing and intelligence with extremely high mobility resource limitation and time variability. in this article we propose the model of wireless computing power networks  wcpns  by jointly unifying the computing resources from both end devices and mec servers. furthermore we formulate the new problem of task transfer to optimize the allocation of computation and communication resources in wcpn. the main objective of task transfer is to minimize the execution latency and energy consumption with respect to resource limitations and task requirements. to solve the formulated problem we propose a multiagent deep reinforcement learning  drl  algorithm to find the optimal task transfer and resource allocation strategies. the drl agents collaborate with others to train a global strategy model through the proposed asynchronous federated aggregation scheme. numerical results show that the proposed scheme can improve computation efficiency speed up convergence rate and enhance utility performance.", "Pub Date": "2023-05-17"}
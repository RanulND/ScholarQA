{"Title": "Unleashing the Second Brain: Enhancing Large Language Models through Chain of Thought with Human Feedback", "Doi": "10.1109/ISCID59865.2023.00029", "Authors": ["j. yu", "m. luo", "h. zhou", "z. lan"], "Key Words": ["chain-of-thought", "prompting", "large language model", "human-ai-interaction"], "Abstract": "the expansion of large language models has led to improved performance and efficiency with prompt engineering emerging as a key strategy for various large language model tasks. however while these methods have proven beneficial they are not without their constraints particularly when it comes to sustaining a comprehensive logical flow of ideas throughout the entire reasoning process. despite the effectiveness of the chain of thought  cot  and tree of thought  tot  methods they have limitations due to their end to end reasoning process. to address this we introduce the chain of thought with human feedback. this new method incorporates human feedback into the model\u201a\u00e4\u00f4s reasoning process allowing for real time adjustments and optimization. this approach fosters a more interactive and dynamic model operation enabling the model to learn from human intuition and expertise and improve its reasoning process over time. we have validated the effectiveness of our method through experiments in gsm8k and mmlu. our main contributions include proposing the first human feedback to the chain of thought and the development of an intuitive interface for individuals to utilize large scale models for problem solving.", "Pub Date": "2024-04-15"}
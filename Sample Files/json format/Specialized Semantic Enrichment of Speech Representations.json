{"Title": "Specialized Semantic Enrichment of Speech Representations", "Doi": "10.1109/ICASSPW59220.2023.10193452", "Authors": ["g. laperri\u221a\u00aere", "h. nguyen", "s. ghannay", "b. jabaian", "y. est\u221a\u00aeve"], "Key Words": ["spoken language understanding", "deep learning", "self-supervised model", "cross-lingual semantic speech representations"], "Abstract": "ssl is now commonly used to capture multilingual speech representation by exploiting huge audio speech data in several languages. in parallel some text based large neural models trained on huge multilingual textual documents have been introduced in order to capture the general semantics of a sentence independently of the language and to represent it under the form of a sentence embedding. very recently an approach has been introduced that takes benefit of such sentence embedding in order to continue the training of an ssl speech model in order to inject some multilingual semantic information. in a previous work we made a layer wise analysis in order to better understand how this semantic information is integrated into a wav2vec2.0 model. in this new study we show how this semantic information can be specialized to a targeted downstream task dedicated to a task oriented spoken language understanding by exploiting a small amount of transcribed data. we also show that the use of in domain data from a close language can also be very beneficial in order to make the semantic representation captured by this enriched ssl model more accurate.", "Pub Date": "2023-08-02"}
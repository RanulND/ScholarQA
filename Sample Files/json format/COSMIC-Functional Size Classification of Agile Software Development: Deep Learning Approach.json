{"Title": "COSMIC-Functional Size Classification of Agile Software Development: Deep Learning Approach", "Doi": "10.1109/ICT4DA59526.2023.10302232", "Authors": ["y. s. molla", "s. t. yimer", "e. alemneh"], "Key Words": ["bert", "cosmic", "domain-specific pre-training", "downstream task", "agile development", "re-bert", "software function size"], "Abstract": "knowing the size of a software early  i.e. requirement stage  helps to manage software projects ahead of resources especially in agile approach. with the proliferation of agile software industries large number of requirements are not clearly defined at the early phase of the software development and are left unmeasured this leads to inaccurate size and effort estimations and in turn failure of software projects. in addition it is challenging to apply common software measurement international consortium  cosmic  standard in agile developments. this is because cosmic needs strict formalization of requirements whereas agile relies on less formal specifications. having a formal or informal functional process or user story description cosmic based estimation divides this process description in to four data elements  entry read write and exit  and finally counts the number of each data element so that the size of such process description will be determined  small medium large and complex . by exploiting the advantages of cosmic on agile methods in this study we develop domain specific vocabularies through domain specific pre trained model for classification of cosmic functional sizes in agile developments. we employ an experimental research methodology for implementing our proposed approach. we further pretrain a generic bert model over requirement engineering domain texts and produce a new domain specific pre trained model called re bert. using re bert we develop deep learning classifiers  re bert seq. base bert seq. base bert  lstm re bert  lstm base bert  bi lstm re bert bi lstm  for conducting cosmic based functional size classifications. the experimental results show that re bert seq. classifier provides 78.97% prediction accuracy which is better among other classifier models  re bert lstm re bert bi lstm base bert lstm base bert bi lstm and base bert seq. classifier . overall re bert  based classifiers provide a 1.40 to 4.80% average improvement over base bert based classifiers. moreover the experimental results show that domain specific pre trained models have a promising effect on improving the performance of machine learning or deep learning models towards a particular downstream task in that domain  in our case functional size classification task .", "Pub Date": "2023-11-06"}
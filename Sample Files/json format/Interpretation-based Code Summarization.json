{"Title": "Interpretation-based Code Summarization", "Doi": "10.1109/ICPC58990.2023.00026", "Authors": ["m. geng", "s. wang", "d. dong", "h. wang", "s. cao", "k. zhang", "z. jin"], "Key Words": ["automatic comment generation", "code summarization", "model interpretation"], "Abstract": "code comment i.e. the natural language text to describe the semantic of a code snippet is an important way for developers to comprehend the code. recently a number of approaches have been proposed to automatically generate the comment given a code snippet aiming at facilitating the comprehension activities of developers. despite that state of the art approaches have already utilized advanced machine learning techniques such as the transformer model they often ignore critical information of the source code leading to the inaccuracy of the generated summarization. in this paper to boost the effectiveness of code summarization we propose a two stage paradigm where in the first stage we train an off the shelf model and then identify its focuses when generating the initial summarization through a model interpretation approach and in the second stage we reinforce the model to generate more qualified summarization based on the source code and its focuses. our intuition is that in such a manner the model could learn to identify what critical information in the code has been captured and what has been missed in its initial summarization and thus revise its initial summarization accordingly just like how a human student learns to write high quality summarization for a natural language text. extensive experiments on two large scale datasets show that our approach can boost the effectiveness of five state of the art code summarization approaches significantly. specifically for the well known code summarizer deepcom utilizing our two stage paradigm can increase its bleu-4 values by around 30% and 25% on the two datasets respectively.", "Pub Date": "2023-07-13"}
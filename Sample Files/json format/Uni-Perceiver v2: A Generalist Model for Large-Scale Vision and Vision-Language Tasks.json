{"Title": "Uni-Perceiver v2: A Generalist Model for Large-Scale Vision and Vision-Language Tasks", "Doi": "10.1109/CVPR52729.2023.00264", "Authors": ["h. li", "j. zhu", "x. jiang", "x. zhu", "h. li", "c. yuan", "x. wang", "y. qiao", "x. wang", "w. wang", "j. dai"], "Key Words": ["recognition: categorization", "detection", "retrieval"], "Abstract": "despite the remarkable success of foundation models their task specific fine tuning paradigm makes them inconsistent with the goal of general perception modeling. the key to eliminating this inconsistency is to use generalist models for general task modeling. however existing attempts at generalist models are inadequate in both versatility and performance. in this paper we propose uni perceiver v2 which is the first generalist model capable of handling major large scale vision and vision language tasks with competitive performance. specifically images are encoded as general region proposals while texts are encoded via a transformer based language model. the encoded representations are transformed by a task agnostic decoder. different tasks are formulated as a unified maximum likelihood estimation problem. we further propose an effective optimization technique named task balanced gradient normalization to ensure stable multi task learning with an unmixed sampling strategy which is helpful for tasks requiring large batch size training. after being jointly trained on various tasks uni perceiver v2 is capable of directly handling downstream tasks without any task specific adaptation. results show that uni perceiver v2 outperforms all existing generalist models in both versatility and performance. meanwhile compared with the commonly recognized strong baselines that require tasks specific fine tuning uni perceiver v2 achieves competitive performance on a broad range of vision and vision language tasks.", "Pub Date": "2023-08-22"}
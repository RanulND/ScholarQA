{"Title": "GPThreats-3: Is Automatic Malware Generation a Threat?", "Doi": "10.1109/SPW59333.2023.00027", "Authors": ["m. botacin"], "Key Words": ["malware", "large-language-models", "antivirus", "gpt-3"], "Abstract": "recent research advances introduced large textual models of which gpt-3 is state of the art. they enable many applications such as generating text and code. whereas the model capabilities might be explored for good they might also cause some negative impact  the model code generation capabilities might be used by attackers to assist in malware creation a phenomenon that must be understood. in this work our goal is to answer the question  can current large textual models  represented by gpt 3  already be used by attackers to generate malware? if so  how can attackers use these models? we explore multiple coding strategies ranging from the entire mal ware description to separate descriptions of mal ware functions that can be used as building blocks. we also test the model ability to rewrite malware code in multiple manners. our experiments show that gpt-3 still has trouble generating entire malware samples from complete descriptions but that it can easily construct malware via building block descriptions. it also still has limitations to understand the described contexts but once it is done it generates multiple versions of the same semantic  malware variants  whose detection rate significantly varies  from 4 to 55 virustotal av s .", "Pub Date": "2023-07-26"}
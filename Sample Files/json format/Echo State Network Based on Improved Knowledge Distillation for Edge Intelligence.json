{"Title": "Echo State Network Based on Improved Knowledge Distillation for Edge Intelligence", "Doi": "10.23919/cje.2022.00.292", "Authors": ["j. zhou", "y. jiang", "l. xu", "l. zhao", "f. xiao"], "Key Words": ["echo state network", "reservoir structure optimization", "knowledge distillation", "edge intelligence", "time series prediction"], "Abstract": "echo state network  esn  as a novel artificial neural network has drawn much attention from time series prediction in edge intelligence. esn is slightly insufficient in long term memory thereby impacting the prediction performance. it suffers from a higher computational overhead when deploying on edge devices. we firstly introduce the knowledge distillation into the reservoir structure optimization and then propose the echo state network based on improved knowledge distillation  esn ikd  for edge intelligence to improve the prediction performance and reduce the computational overhead. the model of esn ikd is constructed with the classic esn as a student network the long and short term memory network as a teacher network and the esn with double loop reservoir structure as an assistant network. the student network learns the long term memory capability of the teacher network with the help of the assistant network. the training algorithm of esn ikd is proposed to correct the learning direction through the assistant network and eliminate the redundant knowledge through the iterative pruning. it can solve the problems of error learning and redundant learning in the traditional knowledge distillation process. extensive experimental simulation shows that esn ikd has a good time series prediction performance in both long term and short term memory and achieves a lower computational overhead.", "Pub Date": "2024-01-22"}
{"Title": "Diversity Measures: Domain-Independent Proxies for Failure in Language Model Queries", "Doi": "10.1109/ICSC59802.2024.00034", "Authors": ["n. ngu", "n. lee", "p. shakarian"], "Key Words": ["llm", "error detection", "natural language interface", "llm hallucination"], "Abstract": "hallucinations and reasoning errors limit the ability of large language models  llms  to serve as a natural language interface for various prompts. meanwhile error prediction in large language models often relies on domain specific information. in this paper we present domain independent measures for quantification of error in the response of a large language model based on the diversity of responses to a given prompt specifically considering components of the response. this results in an approach that is well suited for prompts where the response can be viewed as an answer set such as semantic prompts a common natural language interface use case. we describe how three such measures   based on entropy gini impurity and centroid distance   can be employed. we perform a suite of experiments on multiple datasets and temperature settings to demonstrate that these measures strongly correlate with the probability of failure. additionally we present empirical results demonstrating how these measures can be applied to few shot prompting chain of thought reasoning and error detection.", "Pub Date": "2024-03-22"}
{"Title": "Generative Context-Aware Fine-Tuning of Self-Supervised Speech Models", "Doi": "10.1109/ICASSP48485.2024.10446893", "Authors": ["s. shon", "k. kim", "p. sridhar", "y. -t. hsu", "s. watanabe", "k. livescu"], "Key Words": ["context", "generative context", "self-supervised speech models"], "Abstract": "when performing tasks like automatic speech recognition or spoken language understanding for a given utterance access to preceding text or audio provides contextual information that can improve performance. considering the recent advances in generative large language models  llm  we hypothesize that an llm could generate useful context information using the preceding text. with appropriate prompts llm could generate a prediction of the next sentence or abstractive text like titles or topics. in this paper we study the use of llm generated context information and propose an approach to distill the generated information during fine tuning of self supervised speech models which we refer to as generative context aware fine tuning. this approach allows the fine tuned model to make improved predictions without access to the true surrounding segments or to the llm at inference time while requiring only a very small additional context module. we evaluate the proposed approach using the slue and libri light benchmarks for several downstream tasks  automatic speech recognition named entity recognition and sentiment analysis. the results show that generative context aware fine tuning outperforms a context injection fine tuning approach that accesses the ground truth previous text and is competitive with a generative context injection fine tuning approach that requires the llm at inference time.", "Pub Date": "2024-03-18"}
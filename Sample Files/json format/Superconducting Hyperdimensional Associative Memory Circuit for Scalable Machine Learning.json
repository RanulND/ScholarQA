{"Title": "Superconducting Hyperdimensional Associative Memory Circuit for Scalable Machine Learning", "Authors": ["k. huch", "p. gonzalez-guerrero", "d. lyles", "g. michelogiannakis"], "Pub Date": "2023-05-29", "Abstract": "we propose a generalized architecture for the first rapid single flux quantum  rsfq  associative memory circuit. the circuit employs hyperdimensional computing  hdc  a machine learning  ml  paradigm utilizing vectors with dimensionality in the thousands to represent information. hdc designs have small memory footprints simple computations and simple training algorithms compared to superconducting neural network accelerators  snnas  making them a better option for scalable sfq machine learning  ml  solutions. the proposed superconducting hdc  shdc  circuit uses entirely on chip rsfq memory which is tightly integrated with logic operates at 33.3 ghz is applicable to general ml tasks and is manufacturable at practically useful scales given current sfq fabrication limits. tailored to a language recognition task shdc consists of $\\sim$2\u201a\u00e4\u00ec20 m josephson junctions  jjs  and consumes up to three times less power than an analogous cmos hdc circuit while achieving 78\u201a\u00e4\u00ec84% higher throughput. shdc is capable of outperforming the state of the art rsfq snna supernpu by 48 99% for all benchmark nn architectures tested while occupying up to 90% less area and consuming up to nine times less power. to the best of the authors' knowledge shdc is currently the only superconducting ml approach feasible at practically useful scales for real world ml tasks and capable of online learning.", "Doi": "10.1109/TASC.2023.3271951", "Key Words": ["superconducting digital computing", "hyperdimesional computing", "machine learning", "low energy", "area efficiency", "neuromorphic computing", "rsfq"]}
{"Title": "AdaPT: Fast Emulation of Approximate DNN Accelerators in PyTorch", "Authors": ["d. danopoulos", "g. zervakis", "k. siozios", "d. soudris", "j. henkel"], "Pub Date": "2023-05-19", "Abstract": "current state of the art employs approximate multipliers to address the highly increased power demands of deep neural network  dnn  accelerators. however evaluating the accuracy of approximate dnns is cumbersome due to the lack of adequate support for approximate arithmetic in dnn frameworks. we address this inefficiency by presenting adapt a fast emulation framework that extends pytorch to support approximate inference as well as approximation aware retraining. adapt can be seamlessly deployed and is compatible with the most dnns. we evaluate the framework on several dnn models and application fields including cnns lstms and gans for a number of approximate multipliers with distinct bitwidth values. the results show substantial error recovery from approximate retraining and reduced inference time up to  $53.9 \\times $  with respect to the baseline approximate implementation.", "Doi": "10.1109/TCAD.2022.3212645", "Key Words": ["accelerator", "approximate computing", "deep neural network (dnn)", "pytorch", "quantization"]}
{"Title": "A Large Model\u201a\u00c4\u00f4s Ability to Identify 3D Objects as a Function of Viewing Angle", "Doi": "10.1109/AIxVR59861.2024.00047", "Authors": ["j. rubinstein", "f. ferraro", "c. matuszek", "d. engel"], "Key Words": ["multimodal interaction", "virtual reality", "clip", "3d models"], "Abstract": "virtual reality is progressively more widely used to support embodied artificial intelliegence agents such as robots which frequently engage in \u201a\u00e4\u00f2sim to real\u201a\u00e4\u00f4 based learning approaches. at the same time tools such as large vision and language models offer new capabilities that tie into a wide variety of tasks and capabilities. in order to understand how such agents can learn from simulated environments we explore a language model\u201a\u00e4\u00f4s ability to recover the type of object represented by a photorealistic 3d model as a function of the 3d perspective from which the model is viewed. we used photogrammetry to create 3d models of commonplace objects and rendered 2d images of these models from an fixed set of 420 virtual camera perspectives. a well studied image and language model  clip  was used to generate text  i.e. prompts  corresponding to these images. using multiple instances of various object classes we studied which camera perspectives were most likely to return accurate text categorizations for each class of object.", "Pub Date": "2024-02-28"}
{"Title": "Prediction of actions and places by the time series recognition from images with Multimodal LLM", "Doi": "10.1109/ICSC59802.2024.00053", "Authors": ["t. ogawa", "k. yoshioka", "k. fukuda", "t. morita"], "Key Words": ["knowledge graph reasoning challenge"], "Abstract": "in recent years the risk of accidents in the homes of older adults in an aging society has increased and there is a need to address this problem. we took up the challenge of utilising explainable ai techniques to identify accident risks at home and suggest safer alternatives. this study combined knowledge graphs and large scale language models to solve real world problems. specifically we addressed answering questions using a multimodal dataset of videos recording daily activities and a knowledge graph. the dataset represents the living activities in the virtual space and provides environmental information. the task is divided into two main tasks. task 1 utilises knowledge graph to answer direct questions and processes the data using sparql queries. task 2 addresses more complex questions that cannot be answered by search alone. consequently in task 1 the system could answer all questions using information from the sparql knowledge graph. in task 2 a certain degree of success was achieved for complex questions by reasoning with images created by concatenating multimodal llms and time series images. the source code used in the experiment is available at https //github.com tomo1115tomo kg reasoning challenge.", "Pub Date": "2024-03-22"}
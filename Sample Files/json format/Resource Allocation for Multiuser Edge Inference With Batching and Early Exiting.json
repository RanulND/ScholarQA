{"Title": "Resource Allocation for Multiuser Edge Inference With Batching and Early Exiting", "Doi": "10.1109/JSAC.2023.3242724", "Authors": ["z. liu", "q. lan", "k. huang"], "Key Words": ["edge inference", "radio resource management", "multiuser edge computing"], "Abstract": "the deployment of inference services at the network edge called edge inference offloads computation intensive inference tasks from mobile devices to edge servers thereby enhancing the former\u201a\u00e4\u00f4s capabilities and battery lives. in a multiuser system the joint allocation of communication and computation  c2  resources  i.e. scheduling and bandwidth allocation  is made challenging by adopting efficient inference techniques batching and early exiting and further complicated by the heterogeneity in users\u201a\u00e4\u00f4 requirements on accuracy and latency. batching groups multiple tasks into a single batch for parallel processing to reduce time consuming memory access and thereby boosts the throughput  i.e. completed task per second . on the other hand early exiting allows a task to exit from a deep neural network without traversing the whole network thereby supporting a tradeoff between accuracy and latency. in this work we study optimal c2 resource allocation with batching and early exiting which is an np complete integer programming problem. a set of efficient algorithms are designed under the criterion of maximum throughput by tackling the challenge. first consider the case with batching but without early exiting. the target problem is solved optimally using a proposed best shelf packing algorithm that nests a threshold based scheme which selects users with the best channels and meeting the computation time constraints in a sequential search for the maximum batch size. next consider the general case with batching and early exiting. a low complexity sub optimal algorithm for c2 resource allocation is developed by modifying the preceding algorithm to exploit early exiting for latency reduction. on the other hand the optimal approach is developed based on nesting a depth first tree search with intelligent online pruning into a sequential search for the maximum batch size. the key idea is to derive pruning criteria based on the simple greedy solution for the target problem without a bandwidth constraint and apply the result to designing an intelligent online pruning scheme. experimental results demonstrate that both optimal and sub optimal c2 resource allocation algorithms can leverage integrated batching and early exiting to double the inference throughput compared with conventional schemes.", "Pub Date": "2023-03-17"}
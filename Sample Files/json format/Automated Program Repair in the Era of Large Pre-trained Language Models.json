{"Title": "Automated Program Repair in the Era of Large Pre-trained Language Models", "Doi": "10.1109/ICSE48619.2023.00129", "Authors": ["chunqiu steven xia", "yuxiang wei", "lingming zhang"], "Key Words": ["codes", "computer bugs", "maintenance engineering", "software", "distance measurement", "task analysis", "faces", "automated program repair", "machine learning"], "Abstract": "automated program repair  automated program sepair  aims to help developers automatically patch software bugs. however current state of the art traditional and learning based automated program sepair techniques face the problem of limited patch variety failing to fix complicated bugs. this is mainly due to the reliance on bug fixing datasets to craft fix templates  traditional  or directly predict potential patches  learning based . large pre trained language models  large language model  trained using billions of text code tokens can potentially help avoid this issue. very recently researchers have directly leveraged large language model for automated program sepair without relying on any bug fixing datasets. meanwhile such existing work either failed to include state of the art large language model or was not evaluated on realistic datasets. thus the true power of modern large language model on the important automated program sepair problem is yet to be revealed. in this work we perform the first extensive study on directly applying large language model for automated program sepair. we select 9 recent state of the art large language model including both generative and infilling models ranging from 125m to 20b in size. we designed 3 different repair settings to evaluate the different ways we can use large language model to generate patches  1  generate the entire patch function 2  fill in a chunk of code given the prefix and suffix 3  output a single line fix. we apply the large language model under these repair settings on 5 datasets across 3 different languages and compare different large language model in the number of bugs fixed generation speed and compilation rate. we also compare the large language model against recent state of the art automated program sepair tools. our study demonstrates that directly applying state of the art large language model can already substantially outperform all existing automated program sepair techniques on all our datasets. among the studied large language model the scaling effect exists for automated program sepair where larger models tend to achieve better performance. also we show for the first time that suffix code after the buggy line  adopted in infilling style automated program sepair  is important in not only generating more fixes but more patches with higher compilation rate. besides patch generation the large language model consider correct patches to be more natural than other ones and can even be leveraged for effective patch ranking or patch correctness checking. lastly we show that large language model based automated program sepair can be further substantially boosted via  1  increasing the sample size and 2  incorporating fix template information.", "Pub Date": "2023-05-20"}
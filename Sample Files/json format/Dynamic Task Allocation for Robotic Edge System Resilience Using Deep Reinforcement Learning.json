{"Title": "Dynamic Task Allocation for Robotic Edge System Resilience Using Deep Reinforcement Learning", "Doi": "10.1109/TSMC.2023.3327959", "Authors": ["m. afrin", "j. jin", "a. rahman", "s. li", "y. -c. tian", "y. li"], "Key Words": ["deep reinforcement learning (drl)", "edge computing", "multirobot system", "smart farming", "task allocation"], "Abstract": "incorporating edge and cloud computing with robotics provides extended options for robots to perform real time sensing and actuation operations in various cyber\u201a\u00e4\u00ecphysical systems  cpss  including smart farms. such systems are prone to uncertain failures triggered by mechanical disruptions. consequently the overall system performance degrades primarily when location specific tasks are already assigned to a faulty robot and require immediate recovery. using edge and cloud computing resources is not always feasible due to communication and latency constraints. therefore this article exclusively focuses on harnessing the mobility of robots to support the computation tasks affected by uncertain failures of previously assigned robots and ensure faster resiliency management by relocating active robots near task sources. the proposed mobility as a resilience service  maars  is formulated using a markov decision process  mdp . later an edge server proximal to the robots is trained using deep reinforcement learning  drl  to assign tasks among the robots. specifically a multiple deep  $q$  network  mdqn  based dynamic task allocation mechanism is proposed to converge to a solution exploring reward uncertainties with the best exploitation. numerical evaluation using python and tensorflow validates the effectiveness of the proposed approach compared to other benchmarks.", "Pub Date": "2024-02-15"}
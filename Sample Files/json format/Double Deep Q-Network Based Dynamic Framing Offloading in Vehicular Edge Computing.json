{"Title": "Double Deep Q-Network Based Dynamic Framing Offloading in Vehicular Edge Computing", "Doi": "10.1109/TNSE.2022.3172794", "Authors": ["h. tang", "h. wu", "g. qu", "r. li"], "Key Words": ["vehicular edge computing", "internet of vehicles", "task offloading", "deep reinforcement learning"], "Abstract": "with the rapid development of artificial intelligence  artificial intelliegence  and the internet of vehicles  iov  there is an increasing demand for deploying various intelligent applications on vehicles. vehicular edge computing  vec  is receiving extensive attention from both the industry and academia due to its benefits from the edge computing paradigm which pushes computing tasks from the core of the network to the edge of the network. however in the vec environment considering vehicles to road side units  rsus  due to the mobility of vehicles it is still a challenge to make dynamic and efficient offloading decisions for compute intensive tasks especially in the congestion situation. in order to minimize the total delay and waiting time of tasks from moving vehicles we establish a dynamic offloading model for multiple moving vehicles whose tasks can be divided into sequential subtasks so that the offloading decisions are more refined. moreover the proposed model is frame based to avoid unnecessary waiting time which makes offloading decisions when the subtasks of each vehicle are generated rather than offloading subtasks after gathering subtasks of vehicles for a time slot. aiming to find the optimal offloading decision for sequential subtasks we propose a dynamic framing offloading algorithm based on double deep q network  dfo ddqn . extensive experimental results demonstrate the effectiveness and superiority of the proposed dfo ddqn when compared with other drl based methods and greedy based methods.", "Pub Date": "2023-04-24"}
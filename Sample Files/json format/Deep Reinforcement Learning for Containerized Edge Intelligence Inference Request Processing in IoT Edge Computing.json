{"Title": "Deep Reinforcement Learning for Containerized Edge Intelligence Inference Request Processing in IoT Edge Computing", "Doi": "10.1109/TSC.2023.3320752", "Authors": ["l. nkenyereye", "k. -j. baeg", "w. -y. chung"], "Key Words": ["internet of things", "iot service layer", "iot edge computing", "deep reinforcement learning", "edge intelligence", "artificial intelligence", "ai model inference"], "Abstract": "edge intelligence  ei  refers to a set of connected systems and devices for artificial intelligence  ai  data collected and learned near the data collection site. the ei model inference phase has been improved through edge caching technologies such as intelligent models  ims . im inference across heterogeneously distributed edge nodes is worthy of discussion. the present focuses on software defined infrastructure  sdi  and introduces a containerized ei framework for a mobile wearable internet of things  iot  system. this framework called the containerized edge intelligence framework  ceif  is an inter working architecture that allows the provisioning of containerized ei processing intelligent services related to mobile wearable iot systems. ceif enables dynamic instantiation of the inference services of ai models that have been pre trained on clouds. it also accommodates edge computing devices  ecds  running the container virtualization technique. dynamic ai learning policies can also help with workload optimization thereby reducing the response time of the requests of the ei inference. to stall the rapid increase in user workload when inferring the collected data for analysis we then propose a deep q learning algorithm in which the container cluster platform learns the varying user workload at the location of each ecd. the requests of the ei inference are scaled with the learned value and are processed successfully without overloading the ecd. when evaluated in a case study the proposed algorithm enabled scaling of the processing requests of the ei inference in a containerized ei system while minimizing the number of instantiated container ei instances. the ei inference requests are completed in an under loaded container ei cluster system.", "Pub Date": "2023-12-14"}
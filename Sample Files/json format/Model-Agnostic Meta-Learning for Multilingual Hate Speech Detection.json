{"Title": "Model-Agnostic Meta-Learning for Multilingual Hate Speech Detection", "Doi": "10.1109/TCSS.2023.3252401", "Authors": ["m. r. awal", "r. k. -w. lee", "e. tanwar", "t. garg", "t. chakraborty"], "Key Words": ["cross-lingual transfer", "hate speech detection", "meta-learning"], "Abstract": "hate speech in social media is a growing phenomenon and detecting such toxic content has recently gained significant traction in the research community. existing studies have explored fine tuning language models  lms  to perform hate speech detection and these solutions have yielded significant performance. however most of these studies are limited to detecting hate speech only in english neglecting the bulk of hateful content that is generated in other languages particularly in low resource languages. developing a classifier that captures hate speech and nuances in a low resource language with limited data is extremely challenging. to fill the research gap we propose hatemaml a model agnostic meta learning  maml  based framework that effectively performs hate speech detection in low resource languages. hatemaml utilizes a self supervision strategy to overcome the limitation of data scarcity and produces better lm initialization for fast adaptation to an unseen target language  i.e. cross lingual transfer  or other hate speech datasets  i.e. domain generalization . extensive experiments are conducted on five datasets across eight different low resource languages. the results show that hatemaml outperforms the state of the art baselines by more than 3% in the cross domain multilingual transfer setting. we also conduct ablation studies to analyze the characteristics of hatemaml.", "Pub Date": "2024-01-25"}
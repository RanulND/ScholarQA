{"Title": "PEvoLM: Protein Sequence Evolutionary Information Language Model", "Doi": "10.1109/CIBCB56990.2023.10264890", "Authors": ["i. arab"], "Key Words": ["protein sequences", "evolutionary information", "pssm", "variational inference", "deep learning", "multi-task learning", "elmo"], "Abstract": "with the exponential increase of the protein sequence databases over time multiple sequence alignment  msa  methods like psi blast perform exhaustive and time consuming database search to retrieve evolutionary information. the resulting position specific scoring matrices  pssms  of such search engines represent a crucial input to many machine learning  ml  models in the field of bioinformatics and computational biology. a protein sequence is a collection of contiguous tokens or characters called amino acids  aas . the analogy to natural language allowed us to exploit the recent advancements in the field of natural language processing  nlp  and therefore transfer nlp state of the art algorithms to bioinformatics. this research presents an embedding language model  elmo  converting a protein sequence to a numerical vector representation. while the original elmo trained a 2 layer bidirectional long short term memory  lstms  network following a two path architecture one for the forward and the second for the backward pass by merging the idea of pssms with the concept of transfer learning this work introduces a novel bidirectional language model  bi lm  with four times less free parameters and using rather a single path for both passes. the model was trained not only on predicting the next aa but also on the probability distribution of the next aa derived from similar yet different sequences as summarized in a pssm simultaneously for multitask learning hence learning evolutionary information of protein sequences as well. the network architecture and the pre trained model are made available as open source under the permissive mit license on github at https //github.com issararab/pevolm.", "Pub Date": "2023-10-02"}
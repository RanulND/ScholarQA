{"Title": "Enhancing Argument Pair Extraction Through Supervised Fine-Tuning of the Llama Model", "Doi": "10.1109/EEBDA60612.2024.10485782", "Authors": ["t. mao", "j. fu", "o. yoshie"], "Key Words": ["argumentation", "argument pair extraction", "large language model", "llama", "supervised fine-tuning"], "Abstract": "argument pair extraction  ape  represents a crucial task within the domain of argument mining. this process involves identifying argument pairs within dialogue documents and subsequently creating their associations. the research paper at hand introduces a novel model designated as the llama argument pair extractor  lape  which applies a generative paradigm based on the llama2 7b model to address the complexities inherent to the ape challenge. unlike existing methods that pair arguments in a cascade of tasks prone to error amplification and insufficient training lape generates argument pairs end to end mitigating these issues. our methodology initially undergoes a pre training phase wherein the model is allowed to learn from a vast corpus of unlabeled textual data. this facilitates the acquisition of a broad spectrum of linguistic knowledge. subsequently during the fine tuning phase we train the model parameters in accordance with labeled data. it is aimed at enhancing the model proficiency in executing the argument pair extraction task. experimental results demonstrate that our model outperforms existing extractive models in the task of argument pair extraction. this not only underscores the superiority of our model but also highlights the advantage and potential of generative models in the realm of argument pair extraction.", "Pub Date": "2024-04-08"}
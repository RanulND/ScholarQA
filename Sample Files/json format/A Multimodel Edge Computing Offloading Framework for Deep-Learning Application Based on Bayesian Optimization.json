{"Title": "A Multimodel Edge Computing Offloading Framework for Deep-Learning Application Based on Bayesian Optimization", "Doi": "10.1109/JIOT.2023.3280162", "Authors": ["z. zhao", "h. zhang", "l. wang", "h. huang"], "Key Words": ["bayesian optimization", "deep-learning", "edge computing", "lyapunov drift function", "modified tree-structured parzen estimator (mtpe)", "multimodel"], "Abstract": "with the rapid development of the internet of things  iot  data generated by iot devices are also increasing exponentially. the edge computing has alleviated the problems of limited network and transmission delay when processing tasks of iot devices in traditional cloud computing. and with the popularity of deep learning more and more terminal devices are embedded with artificial intelligence  ai  processors for higher processing capability at the edge. however the problems of deep learning task offloading in a heterogeneous edge computing environment have not been fully investigated. in this article a multimodel edge computing offloading framework is proposed using nvidia jetson edge devices  jetson tx2 jetson xavier nx and jetson nano  and geforce rtx gpu servers  rtx3080 and rtx2080  to simulate the edge computing environment and make binary computational offloading decisions for face detection tasks. we also introduce a bayesian optimization algorithm namely modified tree structured parzen estimator  mtpe  to reduce the total cost of edge computation within a time slot including response time and energy consumption and ensure the accuracy requirements of face detection. in addition we employ the lyapunov model to obtain the harvesting energy between time slots to keep the energy queue stable. experiments reveal that mtpe algorithm can achieve the globally optimal solution in fewer iterations. the total cost of multimodel edge computing framework is reduced by an average of 17.94% compared to a single model framework. in contrast to the double deep q network  ddqn  our proposed algorithm can decrease the computational consumption by 23.01% for obtaining the offloading decision.", "Pub Date": "2023-10-03"}
{"Title": "The Doctrine of MEAN: Realizing Deduplication Storage at Unreliable Edge", "Doi": "10.1109/TPDS.2023.3305460", "Authors": ["j. xia", "g. cheng", "l. luo", "d. guo", "p. lv", "b. sun"], "Key Words": ["deduplication", "fault tolerance", "storage system", "edge computing"], "Abstract": "placing popular data at the network edge helps reduce the retrieval latency but it also brings challenges to the limited edge storage space. currently using available yet not necessarily reliable edge resources is common sense for edge space expansion while deploying deduplication storage strategies is a general method for better space utilization. however a contradiction arises when jointly implementing data deduplication with unreliable edge resources. on the one hand the deduplication policy stipulates that any data chunk can be stored exactly once  on the other hand the use of unreliable resources imposes that data should be backed up for the seek of file availability. to resolve such contradiction we propose mean a deduplication enabled storage system using unreliable resources at the network edge. the core idea of mean is to place similar files together for better deduplication and maintain replicas of popular files for higher reliability. we first formulate this problem and prove its np hardness then provide efficient heuristics based on similarity aware hierarchical clustering. three different reliability scenarios are comprehensively considered to develop our algorithms. we also implement a prototype system and evaluate the performance of mean with a real world dataset. the results show that mean can fortify the file hit ratio under unreliable environments by 77% while reducing the file retrieval delay up to 71% compared with the state of the art approach.", "Pub Date": "2023-08-24"}
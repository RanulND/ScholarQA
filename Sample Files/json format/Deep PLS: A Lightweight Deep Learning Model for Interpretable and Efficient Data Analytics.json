{"Title": "Deep PLS: A Lightweight Deep Learning Model for Interpretable and Efficient Data Analytics", "Doi": "10.1109/TNNLS.2022.3154090", "Authors": ["x. kong", "z. ge"], "Key Words": ["deep learning", "latent variable models", "machine learning", "model interpretability", "partial least squares (plss)"], "Abstract": "the salient progress of deep learning is accompanied by nonnegligible deficiencies such as  1  interpretability problem  2  requirement for large data amounts  3  hard to design and tune parameters  and 4  heavy computation complexity. despite the remarkable achievements of neural networks based deep models in many fields the practical applications of deep learning are still limited by these shortcomings. this article proposes a new concept called the lightweight deep model  ldm . ldm absorbs the useful ideas of deep learning and overcomes their shortcomings to a certain extent. we explore the idea of ldm from the perspective of partial least squares  pls  by constructing a deep pls  dpls  model. the feasibility and merits of dpls are proved theoretically after that dpls is further generalized to a more common form  gdpls  by adding a nonlinear mapping layer between two cascaded pls layers in the model structure. the superiority of dpls and gdpls is demonstrated through four practical cases involving two regression problems and two classification tasks in which our model not only achieves competitive performance compared with existing neural networks based deep models but also is proven to be a more interpretable and efficient method and we know exactly how it improves performance how it gives correct results. note that our proposed model can only be regarded as an alternative to fully connected neural networks at present and cannot completely replace the mature deep vision or language models.", "Pub Date": "2023-10-27"}
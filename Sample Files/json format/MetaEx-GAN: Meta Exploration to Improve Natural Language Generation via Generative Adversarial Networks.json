{"Title": "MetaEx-GAN: Meta Exploration to Improve Natural Language Generation via Generative Adversarial Networks", "Doi": "10.1109/TASLP.2023.3317571", "Authors": ["y. -y. chuang", "h. -m. hsu", "k. lin", "r. -i. chang", "h. -y. lee"], "Key Words": ["generative adversarial networks", "large-scaled pre-trained model", "meta reinforcement learning", "natural language generation"], "Abstract": "generative adversarial networks  gans  have been popularly researched in natural language generation so called language gans. existing works adopt reinforcement learning  rl  based methods such as policy gradients for training language gans. the previous research of language gans usually focuses on stabilizing policy gradients or applying robust architectures  such as the large scale pre trained gpt 2  to achieve better performance. however the quality and diversity of sampling are not guaranteed simultaneously. in this article we propose a novel meta learning based generative adversarial network meta exploration gan  metaex gan  for ensuring the quality and diversity of sampling  sampling efficiency . in the proposed metaex gan we develop an explorer trained by meta exploration to sample from the generated data to achieve better sampling efficiency. metaex gan employs metaex first applied to language gans to achieve better performance. we also propose a critical training method for metaex gan on the nlg task. according to our experimental results metaex gan achieves state of the art performance compared with existing language gans methods. our experiments also demonstrate the generality of metaex gan with different architectures  involving gpt 2  and how metaex gan operates to improve language gans.", "Pub Date": "2023-10-23"}
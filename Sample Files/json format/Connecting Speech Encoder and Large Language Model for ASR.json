{"Title": "Connecting Speech Encoder and Large Language Model for ASR", "Doi": "10.1109/ICASSP48485.2024.10445874", "Authors": ["w. yu", "c. tang", "g. sun", "x. chen", "t. tan", "w. li", "l. lu", "z. ma", "c. zhang"], "Key Words": ["large language model", "automatic speech recognition", "q-former", "long-form speech"], "Abstract": "the impressive capability and versatility of large language models  large language model  have aroused increasing attention in automatic speech recognition  asr  with several pioneering studies attempting to build integrated asr models by connecting a speech encoder with an large language model. this paper presents a comparative study of three commonly used structures as connectors including fully connected layers multi head cross attention and q former. speech encoders from the whisper model series as well as large language model from the vicuna model series with different model sizes were studied. experiments were performed on the commonly used librispeech common voice and gigaspeech datasets where the large language model with q formers demonstrated consistent and considerable word error rate  wer  reductions over large language model with other connector structures. q former based large language model can generalise well to out of domain datasets where 12% relative wer reductions over the whisper baseline asr model were achieved on the eval2000 test set without using any in domain training data from switchboard. moreover a novel segment level q former is proposed to enable large language model to recognise speech segments with a duration exceeding the limitation of the encoders which results in 17% relative wer reductions over other connector structures on 90 second long speech data.", "Pub Date": "2024-03-18"}
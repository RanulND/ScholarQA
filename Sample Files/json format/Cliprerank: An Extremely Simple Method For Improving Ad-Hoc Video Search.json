{"Title": "Cliprerank: An Extremely Simple Method For Improving Ad-Hoc Video Search", "Doi": "10.1109/ICASSP48485.2024.10446902", "Authors": ["a. chen", "f. zhou", "z. wang", "x. li"], "Key Words": ["ad-hoc video search", "large vision-language models", "video search reranking"], "Abstract": "ad hoc video search  avs  enables users to search for unlabeled video content using on the fly textual queries. current deep learning based models for avs are trained to optimize holistic similarity between short videos and their associated descriptions. however due to the diversity of ad hoc queries even for a short video its truly relevant part w.r.t. a given query can be of shorter duration. in such a scenario the holistic similarity becomes suboptimal. to remedy the issue we propose in this paper cliprerank a fine grained re scoring method. we compute cross modal similarities between query and video frames using a pre trained clip model with multi frame scores aggregated by max pooling. the fine grained score is weightedly added to the initial score for search result reranking. as such cliprerank is agnostic to the underlying video retrieval models and extremely simple making it a handy plug in for boosting avs. experiments on the challenging trecvid avs benchmarks  from 2016 to 2021  justify the effectiveness of the proposed strategy. cliprerank consistently improves the trecvid top performers and multiple existing models including sea w2vv++ dual encoding dual task laff clip2video ts2 net and x clip. our method also works when substituting blip-2 for clip.", "Pub Date": "2024-03-18"}
{"Title": "Deep Meta Q-Learning Based Multi-Task Offloading in Edge-Cloud Systems", "Doi": "10.1109/TMC.2023.3264901", "Authors": ["n. sharma", "a. ghosh", "r. misra", "s. k. das"], "Key Words": ["deep q-learning", "directed acyclic graph", "edge-cloud computing", "internet of things", "meta-learning", "multi-task offloading"], "Abstract": "resource constrained edge devices can not efficiently handle the explosive growth of mobile data and the increasing computational demand of modern day user applications. task offloading allows the migration of complex tasks from user devices to the remote edge cloud servers thereby reducing their computational burden and energy consumption while also improving the efficiency of task processing. however obtaining the optimal offloading strategy in a multi task offloading decision making process is an np hard problem. existing deep learning techniques with slow learning rates and weak adaptability are not suitable for dynamic multi user scenarios. in this article we propose a novel deep meta reinforcement learning based approach to the multi task offloading problem using a combination of first order meta learning and deep q learning methods. we establish the meta generalization bounds for the proposed algorithm and demonstrate that it can reduce the time and energy consumption of iot applications by up to 15%. through rigorous simulations we show that our method achieves near optimal offloading solutions while also being able to adapt to dynamic edge cloud environments.", "Pub Date": "2024-03-07"}
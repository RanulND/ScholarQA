{"Title": "PromptTTS++: Controlling Speaker Identity in Prompt-Based Text-To-Speech Using Natural Language Descriptions", "Doi": "10.1109/ICASSP48485.2024.10448173", "Authors": ["r. shimizu", "r. yamamoto", "m. kawamura", "y. shirahata", "h. doi", "t. komatsu", "k. tachibana"], "Key Words": ["text-to-speech", "speech synthesis", "speaker generation", "mixture model", "diffusion model"], "Abstract": "we propose prompttts++ a prompt based text to speech  tts  synthesis system that allows control over speaker identity using natural language descriptions. to control speaker identity within the prompt based tts framework we introduce the concept of speaker prompt which describes voice characteristics  e.g. gender neutral young old and muffled  designed to be approximately independent of speaking style. since there is no large scale dataset containing speaker prompts we first construct a dataset based on the libritts r corpus with manually annotated speaker prompts. we then employ a diffusion based acoustic model with mixture density networks to model diverse speaker factors in the training data. unlike previous studies that rely on style prompts describing only a limited aspect of speaker individuality such as pitch speaking speed and energy our method utilizes an additional speaker prompt to effectively learn the mapping from natural language descriptions to the acoustic features of diverse speakers. our subjective evaluation results show that the proposed method can better control speaker characteristics than the methods without the speaker prompt. audio samples are available at https //reppy4620.github.io demo.promptttspp/.", "Pub Date": "2024-03-18"}
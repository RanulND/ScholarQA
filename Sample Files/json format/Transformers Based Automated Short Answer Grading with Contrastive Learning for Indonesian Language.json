{"Title": "Transformers Based Automated Short Answer Grading with Contrastive Learning for Indonesian Language", "Doi": "10.1109/ICITEE59582.2023.10317785", "Authors": ["a. a. s. mukti", "s. a. i. alfarozi", "s. s. kusumawardani"], "Key Words": ["contrastive learning", "transformers", "automated short answer grading", "e-learning", "large language model"], "Abstract": "the rapid development of technology has impacted various sectors including education. these developments have enabled e learning to thrive especially during the covid 19 pandemic. evaluating student performance and understanding in e learning is typically done through quizzes. however these evaluations especially in essay grading still require manual effort. this can lead to exhaustion and introduce bias and inconsistency into the scoring process. to address this issue one possible solution is to develop an automated short answer grading system. this research explores large language model that has a general understanding of language. this model is then subjected to a finetuning process. specifically this study employs bert model with contrastive learning method to develop an automated short answer scoring system and compare its performance with similar systems. the model is composed of two components namely the model body which utilizes bert variation and the model head which employs logistic regression. the model body is structured in a siamese architecture. the results demonstrate an improvement in model performance of bert model with constrastive learning. when compared to the pretrained bert and bert with cosine similarity finetuning the reduction in prediction mae is 21.72% and 9.90% while for the rmse metric it is 17.79% and 13.80%. the transformers based model with contrastive learning achieves metrics of 0.191 for mae and 0.231 for rmse. these findings indicate the potential of using the contrastive learning method in transformers models to develop an automated short answer scoring system.", "Pub Date": "2023-11-20"}
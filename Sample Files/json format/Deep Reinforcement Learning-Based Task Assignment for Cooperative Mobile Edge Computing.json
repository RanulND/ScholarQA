{"Title": "Deep Reinforcement Learning-Based Task Assignment for Cooperative Mobile Edge Computing", "Doi": "10.1109/TMC.2023.3270242", "Authors": ["l. -t. hsieh", "h. liu", "y. guo", "r. gazda"], "Key Words": ["mobile edge computing (mec)", "edge server cooperation", "task assignment", "stochastic optimization", "deep reinforcement learning"], "Abstract": "mobile edge computing  mec  integrates computing resources in wireless access networks to process computational tasks in close proximity to mobile users with low latency. this paper investigates the task assignment problem for cooperative mec networks in which a set of geographically distributed heterogeneous edge servers not only cooperate with remote cloud data centers but also help each other to jointly process user tasks. we introduce a novel stochastic mec cooperation framework to model the edge to edge horizontal cooperation and the edge to cloud vertical cooperation. the task assignment optimization problem is formulated by taking into consideration dynamic network states uncertain node computing capabilities and task arrivals as well as the heterogeneity of the involved entities. we then develop and compare three task assignment algorithms based on different deep reinforcement learning  drl  approaches value based policy based and hybrid approaches. in addition to reduce the search space and computation complexity of the algorithms we propose decomposition and function approximation techniques by leveraging the structure of the underlying problem. the evaluation results show that the proposed drl based task assignment schemes outperform the existing algorithms and the hybrid actor critic scheme performs the best under dynamic mec network environments.", "Pub Date": "2024-03-07"}
{"Title": "Examining Zero-Shot Vulnerability Repair with Large Language Models", "Doi": "10.1109/SP46215.2023.10179324", "Authors": ["h. pearce", "b. tan", "b. ahmad", "r. karri", "b. dolan-gavitt"], "Key Words": ["cybersecurity", "ai", "code generation", "cwe"], "Abstract": "human developers can produce code with cybersecurity bugs. can emerging \u201a\u00e4\u00f2smart\u201a\u00e4\u00f4 code completion tools help repair those bugs? in this work we examine the use of large language models  large language model  for code  such as openai\u201a\u00e4\u00f4s codex and ai21\u201a\u00e4\u00f4s jurassic j 1  for zero shot vulnerability repair. we investigate challenges in the design of prompts that coax large language model into generating repaired versions of insecure code. this is difficult due to the numerous ways to phrase key information\u201a\u00e4\u00ee both semantically and syntactically\u201a\u00e4\u00eewith natural languages. we perform a large scale study of five commercially available black box \"off the shelf\" large language model as well as an open source model and our own locally trained model on a mix of synthetic hand crafted and real world security bug scenarios. our experiments demonstrate that while the approach has promise  the large language model could collectively repair 100% of our synthetically generated and hand crafted scenarios  a qualitative evaluation of the model\u201a\u00e4\u00f4s performance over a corpus of historical real world examples highlights challenges in generating functionally correct code.", "Pub Date": "2023-07-21"}
{"Title": "MT-DST: Multi-Task Strategy for Few-shot Dialog State Tracking", "Doi": "10.1109/MLBDBI60823.2023.10482155", "Authors": ["j. tang"], "Key Words": ["dialogue state tracking", "few-shot learning", "multi-task learning", "speech processing", "computational linguistics"], "Abstract": "the remarkable effectiveness of large pre trained models in task oriented dialogue  tod  systems particularly in the area of dialog state tracking  dst  has been well documented even in scenarios with limited labeled data. in the past researchers mainly focused on two approaches  generating all belief states simultaneously or generating values sequentially by prompting for each individual slot. the first technique heavily relies on the model\u201a\u00e4\u00f4s comprehension ability which often leads to inferior results while the latter requires going through every possible slot thus compromising processing speed. to address these challenges we propose a new multi task strategy for few shot dialog state tracking  mt dst  to achieve favorable outcomes while maintaining a fast pace. this method utilizes the former approach as the main task with the secondary task serving as an auxiliary job for incorporating additional data. our model has demonstrated state of the art performance in a few shot dst tasks through experiments on the widely used multiwoz 2.1 benchmark.", "Pub Date": "2024-04-02"}
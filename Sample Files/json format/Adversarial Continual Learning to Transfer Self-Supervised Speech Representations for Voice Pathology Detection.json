{"Title": "Adversarial Continual Learning to Transfer Self-Supervised Speech Representations for Voice Pathology Detection", "Authors": ["d. park", "y. yu", "d. katabi", "h. k. kim"], "Pub Date": "2023-07-28", "Abstract": "in recent years voice pathology detection  vpd  has received considerable attention because of the increasing risk of voice problems. several methods such as support vector machine and convolutional neural network based models achieve good vpd performance. to further improve the performance we use a self supervised pretrained model as feature representation instead of explicit speech features. when the pretrained model is fine tuned for vpd an overfitting problem occurs due to a domain shift from conversation speech to the vpd task. to mitigate this problem we propose an adversarial task adaptive pretraining  a tapt  approach by incorporating adversarial regularization during the continual learning process. experiments on vpd using the saarbrucken voice database show that the proposed a tapt improves the unweighted average recall  uar  by an absolute increase of 12.36% and 15.38% compared with svm and resnet50 respectively. it is also shown that the proposed a tapt achieves a uar that is 2.77% higher than that of conventional tapt learning.", "Doi": "10.1109/LSP.2023.3298532", "Key Words": ["adversarial regularization", "continual learning", "fine-tuning", "self-supervised pretrained model", "voice pathology detection", "wav2vec 2.0"]}
{"Title": "Data-Augmentation-Based Federated Learning", "Doi": "10.1109/JIOT.2023.3303889", "Authors": ["h. zhang", "q. hou", "t. wu", "s. cheng", "j. liu"], "Key Words": ["data augmentation", "data heterogeneity", "edge computing", "federated learning (fl)", "neighborhood expansion"], "Abstract": "with the rapid growth of the number of devices generating and collecting data dispersion becomes an important feature of data in internet of things. federated learning  fl  provides a feasible way to mine information in such distributed data. it involves training machine learning models over multiple distributed participants without raw data transmission. however due to the data heterogeneity among participants the performance of the fl model degrades dramatically. currently improved methods mainly reduce data heterogeneity from the perspective of modifying the process of model training which usually have problems such as high resource consumption or the need for auxiliary data. in this article we enhance fl model from another perspective focusing on data rather than model training. we reduce data heterogeneity by enhancing the trained local data to improve fl performance. specifically we propose an fl method based on data augmentation  abbreviated as fedm une  implementing the classic data augmentation method mixup in federated scenarios without transferring raw data. furthermore in order to adapt this method to regression tasks we first modify mixup by bilateral neighborhood expansion  mixup bne  and then propose a federated data augmentation method named fedm bne based on it. compared with the conventional fl method both fedm une and fedm bne increase negligible overhead. to demonstrate the effectiveness we conduct exhaustive experiments on six data sets employing a variety of loss functions. the results indicate that fedm une and fedm bne consistently improve the performance of the fl model. moreover our methods are compatible with existing fl enhancements which yield further improvements in performance.", "Pub Date": "2023-12-11"}
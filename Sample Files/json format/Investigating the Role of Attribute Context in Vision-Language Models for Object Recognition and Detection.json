{"Title": "Investigating the Role of Attribute Context in Vision-Language Models for Object Recognition and Detection", "Doi": "10.1109/WACV57701.2024.00539", "Authors": ["k. buettner", "a. kovashka"], "Key Words": ["algorithms", "vision + language and/or other modalities", "algorithms", "image recognition and understanding", "algorithms", "machine learning architectures", "formulations", "and algorithms"], "Abstract": "vision language alignment learned from image caption pairs has been shown to benefit tasks like object recognition and detection. methods are mostly evaluated in terms of how well object class names are learned but captions also contain rich attribute context that should be considered when learning object alignment. it is unclear how methods use this context in learning as well as whether models succeed when tasks require attribute and object understanding. to address this gap we conduct extensive analysis of the role of attributes in vision language models. we specifically measure model sensitivity to the presence and meaning of attribute context gauging influence on object embeddings through unsupervised phrase grounding and classification via description methods. we further evaluate the utility of attribute context in training for open vocabulary object detection fine grained text region retrieval and attribution tasks. our results show that attribute context can be wasted when learning alignment for detection attribute meaning is not adequately considered in embeddings and describing classes by only their attributes is ineffective. a viable strategy that we find to increase benefits from attributes is contrastive training with adjective based negative captions.", "Pub Date": "2024-04-09"}
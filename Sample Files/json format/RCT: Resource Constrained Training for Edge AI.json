{"Title": "RCT: Resource Constrained Training for Edge AI", "Doi": "10.1109/TNNLS.2022.3190451", "Authors": ["t. huang", "t. luo", "m. yan", "j. t. zhou", "r. goh"], "Key Words": ["efficient training", "memory efficient", "neural network", "quantization", "weight update"], "Abstract": "efficient neural network training is essential for in situ training of edge artificial intelligence  artificial intelliegence  and carbon footprint reduction in general. train neural network on the edge is challenging because there is a large gap between limited resources on edge and the resource requirement of current training methods. existing training methods are based on the assumption that the underlying computing infrastructure has sufficient memory and energy supplies. these methods involve two copies of the model parameters which is usually beyond the capacity of on chip memory in processors. the data movement between off chip and on chip memory incurs large amounts of energy. we propose resource constrained training  rct  to realize resource efficient training for edge devices and servers. rct only keeps a quantized model throughout the training so that the memory requirement for model parameters in training is reduced. it adjusts per layer bitwidth dynamically to save energy when a model can learn effectively with lower precision. we carry out experiments with representative models and tasks in image classification natural language processing and crowd counting applications. experiments show that on average 8\u201a\u00e4\u00ec15 bit weight update is sufficient for achieving sota performance in these applications. rct saves 63.5%\u201a\u00e4\u00ec80% memory for model parameters and saves more energy for communications. through experiments we observe that the common practice on the first last layer in model compression does not apply to efficient training. also interestingly the more challenging a dataset is the lower bitwidth is required for efficient training.", "Pub Date": "2024-02-05"}
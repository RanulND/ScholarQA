{"Title": "Automated Domain Modeling with Large Language Models: A Comparative Study", "Doi": "10.1109/MODELS58315.2023.00037", "Authors": ["k. chen", "y. yang", "b. chen", "j. a. hern\u221a\u00b0ndez l\u221a\u2265pez", "g. mussbacher", "d. varr\u221a\u2265"], "Key Words": ["domain modeling", "large language models", "few-shot learning", "chain-of-thought prompting", "prompt engineering"], "Abstract": "domain modeling is an essential part of software engineering and serves as a way to represent and understand the concepts and relationships in a problem domain. typically software engineers interpret the problem description written in natural language and manually translate it into a domain model. domain modeling can be time consuming and highly depends on the expertise of software engineers. recently large language models  large language model  have exhibited remarkable ability in language understanding generation and reasoning. in this paper we conduct a comprehensive comparative study of using large language model for fully automated domain modeling. we assess two powerful large language model gpt3.5 and gpt4 employing various prompt engineering techniques on a data set containing ten diverse domain modeling examples with reference solutions created by modeling experts. our findings reveal that while large language model demonstrate impressive domain understanding capabilities they are still impractical for full automation with the top performing large language model achieving f1 scores of 0.76 for class generation 0.61 for attribute generation and 0.34 for relationship generation. moreover the f1 score is characterized by higher precision and lower recall  thus domain elements retrieved by large language model are often reliable but there are many missing elements. furthermore modeling best practices are rarely followed in auto generated domain models. our data set and evaluation provide a valuable baseline for future research in automated large language model based domain modeling.", "Pub Date": "2023-12-12"}
{"Title": "Dynamic QoS Prediction With Intelligent Route Estimation Via Inverse Reinforcement Learning", "Doi": "10.1109/TSC.2023.3342481", "Authors": ["j. li", "h. wu", "q. he", "y. zhao", "x. wang"], "Key Words": ["deep learning", "inverse reinforcement learning", "qos prediction", "reinforcement learning", "route estimation"], "Abstract": "dynamic quality of service  qos  measurement is crucial for discovering services and developing online service systems. collaborative filtering based approaches perform dynamic qos prediction by incorporating temporal information only but never consider the dynamic network environment and suffer from poor performance. considering different service invocation routes directly reflect the dynamic environment and further lead to qos fluctuations we coin the problem of dynamic qos prediction  dqp  with intelligent route estimation  ire  and propose a novel framework named ire4dqp. under the ire4dqp framework the dynamic environment is captured by network status representation and the ire is modeled as a markov decision process and implemented by a deep learning agent. after that the dqp is achieved by a specific neural model with the estimated route as input. through collaborative training with reinforcement and inverse reinforcement learning eventually based on the updated representations of the network status ire learns an optimal route policy that matches well with observed qos values and dqp achieves accurate predictions. experimental results demonstrate that ire4dqp outperforms sota methods on the accuracy of response time prediction by 5.79\u201a\u00e4\u00ec31.34% in mae by 1.29\u201a\u00e4\u00ec20.18% in rmse and by 4.43\u201a\u00e4\u00ec27.73% in nmae and with a success rate of nearly 45% on finding routes.", "Pub Date": "2024-04-09"}
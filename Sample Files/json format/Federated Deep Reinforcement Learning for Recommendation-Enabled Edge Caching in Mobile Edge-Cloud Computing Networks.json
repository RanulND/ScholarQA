{"Title": "Federated Deep Reinforcement Learning for Recommendation-Enabled Edge Caching in Mobile Edge-Cloud Computing Networks", "Doi": "10.1109/JSAC.2023.3235443", "Authors": ["c. sun", "x. li", "j. wen", "x. wang", "z. han", "v. c. m. leung"], "Key Words": ["multi-tier computing", "recommendation-enabled edge caching", "soft hits", "federated learning", "discrete soft actor-critic"], "Abstract": "to support rapidly increasing services and applications from users multi tier computing is emerged as a promising system level computing architecture by distributing computing caching/communication networking capabilities between cloud servers to users especially deploying edge servers at network edges  e.g. base stations . however due to heterogeneous content requests of users and a high cost hit manner with direct hits edge caching is still a most serious issue to be addressed. in this paper we investigate the issue of recommendation enabled edge caching in mobile two tier  edge cloud  computing networks. particularly we integrate recommender systems and edge caching to support both direct hits and soft hits and thus improve the resource utilization of edge servers. we model the factors affecting the user quality of experience as a comprehensive system cost and further formulate the problem as a multi agent markov decision process with the goal of minimizing the long term average system cost. to address the formulated problem we propose a decentralized recommendation enabled edge caching framework that leverages a discrete multi agent variant of soft actor critic and federated learning. the proposed framework enables each edge server to learn its best policy locally and generate judicious decisions independently. finally trace driven simulation results demonstrate that the proposed framework converges to a better caching policy and outperforms several existing algorithms on average system cost reduction.", "Pub Date": "2023-02-15"}
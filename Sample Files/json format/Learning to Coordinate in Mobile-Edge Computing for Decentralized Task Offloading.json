{"Title": "Learning to Coordinate in Mobile-Edge Computing for Decentralized Task Offloading", "Doi": "10.1109/JIOT.2022.3209714", "Authors": ["b. zhang", "b. tang", "f. xiao"], "Key Words": ["decentralized coordination", "mobile-edge computing (mec)", "reinforcement learning (rl)", "task offloading"], "Abstract": "edge servers which are located in close proximity to mobile users have become emerging components for computation offloading in multiple internet of things  iot  applications. as the edge resources are limited and shared among multiple mobile users it is crucial for the users to choose appropriate edge server for task offloading so that their cumulative utility can be maximized. reinforcement learning  rl  algorithms which are sequential and model free have been widely considered. however it is still a critical challenge to coordinate the mobile users in a decentralized way. in this work we propose a novel framework of multiagent rl by learning to coordinate. the main idea is to introduce an additional \u201a\u00e4\u00favirtual\u201a\u00e4\u00f9 agent at the edge which learns to broadcast public messages to the mobile users at each interval. we then enforce positive correlation between each user\u201a\u00e4\u00f4s offloading policy and the message. the underlying intuition is that the message can contain information of edge resources and other users\u201a\u00e4\u00f4 policies. therefore it is expected that the decentralized users can make coordinated decisions. theoretical analysis shows that our algorithm can converge to equilibrium points under certain mild assumptions. in the experiments our approach outperforms other baselines significantly in different scenarios. in addition the results show that the broadcast message plays a very important role in coordinating the mobile users.", "Pub Date": "2022-12-22"}
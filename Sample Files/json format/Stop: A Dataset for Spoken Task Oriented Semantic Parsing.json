{"Title": "Stop: A Dataset for Spoken Task Oriented Semantic Parsing", "Doi": "10.1109/SLT54892.2023.10022703", "Authors": ["p. tomasello", "a. shrivastava", "d. lazar", "p. -c. hsu", "d. le", "a. sagar", "a. elkahky", "j. copet", "w. -n. hsu", "y. adi", "r. algayres", "t. a. nguyen", "e. dupoux", "l. zettlemoyer", "a. mohamed"], "Key Words": ["spoken language understanding", "assistant", "domain adaptation"], "Abstract": "end to end spoken language understanding  slu  predicts intent directly from audio using a single model. it promises to improve the performance of assistant systems by leveraging acoustic information lost in the intermediate textual representation and preventing cascading errors from automatic speech recognition  asr . further having one unified model has efficiency advantages when deploying assistant systems on device. however the limited number of public audio datasets with semantic parse labels hinders the research progress in this area. in this paper we release the spoken task oriented semantic parsing  stop  dataset 1 the largest and most complex slu dataset publicly available. additionally we define low resource splits to establish a benchmark for improving slu when limited labeled data is available. furthermore in addition to the human recorded audio we are releasing a tts generated versions to benchmark the performance for low resource and domain adaptation of end to end slu systems.", "Pub Date": "2023-01-27"}
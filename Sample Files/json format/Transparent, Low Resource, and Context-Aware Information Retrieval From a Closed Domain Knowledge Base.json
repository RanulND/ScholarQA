{"Title": "Transparent, Low Resource, and Context-Aware Information Retrieval From a Closed Domain Knowledge Base", "Doi": "10.1109/ACCESS.2024.3380006", "Authors": ["s. rateria", "s. singh"], "Key Words": ["natural language processing", "conversational agent", "information retrieval", "closed domain knowledge base", "bert word movers distance"], "Abstract": "in large scale enterprises vast amounts of textual information are shared across corporate repositories and intranet websites. traditional search techniques that lack context sensitivity often fail to retrieve pertinent data efficiently. modern techniques that use a distributed representation of words require a considerable training dataset and computation thereby presenting financial and operational burdens. generative models for information search suffer from problems of transparency and hallucination which can be detrimental especially for organizations and their stakeholders who rely on these results for critical business operations. this paper presents a non goal oriented conversational agent based on a collection of finite state machines and an information search model for text search from an extensive collection of stored corporate documents and intranet websites. we used a distributed representation of words derived from the bert model which allows for contextual searching. we minimally fine tuned a bert model on a multi label text classification task specific to a closed domain knowledge base. based on dcg metrics our information retrieval model using distributed embeddings from the minimally trained bert model and word movers distance for calculating topic similarity is more relevant to user queries than bert embeddings with cosine similarity and bm25. our architecture promises to significantly expedite and improve the accuracy of information retrieval in closed domain systems without the need for a massive training dataset or expensive computing while maintaining transparency.", "Pub Date": "2024-03-28"}
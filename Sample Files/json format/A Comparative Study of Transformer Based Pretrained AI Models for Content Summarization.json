{"Title": "A Comparative Study of Transformer Based Pretrained AI Models for Content Summarization", "Doi": "10.1109/IIT59782.2023.10366411", "Authors": ["a. s. a. rasheed", "m. m. masud", "m. abduljabbar"], "Key Words": ["artificial intelligence", "transformers", "key point summarization", "natural language processing", "pretrained language models"], "Abstract": "in this study we examine different transformer based pretrained artificial intelligence  artificial intelliegence  models on their ability to summarize text content from different sources. artificial intelliegence has emerged as a powerful tool in this context offering the potential to automate and improve the process of content summarization. we mainly focus on the pretrained transformer models such as pegasus t5 bart and prophetnet for key point summarization from textual contents. we aim to assess the effectiveness of these models in summarizing different contents like articles instructions conversational dialogues and compare and analyze their performance across different datasets. we use rouge metric to evaluate the quality of the generated summaries. the facebook\u201a\u00e4\u00f4s bart model had better performance across different textual datasets. we believe that our findings will offer valuable insights into the capabilities and limitations of transformer based artificial intelliegence models in the context of extracting essential points from large articles making them useful as assistive tools for summarizing course content in educational environments.", "Pub Date": "2023-12-25"}
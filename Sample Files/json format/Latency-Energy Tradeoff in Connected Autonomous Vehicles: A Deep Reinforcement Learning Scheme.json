{"Title": "Latency-Energy Tradeoff in Connected Autonomous Vehicles: A Deep Reinforcement Learning Scheme", "Doi": "10.1109/TITS.2022.3215523", "Authors": ["i. budhiraja", "n. kumar", "h. sharma", "m. elhoseny", "y. lakys", "j. j. p. c. rodrigues"], "Key Words": ["vehicle edge computing", "soft actor-critic", "latency", "energy", "connected autonomous vehicles"], "Abstract": "vehicle edge computing  vec  assisted computational offloading brings cloud computing closer to user equipment  ues  at the edge of the access network by delivering various services to the ues with limited processing power and battery. however in fifth generation and beyond 5g  b5g  networks where ues\u201a\u00e4\u00f4 service requests and locations change dynamically the deployment of static edge server deployments may lead to an increase in latency and total energy consumption. this paper presents a latency energy aware efficient task offloading scheme for connected autonomous vehicular networks. firstly vehicles are assembled into clusters in which vehicle can transmit tasks to the other vehicle while on the other hand the vec server is used for processing the data. we developed a joint resource allocation and offloading decision optimization problem to minimize network latency and total energy usage. due to the non convex character of the optimization issue we employed the markov decision process  mdp  to convert it to a reinforcement learning  rl  problem. then we used a soft actor critic based scheme to achieve the optimal policy for resource allocation and task offloading to reduce the total latency and energy consumption for connected autonomous vehicles. simulation analysis reveals that the proposed scheme attains 46.6% and 17.2% lesser delay and 28.8% and 20.0% consumes less energy than the hybrid drl with genetic algorithm  hdrl ga  and drl based collaborative data scheduling  drl cdss  state of art schemes.", "Pub Date": "2023-11-01"}
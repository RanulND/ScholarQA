{"Title": "Uncertain about ChatGPT: enabling the uncertainty evaluation of large language models", "Doi": "10.23919/FUSION52260.2023.10224086", "Authors": ["a. -l. jousselme", "j. p. de villiers", "a. de freitas", "e. blasch", "v. dragos", "g. pavlin", "p. c. costa", "k. b. laskey", "c. laudy"], "Key Words": ["uncertainty evaluation", "ontology", "information quality", "source quality", "large language models", "nlp"], "Abstract": "chatgpt openai\u201a\u00e4\u00f4s chatbot has gained consider able attention since its launch in november 2022 owing to its ability to formulate articulated responses to text queries and comments relating to seemingly any conceivable subject. as impressive as the majority of interactions with chatgpt are this large language model has a number of acknowledged shortcomings which in several cases may be directly related to how chatgpt handles uncertainty. the objective of this paper is to pave the way to formal analysis of chatgpt uncertainty handling. to this end the ability of the uncertainty representation and reasoning framework  urref  ontology is assessed to support such analysis. elements of structured experiments for reproducible results are identified. the dataset built varies information criteria of correctness non specificity self confidence relevance and inconsistency and the source criteria of reliability competency and type. chatgpt\u201a\u00e4\u00f4s answers are analyzed along information criteria of correctness non specificity and self confidence. both generic and singular information are sequentially provided. the outcome of this preliminary study is twofold  firstly we validate that the experimental setup is efficient in capturing aspects of chatgpt uncertainty handling. secondly we identify possible modifications to the urref ontology that will be discussed and eventually implemented in urref ontology version 4.0 under development.", "Pub Date": "2023-08-25"}
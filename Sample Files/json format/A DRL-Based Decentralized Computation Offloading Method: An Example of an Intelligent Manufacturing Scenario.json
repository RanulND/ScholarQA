{"Title": "A DRL-Based Decentralized Computation Offloading Method: An Example of an Intelligent Manufacturing Scenario", "Doi": "10.1109/TII.2022.3227652", "Authors": ["s. lu", "s. liu", "y. zhu", "w. liang", "k. li", "y. lu"], "Key Words": ["computation offloading", "deep deterministic policy gradient (ddpg)", "deep reinforcement learning (drl)", "dual critic", "edge computing"], "Abstract": "with the development of edge computing and 5g the demand for resource limited devices to execute computation intensive tasks can be effectively alleviated. the research on computation offloading lays an essential foundation for realizing mobile edge computing and deep reinforcement learning  drl  has become an emerging technique to address the computation offloading problem. this article utilizes a drl based algorithm to design a decentralized computation offloading framework aimed at minimizing the computational cost. we employ a multiuser system model with a single edge server suitable for industrial scenarios. then we propose a dual critic deep deterministic policy gradient  dc ddpg  algorithm based on the deep deterministic policy gradient  ddpg  algorithm to tackle computation offloading and resource allocation problems for all users. dc ddpg adopts two critic nets in both the primary and target nets to fit the action value of two different optimization objectives which expedites the convergence during the training process and reduces the computational cost of the edge computation system during operation. compared with other drl methods such as deep q network and ddpg numerical results demonstrate that the proposed dc ddpg algorithm has a faster convergence speed and performs significantly better than other drl based algorithms in terms of system computational cost in computing intensive tasks which makes it more suitable for industrial intelligent manufacturing scenarios with large data volume.", "Pub Date": "2023-07-24"}
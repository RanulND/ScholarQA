{"Title": "Sa-Paraformer: Non-Autoregressive End-To-End Speaker-Attributed ASR", "Doi": "10.1109/ASRU57964.2023.10389762", "Authors": ["y. li", "f. yu", "y. liang", "p. guo", "m. shi", "z. du", "s. zhang", "l. xie"], "Key Words": ["speaker-attributed asr", "non-autoregressive", "multi-speaker asr", "alimeeting"], "Abstract": "joint modeling of multi speaker asr and speaker diarization has recently shown promising results in speaker attributed automatic speech recognition  sa asr . although being able to obtain state of the art  sota  performance most of the studies are based on an autoregressive  ar  decoder which generates tokens one by one and results in a large real time factor  rtf . to speed up inference we introduce a recently proposed non autoregressive model paraformer as an acoustic model in the sa asr model. paraformer uses a single step decoder to enable parallel generation obtaining comparable performance to the sota ar transformer models. besides we propose a speaker filling strategy to reduce speaker identification errors and adopt an inter ctc strategy to enhance the encoder\u201a\u00e4\u00f4s ability in acoustic modeling. experiments on the alimeeting corpus show that our model outperforms the cascaded sa asr model by a 6.1% relative speaker dependent character error rate  sd cer  reduction on the test set. moreover our model achieves a comparable sd cer of 34.8% with only 1/10 rtf compared with the sota joint ar sa asr model.", "Pub Date": "2024-01-19"}
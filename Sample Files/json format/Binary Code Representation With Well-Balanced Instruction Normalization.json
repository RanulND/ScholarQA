{"Title": "Binary Code Representation With Well-Balanced Instruction Normalization", "Doi": "10.1109/ACCESS.2023.3259481", "Authors": ["h. koo", "s. park", "d. choi", "t. kim"], "Key Words": ["binary code", "code representation", "bert", "well-balanced instruction normalization", "binary code similarity detection"], "Abstract": "the recovery of contextual meanings on a machine code is required by a wide range of binary analysis applications such as bug discovery malware analysis and code clone detection. to accomplish this advancements on binary code analysis borrow the techniques from natural language processing to automatically infer the underlying semantics of a binary rather than replying on manual analysis. one of crucial pipelines in this process is instruction normalization which helps to reduce the number of tokens and to avoid an out of vocabulary  oov  problem. however existing approaches often substitutes the operand s  of an instruction with a common token  e. g. callee target  $\\rightarrow $  foo  inevitably resulting in the loss of important information. in this paper we introduce well balanced instruction normalization  win  a novel approach that retains rich code information while minimizing the downsides of code normalization. with large swaths of binary code our finding shows that the instruction distribution follows zipf\u201a\u00e4\u00f4s law like a natural language a function conveys contextually meaningful information and the same instruction at different positions may require diverse code representations. to show the effectiveness of win we present deep semantic that harnesses the bert architecture with two training phases  pre training for generic assembly code representation and fine tuning for building a model tailored to a specialized task. we define a downstream task of binary code similarity detection which requires underlying code semantics. our experimental results show that our binary similarity model with win outperforms two state of the art binary similarity tools deepbindiff and safe with an average improvement of 49.8% and 15.8% respectively.", "Pub Date": "2023-03-28"}
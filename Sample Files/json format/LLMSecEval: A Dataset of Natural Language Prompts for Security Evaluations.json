{"Title": "LLMSecEval: A Dataset of Natural Language Prompts for Security Evaluations", "Doi": "10.1109/MSR59073.2023.00084", "Authors": ["c. tony", "m. mutas", "n. e. d. ferreyra", "r. scandariato"], "Key Words": ["llms", "code security", "nl prompts", "cwe"], "Abstract": "large language models  llms  like codex are powerful tools for performing code completion and code generation tasks as they are trained on billions of lines of code from publicly available sources. moreover these models are capable of generating code snippets from natural language  nl  descriptions by learning languages and programming practices from public github repositories. although llms promise an effortless nl driven deployment of software applications the security of the code they generate has not been extensively investigated nor documented. in this work we present llmseceval a dataset containing 150 nl prompts that can be leveraged for assessing the security performance of such models. such prompts are nl descriptions of code snippets prone to various security vulnerabilities listed in mitre\u201a\u00e4\u00f4s top 25 common weakness enumeration  cwe  ranking. each prompt in our dataset comes with a secure implementation example to facilitate comparative evaluations against code produced by llms. as a practical application we show how llmseceval can be used for evaluating the security of snippets automatically generated from nl descriptions.", "Pub Date": "2023-07-12"}
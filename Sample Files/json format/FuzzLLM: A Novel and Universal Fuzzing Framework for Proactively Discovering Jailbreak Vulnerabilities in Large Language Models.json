{"Title": "FuzzLLM: A Novel and Universal Fuzzing Framework for Proactively Discovering Jailbreak Vulnerabilities in Large Language Models", "Doi": "10.1109/ICASSP48485.2024.10448041", "Authors": ["d. yao", "j. zhang", "i. g. harris", "m. carlsson"], "Key Words": ["large language model", "jailbreak vulnerability", "automated fuzzing"], "Abstract": "jailbreak vulnerabilities in large language models  large language model  which exploit meticulously crafted prompts to elicit content that violates service guidelines have captured the attention of research communities. while model owners can defend against individual jailbreak prompts through safety training strategies this relatively passive approach struggles to handle the broader category of similar jailbreaks. to tackle this issue we introduce fuzzllm an automated fuzzing framework designed to proactively test and discover jailbreak vulnerabilities in large language model. we utilize templates to capture the structural integrity of a prompt and isolate key features of a jailbreak class as constraints. by integrating different base classes into powerful combo attacks and varying the elements of constraints and prohibited questions fuzzllm enables efficient testing with reduced manual effort. extensive experiments demonstrate fuzzllm\u201a\u00e4\u00f4s effectiveness and comprehensiveness in vulnerability discovery across various large language model.", "Pub Date": "2024-03-18"}
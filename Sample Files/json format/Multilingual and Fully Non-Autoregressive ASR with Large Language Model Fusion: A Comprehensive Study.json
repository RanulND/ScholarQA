{"Title": "Multilingual and Fully Non-Autoregressive ASR with Large Language Model Fusion: A Comprehensive Study", "Doi": "10.1109/ICASSP48485.2024.10448361", "Authors": ["w. ronny huang", "c. allauzen", "t. chen", "k. gupta", "k. hu", "j. qin", "y. zhang", "y. wang", "s. -y. chang", "t. n. sainath"], "Key Words": ["large language model", "multilingual speech recognition"], "Abstract": "in the era of large models the autoregressive nature of decoding often results in latency serving as a significant bottleneck. we propose a non autoregressive lm fused asr system that effectively leverages the parallelization capabilities of accelerator hardware. our approach combines the universal speech model  usm  and the palm 2 language model in per segment scoring mode achieving an average relative wer improvement across all languages of 10.8% on fleurs and 3.6% on youtube captioning. furthermore our comprehensive ablation study analyzes key parameters such as large language model size context length vocabulary size fusion methodology. for instance we explore the impact of large language model size ranging from 128m to 340b parameters on asr performance. this study provides valuable insights into the factors influencing the effectiveness of practical large scale lm fused speech recognition systems.", "Pub Date": "2024-03-18"}
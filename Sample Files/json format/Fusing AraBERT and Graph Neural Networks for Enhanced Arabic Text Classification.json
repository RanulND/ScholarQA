{"Title": "Fusing AraBERT and Graph Neural Networks for Enhanced Arabic Text Classification", "Doi": "10.1109/ACIT58888.2023.10453909", "Authors": ["o. karajeh", "m. n. al-kabi", "e. a. fox"], "Key Words": ["graph convolutional networks", "arabic text classification", "arabert-gcn"], "Abstract": "text classification is a fundamental task in natural language processing and has been widely studied for various languages. however arabic text classification is challenging due to the complexity of arabic  i.e. rich morphological structure  high degree of ambiguity and optional diacritics in the writing system. large scale pre trained contextualized models  e.g. arabert  can successfully capture semantics in the local context. on the other hand graph based models could capture the global context by incorporating long distance semantics. a text classification model combining the local and global context can enhance classifier performance for highly complex and ambiguous languages. in this work we introduce the arabic bert graph convolutional network  arabert gcn  that can leverage the advantage of using large scale pre trained models alongside graph convolutional networks. experimental results show that arabert gcn outperforms the state of the art  sota  on our arabic text datasets.", "Pub Date": "2024-03-18"}
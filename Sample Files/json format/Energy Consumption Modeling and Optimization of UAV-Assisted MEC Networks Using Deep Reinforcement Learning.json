{"Title": "Energy Consumption Modeling and Optimization of UAV-Assisted MEC Networks Using Deep Reinforcement Learning", "Doi": "10.1109/JSEN.2024.3370924", "Authors": ["m. yan", "l. zhang", "w. jiang", "c. a. chan", "a. f. gygax", "a. nirmalathas"], "Key Words": ["cooperation strategy", "deep reinforcement learning (drl)", "energy consumption", "multiaccess edge computing (mec)"], "Abstract": "unmanned aerial vehicle  uav  assisted multiaccess edge computing  mec  technology has garnered significant attention and has been successfully implemented in specific scenarios. the optimization of the network energy consumption in the relevant scenarios is essential for the whole system performance due to the constrained energy capacity of uavs. however the dynamic changes in mec network resources make energy consumption optimization a challenge. in this article a multi uav multiuser mec model is established to assess the system energy consumption and the optimization problem of multi uav cooperation strategies is formulated based on the model. then a multiagent deep deterministic policy gradient  maddpg  algorithm based on deep reinforcement learning  drl  is employed to resolve the above optimization problem. each uav is equivalent to a single agent that cooperates with other agents to train actors and critic evaluation networks to accomplish collaborative decision making. in addition a prioritized experience replay  per  scheme is used to improve the convergence of the training process. simulation results show the impact of changes in different network resources on the network energy consumption by comparing the performance of different algorithms. the findings presented in this article serve as a valuable reference for future work on system performance optimization specifically in terms of energy efficiency.", "Pub Date": "2024-04-15"}
{"Title": "Multilingual Program Code Classification Using $n$-Layered Bi-LSTM Model With Optimized Hyperparameters", "Doi": "10.1109/TETCI.2023.3336920", "Authors": ["m. m. rahman", "y. watanobe"], "Key Words": ["multilingual program code", "code classification", "bidirectional lstm (bi-lstm)", "layered bi-lstm", "programming learning"], "Abstract": "programmers are allowed to solve problems using multiple programming languages resulting in the accumulation of a huge number of multilingual solution codes. consequently identifying codes from this vast archive of multilingual codes is a challenging and non trivial task. considering the codes' complexity compared to natural languages conventional language models have had limited success. deep neural network models have achieved state of the art performance in programming related tasks. however the multilingual code classification based on the problem name or algorithm remains an open problem. this paper presents a novel multilingual program code classification model for the code classification task based on algorithms and problem names. first a layered bidirectional long short term memory model is designed to better understand the complex code context. second preprocessing tokenization and encoding processes are performed on real life datasets. next clean and trainable formatted data are prepared. finally experiments are conducted on real life datasets  e.g. sorting searching graphs and trees numerical computations basic data structures and their combinations  with optimized hyperparameter settings. the results show that the proposed model can effectively improve the code classification accuracy compared to other baseline models.", "Pub Date": "2024-03-27"}
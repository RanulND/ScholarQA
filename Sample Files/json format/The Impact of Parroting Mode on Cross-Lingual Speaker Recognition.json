{"Title": "The Impact of Parroting Mode on Cross-Lingual Speaker Recognition", "Doi": "10.1109/ISM59092.2023.00035", "Authors": ["w. -h. liao", "y. -c. ou", "p. -h. chen", "y. -c. wu"], "Key Words": ["text-independent speaker recognition", "cross-lingual dataset", "deep-learning", "audio embedding", "parroting mode"], "Abstract": "people use multiple languages in their daily lives across regions worldwide which motivated us to investigate cross lingual speaker recognition. in this work we propose to collect recordings of mandarin and spanish namely the mandarin spanish speech dataset  mssd 40  to analyze the performance of various audio embeddings for cross lingual speaker recognition tasks. all participants are fluent in mandarin but none of the participants have prior knowledge of the spanish language. as such they have been advised to adopt a parroting mode of spanish speech production wherein they simply repeat the sounds emanating from the loudspeaker. using this approach variations resulting from individual differences in language fluency can be reduced enabling us to focus on the anatomical aspects of the speech production mechanism.embeddings extracted from models pre trained with a large number of audio segments have become effective solutions for coping with audio analysis tasks using small datasets. preliminary experimental results using two collected multi lingual datasets indicate that both embedding methods and the language employed will affect the robustness of the speaker recognition task. precisely stable performance is observed when familiar languages are used. beats embedding generates the best outcome in all languages when no fine tuning is exercised.", "Pub Date": "2024-03-20"}
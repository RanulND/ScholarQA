{"Title": "Toward a Virtual Edge Service Provider: Actor-Critic Learning to Incentivize the Computation Nodes", "Doi": "10.1109/TNSE.2023.3283410", "Authors": ["m. cheraghinia", "s. h. rastegar", "v. shah-mansouri", "h. kebriaei", "k. zhu", "d. niyato"], "Key Words": ["computation offloading", "deep reinforcement learning (drl)", "incentive mechanism", "soft actor-critic (sac)", "stackelberg game", "virtual edge service provider"], "Abstract": "the growing development of computation intensive applications has considerably increased the demand for computing resources in the network. many of these applications require computations with low delays. edge computing which offers computing resources at the edge of the network is a prominent solution. however an edge service provider might not have sufficient resources at the edge to satisfy the demands of its users. computation offloading can fill the gap by letting the service provider transfer the users' computational tasks to other computation nodes  cns . nevertheless due to the imposed costs cns are not always interested in sharing their computation capacity. this article considers the concept of a virtual edge service provider and studies an incentive mechanism to motivate the cns to share their resources. we formulate the problem as a stackelberg game and present a complete information analysis. we prove the existence and uniqueness of the game equilibriums. however the complete information scenario is not accessible in practice due to privacy reasons. therefore we propose a soft actor critic algorithm as an incomplete information method using deep reinforcement learning. finally through extensive numerical evaluations we show that the incomplete information method converges to the same equilibrium that the complete information analysis proved.", "Pub Date": "2024-01-05"}
{"Title": "ConZIC: Controllable Zero-shot Image Captioning by Sampling-Based Polishing", "Doi": "10.1109/CVPR52729.2023.02247", "Authors": ["z. zeng", "h. zhang", "r. lu", "d. wang", "b. chen", "z. wang"], "Key Words": ["vision", "language", "reasoning"], "Abstract": "zero shot capability has been considered as a new revolution of deep learning letting machines work on tasks without curated training data. as a good start and the only existing outcome of zero shot image captioning  ic  zerocap abandons supervised training and sequentially searches every word in the caption using the knowledge of large scale pre trained models. though effective its autoregressive generation and gradient directed searching mechanism limit the diversity of captions and inference speed respectively. moreover zerocap does not consider the controllability issue of zero shot ic. to move forward we propose a framework for controllable zero shot ic named conzic. the core of conzic is a novel sampling based non autoregressive language model named gibbs bert which can generate and continuously polish every word. extensive quantitative and qualitative results demonstrate the superior performance of our proposed conzic for both zero shot ic and controllable zero shot ic. especially conzic achieves about $5\\times$ generation speed than zerocap and about $1.5\\times$ diversity scores with accurate generation given different control signals. our code is available at https //github.com joeyz0z conzic.", "Pub Date": "2023-08-22"}
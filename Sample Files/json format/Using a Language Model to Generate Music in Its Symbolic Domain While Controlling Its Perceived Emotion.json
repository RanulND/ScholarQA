{"Title": "Using a Language Model to Generate Music in Its Symbolic Domain While Controlling Its Perceived Emotion", "Doi": "10.1109/ACCESS.2023.3280603", "Authors": ["n. imasato", "k. miyazawa", "c. duncan", "t. nagai"], "Key Words": ["ai music composition", "controlled music generation", "deep learning", "language model", "autoregressive model"], "Abstract": "this work proposes a transformer based model capable of generating music in its symbolic domain in a controllable fashion. the ultimate goal of this is to build a system with which people can compose music collaboratively with a computer. using an nlp model as a base  gpt 2  we take advantage of the similarities across symbolic music representation and written language to build a model capable of conditionally predicting musical sequences. controllability is achieved without explicit programming for it and does not require extensive retraining of the model. a study with 939 participants was performed to evaluate this controllability. the results of this suggest the proposed method is indeed effective and can be used to control the generation of music in its symbolic domain. the method itself is flexible to any desired \u201a\u00e4\u00facontrol\u201a\u00e4\u00f9 but this work focuses specifically on the emotion conveyed when one listens to a piece of music.", "Pub Date": "2023-06-05"}
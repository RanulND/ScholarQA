{"Title": "FLAG3D: A 3D Fitness Activity Dataset with Language Instruction", "Doi": "10.1109/CVPR52729.2023.02117", "Authors": ["y. tang", "j. liu", "a. liu", "b. yang", "w. dai", "y. rao", "j. lu", "j. zhou", "x. li"], "Key Words": ["video: action and event understanding"], "Abstract": "with the continuously thriving popularity around the world fitness activity analytic has become an emerging research topic in computer vision. while a variety of new tasks and algorithms have been proposed recently there are growing hunger for data resources involved in high quality data fine grained labels and diverse environments. in this paper we present flag3d a large scale 3d fitness activity dataset with language instruction containing 180k sequences of 60 categories. flag3d features the following three aspects  1  accurate and dense 3d human pose captured from advanced mocap system to handle the complex activity and large movement 2  detailed and professional language instruction to describe how to perform a specific activity 3  versatile video resources from a high tech mocap system rendering software and cost effective smartphones in natural environments. extensive experiments and in depth analysis show that flag3d contributes great research value for various challenges such as cross domain human action recognition dynamic human mesh recovery and language guided human action generation. our dataset and source code are publicly available at https //andytang15.github.io flag3d.", "Pub Date": "2023-08-22"}
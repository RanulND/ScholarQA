{"Title": "Can AI Keep You Safe? A Study of Large Language Models for Phishing Detection", "Doi": "10.1109/CCWC60891.2024.10427626", "Authors": ["r. chataut", "p. k. gyawali", "y. usman"], "Key Words": ["artificial intelligence", "chatgpt", "llms", "phishing attacks", "security"], "Abstract": "phishing attacks continue to be a pervasive challenge in cybersecurity with threat actors constantly developing new strategies to penetrate email inboxes and compromise sensitive data. in this study we investigate the effectiveness of large language models  llms  in the crucial task of phishing email detection. with the growing sophistication of these attacks we assess the performance of three distinct llms  gpt 3.5 gpt 4 and a customized chatgpt against a carefully curated dataset containing both phishing and legitimate emails. our research reveals the proficiency of llms in identifying phishing emails with each model showing varying levels of success. the paper outlines the strengths and limitations of gpt 3.5 gpt 4 and the custom chatgpt illuminating their respective suitability for practical applications in email security. these results underscore the potential of llms in effectively identifying phishing emails and their significant implications for enhancing cybersecurity measures and safeguarding users from the risks of online fraud.", "Pub Date": "2024-02-13"}
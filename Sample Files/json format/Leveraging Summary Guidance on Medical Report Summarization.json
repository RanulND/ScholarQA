{"Title": "Leveraging Summary Guidance on Medical Report Summarization", "Doi": "10.1109/JBHI.2023.3304376", "Authors": ["y. zhu", "x. yang", "y. wu", "w. zhang"], "Key Words": ["medical report summarization", "abstractive summarization", "summary guidance", "sequence-to-sequence"], "Abstract": "this study presents three deidentified large medical text datasets named discharge echo and radiology which contain 50 k 16 k and 378 k pairs of report and summary that are derived from mimic iii respectively. we implement convincing baselines of automated abstractive summarization on the created datasets with pre trained encoder decoder language models including bert2bert bertshare robertashare pegasus prophetnet t5 large bart and gsum. further based on the bart model we leverage the sampled summaries from the training set as prior knowledge guidance for encoding additional contextual representations of the guidance with the encoder and enhancing the decoding representations in the decoder. the experimental results confirm the improvement of rouge scores and bertscore made by the proposed method.", "Pub Date": "2023-10-05"}
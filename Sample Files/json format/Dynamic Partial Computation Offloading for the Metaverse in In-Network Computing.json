{"Title": "Dynamic Partial Computation Offloading for the Metaverse in In-Network Computing", "Doi": "10.1109/ACCESS.2023.3344817", "Authors": ["i. aliyu", "s. oh", "n. ko", "t. -w. um", "j. kim"], "Key Words": ["computational offloading", "deep reinforcement learning", "game theory", "in-network computing", "metaverse"], "Abstract": "the computing in the network  coin  paradigm is a promising solution that leverages unused network resources to perform tasks to meet computation demanding applications such as the metaverse. in this vein we consider the partial computation offloading problem in the metaverse for multiple subtasks in a coin environment to minimize energy consumption and delay while dynamically adjusting the offloading policy based on the changing computational resource status. the problem is np hard and we transform it into two subproblems  the task splitting problem  tsp  on the user side and the task offloading problem  top  on the coin side. we model the tsp as an ordinal potential game and propose a decentralized algorithm to obtain its nash equilibrium  ne . then we model the top as a markov decision process and propose the double deep q network  ddqn  to solve for the optimal offloading policy. unlike the conventional ddqn algorithm where intelligent agents sample offloading decisions randomly within a certain probability the coin agent explores the ne of the tsp and the deep neural network. finally the simulation results reveal that the proposed model approach allows the coin agent to update its policies and make more informed decisions leading to improved performance over time compared to the traditional baseline.", "Pub Date": "2024-01-25"}
{"Title": "Multimodal Integration, Fine Tuning of Large Language Model for Autism Support", "Doi": "10.1109/ICMCSI61536.2024.00099", "Authors": ["k. pai", "v. jagwani", "s. pandita", "d. kalbande"], "Key Words": ["large language models", "machine learning", "autism spectrum disorder", "gpt", "fine-tuning", "image recognition", "natural language processing", "human-computer interaction", "low rank adaptation", "interaction monitoring"], "Abstract": "this research project centres on creating an inclusive environment for the specially abled. created an app that integrates real time object detection and speech to text capabilities which provides a multi modal user experience with the pre trained model. incorporated parameter efficient fine tuning using low rank adaptation  lora  to emulate the behaviour of an autism counsellor.the second module of the research employs yolov5 and machine learning to analyze therapy videos to get interaction timestamps and statistical insights. it automates the identification of interactions and serves as a valuable aid to guardians and therapists.this paper details the methodology for real time object detection using yolo ssd mobilenet and enhances understanding in the context of adaptation of language models for a particular use case. furthermore dives deeper into the intricacies of interaction monitoring using bounding boxes in yolo.by pushing the boundaries of large language model capabilities this research not only refines language models but also lays the foundation for their application in dynamic contexts of the real world exemplifying their revolutionary potential.", "Pub Date": "2024-04-11"}
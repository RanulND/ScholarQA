{"Title": "A 1-16b Reconfigurable 80Kb 7T SRAM-Based Digital Near-Memory Computing Macro for Processing Neural Networks", "Doi": "10.1109/TCSI.2022.3232648", "Authors": ["h. kim", "j. mu", "c. yu", "t. t. -h. kim", "b. kim"], "Key Words": ["sram", "vector matrix multiplication", "multiply-and-accumulate", "pim", "cim", "digital near-memory computing"], "Abstract": "this work introduces a digital sram based near memory compute macro for dnn inference improving on chip weight memory capacity and area efficiency compared to state of the art digital computing in memory  cim  macros. a  $20\\times 256.1$  16b reconfigurable digital computing near memory  nm  macro is proposed supporting a reconfigurable 1 16b precision through the bit serial computing scheme and the weight and input gating architecture for sparsity aware operations. each reconfigurable column mac comprises  $16\\times $  custom designed 7t sram bitcells to store 1 16b weights a conventional 6t sram for zero weight skip control a bitwise multiplier and a full adder with a register for partial sum accumulations.  $20\\times $  parallel partial sum outputs are post accumulated to generate a sub partitioned output feature map which will be concatenated to produce the final convolution result. besides pipelined array structure improves the throughput of the proposed macro. the proposed near memory computing macro implements an 80kb binary weight storage in a 0.473mm2 die area using 65nm. it presents the area energy efficiency of 4329 270.6 gops mm2 and 315.07 1.23tops w at 1 16b precision.", "Pub Date": "2023-03-31"}
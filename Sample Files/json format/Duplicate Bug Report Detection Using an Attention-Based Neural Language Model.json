{"Title": "Duplicate Bug Report Detection Using an Attention-Based Neural Language Model", "Doi": "10.1109/TR.2022.3193645", "Authors": ["m. b. messaoud", "a. miladi", "i. jenhani", "m. w. mkaouer", "l. ghadhab"], "Key Words": ["bidirectional encoder representations from ransformers (bert)", "deep learning", "duplicate bug report", "pretrained neural language model"], "Abstract": "context  users and developers use bug tracking systems to report errors that occur during the development and testing of software. the manual identification of duplicates is a tedious task especially with software that have large bug repositories. in this context their automatic detection becomes a necessary task that can help prevent frequently fixing the same bug. objective  in this article we propose bert mlp a novel pretrained language model using bidirectional encoder representations from ransformers  bert  for duplicate bug report detection  dbrd  with the aim of improving the detection rate compared to existing works. method  our approach considers only unstructured data. these are fed into the bert model in order to learn the contextual relationships between words. the output is fed into a multilayer perceptron  mlp  classifier representing our base dbrd. results  our approach was evaluated on three projects  mozilla firefox eclipse platform and thunderbird. it achieved an accuracy of 92.11 94.08 and 89.03% respectively for mozilla eclipse and thunderbird. a comparison with a dual channel convolutional neural network  dc cnn  model and other pretrained models including roberta and sentence bert has been conducted. results showed that bert mlp outperformed the second best performing models  dc cnn and sentence bert  by 12% in accuracy for eclipse and 9% for both mozilla and thunderbird respectively.", "Pub Date": "2023-06-01"}
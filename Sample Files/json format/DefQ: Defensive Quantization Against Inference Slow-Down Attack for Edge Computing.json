{"Title": "DefQ: Defensive Quantization Against Inference Slow-Down Attack for Edge Computing", "Doi": "10.1109/JIOT.2021.3138935", "Authors": ["h. qiu", "t. zhang", "t. zhang", "h. li", "m. qiu"], "Key Words": ["deep learning (dl)", "edge computing", "inference slow-down", "security"], "Abstract": "the novel multiexit deep neural network  dnn  architectures provide a new optimization solution for efficient model inference in edge systems. inference of most samples can be completed within the first few layers on an edge device without the need to transmit them to a remote server. this can significantly increase the inference speed and system throughput which is particularly beneficial to the resource constrained scenarios. unfortunately researchers proposed an inference slow down attack against this technique where an external adversary can add imperceptible perturbations on clean samples to invalidate the multiexit mechanism. in this article we propose a defensive quantization  defq  method as the first defense against the inference slow down attack. it is designed to be lightweight and can be easily implemented in off the shelf camera sensors. particularly defq introduces a novel quantization operation to preprocess the input images. it is capable of removing the perturbations from the malicious samples and preserving the correct inference exit points and prediction accuracy. meanwhile it has little impact on the clean samples. extensive evaluations show that defq can effectively defeat the inference slow down attack and well protect the efficiency of edge systems.", "Pub Date": "2023-02-06"}
{"Title": "GFNet: Global Filter Networks for Visual Recognition", "Doi": "10.1109/TPAMI.2023.3263824", "Authors": ["y. rao", "w. zhao", "z. zhu", "j. zhou", "j. lu"], "Key Words": ["image classification", "object detection", "representation learning", "semantic segmentation"], "Abstract": "recent advances in self attention and pure multi layer perceptrons  mlp  models for vision have shown great potential in achieving promising performance with fewer inductive biases. these models are generally based on learning interaction among spatial locations from raw data. the complexity of self attention and mlp grows quadratically as the image size increases which makes these models hard to scale up when high resolution features are required. in this paper we present the global filter network  gfnet  a conceptually simple yet computationally efficient architecture that learns long term spatial dependencies in the frequency domain with log linear complexity. our architecture replaces the self attention layer in vision transformers with three key operations  a 2d discrete fourier transform an element wise multiplication between frequency domain features and learnable global filters and a 2d inverse fourier transform. based on this basic design we develop a series of isotropic models with a transformer style simple architecture and cnn style hierarchical models with better performance. isotropic gfnet models exhibit favorable accuracy complexity trade offs compared to recent vision transformers and pure mlp models. hierarchical gfnet models can inherit successful designs in cnns and be easily scaled up with larger model sizes and more training data showing strong performance on both image classification  e.g. 85.0% top 1 accuracy on imagenet 1 k without any extra data or supervision and 87.4% accuracy with imagenet 21 k pre training  and dense prediction tasks  e.g. 54.3 miou on ade20 k val . our results demonstrate that gfnet can be a very competitive alternative to transformer based models and cnns in terms of efficiency generalization ability and robustness. code is available at https //github.com raoyongming/gfnet.", "Pub Date": "2023-08-07"}
{"Title": "Advancing Abstractive Bangla Text Summarization: A Deep Learning Approach Using Seq2seq Encoder- Decoder Model and T5 Transformer", "Doi": "10.1109/STI59863.2023.10464712", "Authors": ["s. m. tasnimul hasan", "m. a. rahman", "m. m. hasan", "m. r. hasan", "m. m. hoque"], "Key Words": ["abstractive summarization", "seq2seq", "encoder decoder", "t5 transformer", "bangla text", "bert", "rouge"], "Abstract": "text summarization plays a vital role in distilling essential information from large volumes of text. while significant progress has been made in english text summarization using deep learning techniques the research on bangla text summarization remains limited with most existing methods relying on non deep learning approaches. this study addresses the scarcity of abstractive bangla text summarization methods by conducting a comprehensive analysis using two deep learning models  sequence to sequence  se q2se q  encoder decoder model and t5 transformer. through evaluation using bert and rouge scores on the aust nlp research dataset and standard bnlpc datasets this study reveals the seq2seq model superior performance in generating coherent abstractive summaries. according to the investigation findings the average f1 score is 0.8551 with average precision and recall of 0.8527 and 0.8578 respectively determined through bert score evaluations.", "Pub Date": "2024-03-25"}
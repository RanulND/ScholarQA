{"Title": "Asynchronous Deep Reinforcement Learning for Collaborative Task Computing and On-Demand Resource Allocation in Vehicular Edge Computing", "Doi": "10.1109/TITS.2023.3249745", "Authors": ["l. liu", "j. feng", "x. mu", "q. pei", "d. lan", "m. xiao"], "Key Words": ["vehicular edge computing", "collaborative computing", "on-demand allocation", "asynchronous deep reinforcement learning"], "Abstract": "vehicular edge computing  vec  is enjoying a surge in research interest due to the remarkable potential to reduce response delay and alleviate bandwidth pressure. facing the ever growing service applications in vec how to effectively aggregate and flexibly schedule ubiquitous network resources for implementing diverse tasks and meeting differentiated demands from numerous vehicular users remains haunting. toward this end we investigate collaborative task computing and on demand resource allocation. the collaborative computing framework in vec is provided to support deep collaboration and intelligent management of heterogeneous resources widely distributed in vehicles edge servers and cloud. based on this framework the joint optimization problem of distributed task offloading and multi resource management is formulated with the aim to maximize the system utility by making the optimal task and resource scheduling policy the novelty of which lies in the exploration of available vehicle resources and the consideration of service migration. in view of the dynamics randomness and time variant of vehicular networks the asynchronous deep reinforcement algorithm is leveraged to find the optimal solution. extensive simulation experiments are implemented to demonstrate the superiority of our proposed algorithm in terms of response latency compared with full offloading and random offloading.", "Pub Date": "2023-12-01"}
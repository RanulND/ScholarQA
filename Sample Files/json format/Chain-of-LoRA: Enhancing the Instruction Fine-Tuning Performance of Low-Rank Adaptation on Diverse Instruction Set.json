{"Title": "Chain-of-LoRA: Enhancing the Instruction Fine-Tuning Performance of Low-Rank Adaptation on Diverse Instruction Set", "Doi": "10.1109/LSP.2024.3377590", "Authors": ["x. qiu", "t. hao", "s. shi", "x. tan", "y. -j. xiong"], "Key Words": ["large language models", "low-rank adaptation", "instruction fine-tuning"], "Abstract": "recently large language models  large language model  with conversational style interaction such as chatgpt and claude have gained significant importance in the advancement of artificial general intelligence  agi . however the extensive resource requirements during pre training instruction fine tuning  if  and reinforcement learning through human feedback  rlhf  pose challenges particularly for individuals and studios with limited resources. moreover sensitive data that cannot be deployed on remote training platforms or queried through application programming interface further exacerbates this issue. to address these limitations researchers have introduced a parameter efficient framework called low rank adaptation  lora  for if on large language model. however training individual lora networks faces capacity constraints and struggles to adapt to large domains with significant distributional shifts across different tasks. in this letter we propose a novel framework called chain of lora to enhance the if performance of lora. our approach involves training a lora network to classify the instruction type and then utilizing task specific lora networks to accomplish the respective tasks. by training multiple task specific lora networks we exploit a trade off between performance and disk storage leveraging the easily expandable and cost effective nature of disk storage compared to precious graphical resources. our experimental results demonstrate that our proposed framework achieves comparable performance to typical direct if on large language model.", "Pub Date": "2024-03-27"}
{"Title": "Learning Approximate Execution Semantics From Traces for Binary Function Similarity", "Doi": "10.1109/TSE.2022.3231621", "Authors": ["k. pei", "z. xuan", "j. yang", "s. jana", "b. ray"], "Key Words": ["binary analysis", "large language models", "software security"], "Abstract": "detecting semantically similar binary functions \u201a\u00e4\u00ec a crucial capability with broad security usages including vulnerability detection malware analysis and forensics \u201a\u00e4\u00ec requires understanding function behaviors and intentions. this task is challenging as semantically similar functions can be compiled to run on different architectures and with diverse compiler optimizations or obfuscations. most existing approaches match functions based on syntactic features without understanding the functions\u201a\u00e4\u00f4 execution semantics. we present trex a transfer learning based framework to automate learning approximate execution semantics explicitly from functions\u201a\u00e4\u00f4 traces collected via forced execution  i.e. by violating the control flow semantics  and transfer the learned knowledge to match semantically similar functions. while it is known that forced execution traces are too imprecise to be directly used to detect semantic similarity our key insight is that these traces can instead be used to teach an ml model approximate execution semantics of diverse instructions and their compositions. we thus design a pretraining task which trains the model to learn approximate execution semantics from the two modalities  i.e. forced executed code and traces  of the function. we then finetune the pretrained model to match semantically similar functions. we evaluate trex on 1472066 functions from 13 popular software projects compiled to run on 4 architectures  x86 x64 arm and mips  and with 4 optimizations  o0 o3  and 5 obfuscations. trex outperforms the state of the art solutions by 7.8% 7.2% and 14.3% in cross architecture optimization and obfuscation function matching respectively while running 8\u221a\u00f3 faster. ablation studies suggest that the pretraining significantly boosts the function matching performance underscoring the importance of learning execution semantics. our case studies demonstrate the practical use cases of trex \u201a\u00e4\u00ec on 180 real world firmware images trex uncovers 14 vulnerabilities not disclosed by previous studies. we release the code and dataset of trex at https //github.com cumlsec/trex.", "Pub Date": "2023-04-18"}
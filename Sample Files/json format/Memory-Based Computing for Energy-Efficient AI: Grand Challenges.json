{"Title": "Memory-Based Computing for Energy-Efficient AI: Grand Challenges", "Doi": "10.1109/VLSI-SoC57769.2023.10321880", "Authors": ["f. karimzadeh", "m. imani", "b. asgari", "n. cao", "y. lin", "y. fang"], "Key Words": ["compute-in-memory", "energy-efficiency", "deep learning", "large language models"], "Abstract": "the remarkable progress in artificial intelligence  artificial intelliegence  has ushered in a new era characterized by models with billions of parameters enabling extraordinary capabilities across diverse domains. however these achievements come at a significant cost in terms of memory and energy consumption. the growing demand for computational resources raises grand challenges for the sustainable development of energy efficient artificial intelliegence systems. this paper delves into the paradigm of memory based computing as a promising avenue to address these challenges. by capitalizing on the inherent characteristics of memory and its efficient utilization memory based computing offers a novel approach to enhance artificial intelliegence performance while reducing the associated energy costs. our paper systematically analyzes the multifaceted aspects of this paradigm highlighting its potential benefits and outlining the challenges it poses. through an exploration of various methodologies architectures and algorithms we elucidate the intricate interplay between memory utilization computational efficiency and artificial intelliegence model complexity. furthermore we review the evolving area of hardware and software solutions for memory based computing underscoring their implications for achieving energy efficient artificial intelliegence systems. as artificial intelliegence continues its rapid evolution identifying the key challenges and insights presented in this paper serve as a foundational guide for researchers striving to navigate the complex field of memory based computing and its pivotal role in shaping the future of energy efficient artificial intelliegence.", "Pub Date": "2023-11-22"}
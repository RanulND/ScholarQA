{"Title": "CzeGPT-2\u201a\u00c4\u00ecTraining New Model for Czech Generative Text Processing Evaluated With the Summarization Task", "Doi": "10.1109/ACCESS.2024.3371689", "Authors": ["a. h\u221a\u00b0jek", "a. hor\u221a\u00b0k"], "Key Words": ["czech", "gpt-2", "large language model", "model evaluation", "model training", "summarization"], "Abstract": "automatic text summarization  ats  alongside neural machine translation or question answering is one of the leading tasks in natural language processing  nlp . in recent years ats has experienced significant development especially in the english nlp world. modern approaches are mainly based on the versatile transformer architecture proposed by vaswani et al. in 2017 which has revolutionized the field and was later tuned and adjusted to various needs of different tasks. non mainstream languages with czech taken as a representative on the other hand are a little bit behind these efforts and tend to use lighter or heuristic methods. with the new czegpt 2 model and abstractive summarizer we would like to take a step forward detailing the process of training a gpt-2 generative transformer model for a new language with a comprehensive evaluation of the task of czech summarization and pointing out the benefits of this approach. we also present an in depth analysis of the errors in generated summaries allowing to locate the model\u201a\u00e4\u00f4s weak spots.", "Pub Date": "2024-03-08"}
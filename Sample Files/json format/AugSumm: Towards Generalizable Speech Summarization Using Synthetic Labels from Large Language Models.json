{"Title": "AugSumm: Towards Generalizable Speech Summarization Using Synthetic Labels from Large Language Models", "Doi": "10.1109/ICASSP48485.2024.10447328", "Authors": ["j. -w. jung", "r. sharma", "w. chen", "b. raj", "s. watanabe"], "Key Words": ["speech summarization", "synthetic summary", "large language model", "data augmentation", "chatgpt"], "Abstract": "abstractive speech summarization  ssum  aims to generate humanlike summaries from speech. given variations in information captured and phrasing recordings can be summarized in multiple ways. therefore it is more reasonable to consider a probabilistic distribution of all potential summaries rather than a single summary. however conventional ssum models are mostly trained and evaluated with a single ground truth  gt  human annotated deterministic summary for every recording. generating multiple human references would be ideal to better represent the distribution statistically but is impractical because annotation is expensive. we tackle this challenge by proposing augsumm a method to leverage large language models  llms  as a proxy for human annotators to generate augmented summaries for training and evaluation. first we explore prompting strategies to generate synthetic summaries from chatgpt. we validate the quality of synthetic summaries using multiple metrics including human evaluation where we find that summaries generated using augsumm are perceived as more valid to humans. second we develop methods to utilize synthetic summaries in training and evaluation. experiments on how2 demonstrate that pre training on synthetic summaries and fine tuning on gt summaries improves rouge l by 1 point on both gt and augsumm based test sets. augsumm summaries are available at https //github.com jungjee/augsumm.", "Pub Date": "2024-03-18"}
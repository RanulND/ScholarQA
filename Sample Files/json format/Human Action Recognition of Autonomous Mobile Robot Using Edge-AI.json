{"Title": "Human Action Recognition of Autonomous Mobile Robot Using Edge-AI", "Doi": "10.1109/JSEN.2022.3225158", "Authors": ["s. -t. wang", "i. -h. li", "w. -y. wang"], "Key Words": ["autonomous mobile robot (amr)", "bidirectional long-short-term-memory (bilstm)", "edge artificial intelligence (edge ai)", "human action recognition (har)", "ros"], "Abstract": "the development of autonomous mobile robots  amrs  has brought with its requirements for intelligence and safety. human action recognition  har  within amr has become increasingly important because it provides interactive cognition between human and amr. this study presents a full architecture for edge artificial intelligence har  edge ai har  to allow amr to detect human actions in real time. the architecture consists of three parts  a human detection and tracking network a key frame extraction function and a har network. the har network is a cascade of a densenet121 and a double layer bidirectional long short term memory  dlbilstm  in which the densenet121 is a pretrained model to extract spatial features from action key frames and the dlbilstm provides a deep two directional lstm inference to classify complicated time series human actions. edge ai har undergoes two optimizations\u201a\u00e4\u00eeros distributed computation and tensorrt structure optimization\u201a\u00e4\u00eeto give a small model structure and high computational efficiency. edge ai har is demonstrated in two experiments using an amr and is demonstrated to give an average precision of 97.58% for single action recognition and around 86% for continuous action recognition.", "Pub Date": "2023-01-13"}
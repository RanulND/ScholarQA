{"Title": "Query-Focused Submodular Demonstration Selection for In-Context Learning in Large Language Models", "Doi": "10.1109/AICS60730.2023.10470628", "Authors": ["p. trust", "r. minghim"], "Key Words": ["in-context learning", "visualization", "language models", "submodular optimization", "data selection"], "Abstract": "the increase in dataset and parameter size of large language models has given rise to an emergent ability known as in context learning  icl . this approach allows models to perform tasks based on human instructions and a few demonstration examples in a prompt. icl differs from traditional fine tuning methods by enabling the adaptation of pretrained models to new tasks without modifying their core parameters or requiring gradient updates. despite its potential the intri cacies of icl particularly the methods for choosing effective demonstration examples to enhance predictive performance are not fully understood with prior research often relying on random selection. our research addresses this gap in two ways. firstly we advocate the use of query focused submodular mutual information functions for selecting demonstration examples in icl. these functions help identify examples that are both diverse and representative thereby improving few shot performance in comparison to random and zero shot baselines. our experiments validate this approach. secondly we introduce an interactive tool to explore the impact of hyperparameters on model performance. these parameters include the quantity and generation methods of demonstration examples and their influence on data manifolds and clusters. our results show that carefully chosen examples can lead to performance improvements of up to 20%. for instance in sentiment classification we observed an f1 score of 88.35% compared to 51.95% and in topic classification 90.56% versus 31.38%.", "Pub Date": "2024-03-20"}
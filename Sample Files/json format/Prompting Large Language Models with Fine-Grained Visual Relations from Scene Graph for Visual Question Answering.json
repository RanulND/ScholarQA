{"Title": "Prompting Large Language Models with Fine-Grained Visual Relations from Scene Graph for Visual Question Answering", "Doi": "10.1109/ICASSP48485.2024.10448321", "Authors": ["j. liu", "c. fang", "l. li", "b. li", "d. hu", "c. ma"], "Key Words": ["gqa", "scene graph", "visual question answering", "large language models"], "Abstract": "visual question answering  visual question answering  is a task that requires models to comprehend both questions and images. an increasing number of works are leveraging the strong reasoning capabilities of large language models  large language model  to address visual question answering. these methods typically utilize image captions as visual text description to aid large language model in comprehending images. however these captions often overlooking the relations of fine grained objects which will limit the reasoning capability of large language model. in this paper we present pfvr a modular framework that prompts large language model with fine grained visual relationships for visual question answering. pfvr primarily consists of an answer guided generation module  agg  and a question guided filtering module  qgf . the two modules can combine to extract the fine grained visual relations from scene graph which will finally serve as crucial context for large language model to comprehend the image. extensive experiments conducted on the popular visual question answering dataset gqa confirm pfvr achieves state of the art results compared to other strong visual question answering competitors demonstrating its exceptional effectiveness.", "Pub Date": "2024-03-18"}
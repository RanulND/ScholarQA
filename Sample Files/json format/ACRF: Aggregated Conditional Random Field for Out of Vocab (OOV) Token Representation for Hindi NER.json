{"Title": "ACRF: Aggregated Conditional Random Field for Out of Vocab (OOV) Token Representation for Hindi NER", "Doi": "10.1109/ACCESS.2024.3362645", "Authors": ["s. singh", "u. s. tiwary"], "Key Words": ["crf", "llm", "ner", "nlp", "transformer"], "Abstract": "named entities are random like emerging entities and complex entities. most of the large language model\u201a\u00e4\u00f4s tokenizers have fixed vocab  hence they tokenize out of vocab  oov  words into multiple sub words during tokenization. during fine tuning for any downstream task these sub words  tokens  make the named entity classification more complex since for each sub word an extra entity type is assigned for utilizing the word embedding of the sub word. this work attempts to reduce this complexity by aggregating token embeddings of each word. in this work we have applied aggregated crf  acrf  where a conditional random field  crf  is applied at the top of aggregated token embeddings for named entity prediction. aggregation is done at embeddings of all tokens generated by a tokenizer corresponding to a word. the experiment was done with two hindi datasets  hiner and hindi multiconer2 . this work showed that the acrf is better than vanilla crf  where token embeddings are not aggregated . also our result outperformed the existing best result at hiner data which was done by applying a cross entropy classification layer. further an analysis of the impact of tokenization has been conducted both generally and according to entity types for each word present in test data and the results show that acrf performed better for the words which tokenized in more than one sub words  oov  compared to vanilla crf. in addition this work conducts a comparative analysis between two transformer based models muril large and xlm roberta large and investigates how these models adopt aggregation strategy based on oov.", "Pub Date": "2024-02-15"}
{"Title": "Selective Propositional Reasoning: A Cognitive Load-Aware Strategy for Enhanced Reasoning", "Doi": "10.1109/CBASE60015.2023.10439142", "Authors": ["y. yue", "y. lei", "w. shi", "y. zhou"], "Key Words": ["large language model", "reasoning", "cognitive load", "selector", "selective propositional reasoning"], "Abstract": "large language models  llms  have made significant strides across a myriad of domains. while techniques like chain of thought have enhanced llm\u201a\u00e4\u00f4s reasoning abilities to some extent they still fall short in complex reasoning tasks. drawing parallels with human cognition there exists a concept of \"cognitive load\" that impacts our efficiency in processing information. based on this we hypothesize that llms much like humans may also be affected by cognitive load during their reasoning processes. building on this assumption we postulate that by alleviating the cognitive load llms encounter during reasoning we can augment their overall performance. to this end we introduce the selective propositional reasoning  spr  methodology which is specifically designed to mitigate this cognitive burden. our experimental results underscore the effectiveness of spr evidencing a 6% improvement in overall accuracy. additionally the proposition pair enumeration  ppe  strategy further substantiates our cognitive load hypothesis showcasing a 1.5% overall performance enhancement. collectively our findings not only emphasize the potential benefits of addressing cognitive load in llms but also bridge the gap between psychological constructs and computational modeling.", "Pub Date": "2024-02-21"}
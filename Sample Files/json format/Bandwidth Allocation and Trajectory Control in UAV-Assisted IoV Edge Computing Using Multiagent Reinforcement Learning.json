{"Title": "Bandwidth Allocation and Trajectory Control in UAV-Assisted IoV Edge Computing Using Multiagent Reinforcement Learning", "Doi": "10.1109/TR.2022.3192020", "Authors": ["j. wang", "x. zhang", "x. he", "y. sun"], "Key Words": ["attention mechanism", "bandwidth assignment", "location deployment", "multiagent deep reinforcement learning (drl)", "value decomposition network (vdn)"], "Abstract": "the rapid development of an unmanned aerial vehicle  uav  has brought new opportunities for wireless communication and edge computing. in this article we investigate the scenario where multiple uavs serve as edge computing devices for the internet of vehicles  iov . regardless of the allocation of computing resources we focus on bandwidth allocation and trajectory control to maximize the communication capacity of the system so that the uav edge computing network can process more data. with this intent a uav assisted iov edge computing system model is constructed as a nonconvex optimization problem aiming to maximize the achievable channel capacity of the network. to solve this problem two \u201a\u00e4\u00faquasi distributed\u201a\u00e4\u00f9 multiagent algorithms i.e. actor critic mixing network  ac mix  and multi attentive agent deep deterministic policy gradient  ma2ddpg  are proposed based on deep deterministic policy gradient. specifically ac mix utilizes a mixing network to obtain a global $q$ value for better evaluation of joint action while ma2ddpg employs a multihead attention mechanism to achieve multiagent collaboration. using multi agents deep deterministic policy gradient  maddpg  as benchmark several experiments are carried out to verify the performance of the proposed algorithms. simulation results show that the convergence velocity of ac mix and ma2ddpg is improved by 30.0% and 63.3% respectively compared with maddpg.", "Pub Date": "2023-06-01"}
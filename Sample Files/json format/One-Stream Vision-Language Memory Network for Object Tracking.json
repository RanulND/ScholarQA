{"Title": "One-Stream Vision-Language Memory Network for Object Tracking", "Doi": "10.1109/TMM.2023.3285441", "Authors": ["h. zhang", "j. wang", "j. zhang", "t. zhang", "b. zhong"], "Key Words": ["object tracking", "vision-language", "one-stream", "memory network"], "Abstract": "most existing tracking methods try to represent the target by exploiting visual information as much as possible based on the various deep networks. however the appearance model hardly describes the attribute feature of the target well which makes the trackers fail to adapt to the complex visual surrounding. in this article inspired by brain like intelligence we propose an one stream vision language memory network  ovlm  for object tracking. firstly we use the combination of vision and language to build the target model and use the semantic information in the language to compensate for the instability of visual information making the target model more stable in the face of complex appearance changes. secondly to build a more compact target model we propose a memory token selection mechanism that utilizes linguistic information to eliminate tokens that do not contain target information. furthermore to provide better visual information for target modeling we propose a language based evaluation method to select high quality target samples to be stored in the memory. finally ovlm achieves a 64.7% success rate on the large scale tracking benchmark dataset tnl2k outperforming the previous best result  vlt  by 11.6%. by exposing the possibility of the vision language memory network we aim to draw greater attention to it and open up new avenues for vision language tracking.", "Pub Date": "2024-01-22"}
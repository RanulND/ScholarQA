{"Title": "CLUE: Systems Support for Knowledge Transfer in Collaborative Learning With Neural Nets", "Doi": "10.1109/TCC.2023.3294490", "Authors": ["h. daga", "y. chen", "a. agrawal", "a. gavrilovska"], "Key Words": ["deep learning", "edge computing", "edge inference", "intelligent edge"], "Abstract": "for highly distributed environments such as edge computing collaborative learning approaches eschew the dependence on a global shared model in favor of models tailored for each location. creating tailored models for individual learning contexts reduces the amount of data transfer while collaboration among peers provides acceptable model performance. collaboration assumes however the availability of knowledge transfer mechanisms which are not trivial for deep learning models where knowledge isn't easily attributed to precise model slices. we present clue \u201a\u00e4\u00ec a framework that facilitates knowledge transfer for neural networks. clue provides new system support for dynamically extracting significant parameters from a helper node neural network and uses this with a multi model boosting based approach to improve the predictive performance of the target node. the evaluation of clue with different pytorch and tensorflow neural network models demonstrates that its knowledge transfer mechanism improves by up to $3.5\\times$3.5\u221a\u00f3 how quickly a model adapts to changes compared to learning in isolation while affording up to several magnitudes reduction in data movement costs compared to federated learning.", "Pub Date": "2023-12-05"}
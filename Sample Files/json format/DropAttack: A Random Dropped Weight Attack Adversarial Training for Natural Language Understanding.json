{"Title": "DropAttack: A Random Dropped Weight Attack Adversarial Training for Natural Language Understanding", "Doi": "10.1109/TASLP.2023.3330613", "Authors": ["s. ni", "j. li", "m. yang", "h. -y. kao"], "Key Words": ["adversarial training", "natural language understanding", "regularization", "generalization"], "Abstract": "adversarial training has been proven to be a powerful regularization technique to improve language models. in this work we propose a novel random dropped weight attack adversarial training method  dropattack  for natural language understanding. our dropattack improves the generalization of models by minimizing the internal adversarial risk caused by a multitude of attack combinations. specifically dropattack enhances the adversarial attack space by intentionally adding worst case adversarial perturbations to the weight parameters and randomly dropping the specific proportion of attack perturbations. to extensively validate the effectiveness of dropattack 12 public english natural language understanding datasets were used. experiments on the glue benchmark show that when dropattack is applied only to the finetuning stage it is able to improve the overall test scores of the bert base pre trained model from 78.3 to 79.7 and roberta large pre trained model from 88.1 to 88.8. further dropattack also significantly improves models trained from scratch. theoretical analysis reveals that dropattack performs potential gradient regularization on the input and weight parameters of the model. moreover visualization experiments show that dropattack can push the minimum risk of the neural network to a lower and flatter loss landscape.", "Pub Date": "2023-11-20"}
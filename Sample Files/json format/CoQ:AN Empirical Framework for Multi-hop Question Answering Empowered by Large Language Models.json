{"Title": "CoQ:AN Empirical Framework for Multi-hop Question Answering Empowered by Large Language Models", "Doi": "10.1109/ICASSP48485.2024.10447488", "Authors": ["q. huang", "f. huang", "d. tao", "y. zhao", "b. wang", "y. huang"], "Key Words": ["large language models", "question answering", "cot", "knowledge bases"], "Abstract": "prompt based large language models large language model  are surprisingly powerful in generating natural language reasoning steps or chains of thoughts cot  for multi hop question answering qa . however large language model struggle when they lack access to necessary knowledge or when the knowledge within their parameters is outdated. additionally large language model that rely solely on cot tend to generate hallucinations during the reasoning process. to address these dilemmas we propose the chain of question  coq  framework a novel multi hop qa approach. this approach decomposes a complex original question into multiple sub questions according to a cot to retrieve knowledge from an external knowledge base. it then answers the question process based on the retrieved knowledge in accordance with a cot. we design that each point of thought generated during the reasoning process be supported by the knowledge retrieved in the external knowledge base. experiments show that coq is effective in reducing model hallucinations leading to higher factual accuracy than cot. on average it reduces factual errors by 31% over cot and even by 38% on the two most commonly used models today.", "Pub Date": "2024-03-18"}
{"Title": "TrICy: Trigger-Guided Data-to-Text Generation With Intent Aware Attention-Copy", "Doi": "10.1109/TASLP.2024.3353574", "Authors": ["v. agarwal", "s. ghosh", "h. bss", "h. arora", "b. r. k. raja"], "Key Words": ["data-to-text", "natural language generation", "edge devices"], "Abstract": "data to text  d2t  generation is a crucial task in many natural language understanding  nlu  applications and forms the foundation of task oriented dialog systems. in the context of conversational artificial intelliegence solutions that can work directly with local data on the user device architectures utilizing large pre trained language models  plms  are impractical for on device deployment due to a high memory footprint. to this end we propose tricy a novel lightweight framework for an enhanced d2t task that generates text sequences based on the intent in context and may further be guided by user provided triggers. we leverage an attention copy mechanism to predict out of vocabulary  oov  words accurately. performance analyses on e2e nlg dataset [novikova et al. 2017]  bleu  66.43% rouge l  70.14%  webnlg dataset [gardent et al. 2017]  bleu  seen 64.08% unseen 52.35%  and our custom dataset related to text messaging applications showcase our architecture effectiveness. moreover we show that by leveraging an optional trigger input data to text generation quality increases significantly and achieves the new sota score of 69.29% bleu for e2e nlg. furthermore our analyses show that tricy achieves at least 24% and 3% improvement in bleu and meteor respectively over large language model like gpt 3 chatgpt and llama 2. we also demonstrate that in some scenarios performance improvement due to triggers is observed even when they are absent in training.", "Pub Date": "2024-01-26"}
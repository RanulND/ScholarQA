{"Title": "SURT 2.0: Advances in Transducer-Based Multi-Talker Speech Recognition", "Doi": "10.1109/TASLP.2023.3318398", "Authors": ["d. raj", "d. povey", "s. khudanpur"], "Key Words": ["multi-talker asr", "transducers", "surt"], "Abstract": "the streaming unmixing and recognition transducer  surt  model was proposed recently as an end to end approach for continuous streaming multi talker speech recognition  asr . despite impressive results on multi turn meetings surt has notable limitations   i  it suffers from leakage and omission related errors   ii  it is computationally expensive due to which it has not seen adoption in academia  and  iii  it has only been evaluated on synthetic mixtures. in this work we propose several modifications to the original surt which are carefully designed to fix the above limitations. in particular we  i  change the unmixing module to a mask estimator that uses dual path modeling  ii  use a streaming zipformer encoder and a stateless decoder for the transducer  iii  perform mixture simulation using force aligned subsegments  iv  pre train the transducer on single speaker data  v  use auxiliary objectives in the form of masking loss and encoder ctc loss and  vi  perform domain adaptation for far field recognition. we show that our modifications allow surt 2.0 to outperform its predecessor in terms of multi talker asr results while being efficient enough to train with academic resources. we conduct our evaluations on 3 publicly available meeting benchmarks \u201a\u00e4\u00ee libricss ami and icsi where our best model achieves wers of 16.9% 44.6% and 32.2% respectively on far field unsegmented recordings.", "Pub Date": "2023-10-23"}
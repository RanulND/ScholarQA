{"Title": "A Multimodal Approach to Device-Directed Speech Detection with Large Language Models", "Doi": "10.1109/ICASSP48485.2024.10446224", "Authors": ["d. wagner", "a. churchill", "s. sigtia", "p. georgiou", "m. mirsamadi", "a. mishra", "e. marchi"], "Key Words": ["device-directed speech detection", "large language model", "multimodal", "conditional generation"], "Abstract": "interactions with virtual assistants typically start with a predefined trigger phrase followed by the user command. to make interactions with the assistant more intuitive we explore whether it is feasible to drop the requirement that users must begin each command with a trigger phrase. we explore this task in three ways  first we train classifiers using only acoustic information obtained from the audio waveform. second we take the decoder outputs of an automatic speech recognition  asr  system such as 1 best hypotheses as input features to a large language model  large language model . finally we explore a multimodal system that combines acoustic and lexical features as well as asr decoder signals in an large language model. using multimodal information yields relative equal error rate improvements over text only and audio only models of up to 39% and 61%. increasing the size of the large language model and training with low rank adaption leads to further relative eer reductions of up to 18% on our dataset.", "Pub Date": "2024-03-18"}
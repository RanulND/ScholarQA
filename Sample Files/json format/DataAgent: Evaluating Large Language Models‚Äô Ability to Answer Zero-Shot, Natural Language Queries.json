{"Title": "DataAgent: Evaluating Large Language Models\u201a\u00c4\u00f4 Ability to Answer Zero-Shot, Natural Language Queries", "Doi": "10.1109/ICAIC60265.2024.10433803", "Authors": ["m. mishra", "a. braham", "c. marsom", "b. chung", "g. griffin", "d. sidnerlikar", "c. sarin", "a. rajaram"], "Key Words": ["gpt", "data science", "natural language processing", "large language model", "data processing", "reflexion", "chain-of-thought", "saycan", "action plan generation", "zero-shot prompting", "plain language"], "Abstract": "conventional processes for analyzing datasets and extracting meaningful information are often time consuming and laborious. previous work has identified manual repetitive coding and data collection as major obstacles that hinder data scientists from undertaking more nuanced labor and high level projects. to combat this we evaluated openai\u201a\u00e4\u00f4s gpt 3.5 as a \"language data scientist\"  lds  that can extrapolate key findings including correlations and basic information from a given dataset. the model was tested on a diverse set of benchmark datasets to evaluate its performance across multiple standards including data science code generation based tasks involving libraries such as numpy pandas scikit learn and tensorflow and was broadly successful in correctly answering a given data science query related to the benchmark dataset. the lds used various novel prompt engineering techniques to effectively answer a given question including chain of thought reinforcement and saycan prompt engineering. our findings demonstrate great potential for leveraging large language models for low level zero shot data analysis.", "Pub Date": "2024-02-16"}
{"Title": "Fine-tuned generative LLM oversampling can improve performance over traditional techniques on multiclass imbalanced text classification", "Doi": "10.1109/BigData59044.2023.10386772", "Authors": ["n. a. cloutier", "n. japkowicz"], "Key Words": ["imbalance", "resampling", "oversampling", "nlp"], "Abstract": "a common challenge in classification and data mining is the class imbalance problem where one class in a dataset has significantly more samples than another. the presence of this problem typically worsens the performance of classifiers trained on these datasets by giving them a strong preference for better represented classes above others. resampling is the process of adding  oversampling  or taking away  undersampling  samples from a dataset typically with the purpose of introducing balance to the dataset before a classifier is trained. with recent advances in generative large language models  llms  certain authors have proposed the use of these models to generate new samples as a form of oversampling for imbalanced text data. this method has shown initial success but has not been systematically compared to more traditional methods of resampling across many domains. we find that this use of generative llms generally outperforms other methods on imbalanced multiclass classification but not on binary classification.", "Pub Date": "2024-01-22"}
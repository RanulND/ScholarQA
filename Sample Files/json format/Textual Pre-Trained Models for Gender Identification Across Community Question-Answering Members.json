{"Title": "Textual Pre-Trained Models for Gender Identification Across Community Question-Answering Members", "Doi": "10.1109/ACCESS.2023.3235735", "Authors": ["p. schwarzenberg", "a. figueroa"], "Key Words": ["gender identification", "community question-answering sites", "engagement and participation in online communities", "transformers"], "Abstract": "promoting engagement and participation is vital for online social networks such as community question answering  cqa  sites. one way of increasing the contribution of their members is by connecting their content with the right target audience. to achieve this goal demographic analysis is pivotal in deciphering the interest of each community fellow. indeed demographic factors such as gender are fundamental in reducing the gender disparity across distinct topics. this work assesses the classification rate of assorted state of the art transformer based models  e.g. bert and fnet  on the task of gender identification across cqa fellows. for this purpose it benefited from a massive text oriented corpus encompassing 548375 member profiles including their respective full questions answers and self descriptions. this assisted in conducting large scale experiments considering distinct combinations of encoders and sources. contrary to our initial intuition in average terms self descriptions were detrimental due to their sparseness. in effect the best transformer models achieved an auc of 0.92 by taking full questions and answers into account  i.e. deberta and mobilebert . our qualitative results reveal that fine tuning on user generated content is affected by pre training on clean corpora and that this adverse effect can be mitigated by correcting the case of words.", "Pub Date": "2023-01-18"}
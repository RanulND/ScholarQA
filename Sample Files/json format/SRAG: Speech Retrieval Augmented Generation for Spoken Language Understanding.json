{"Title": "SRAG: Speech Retrieval Augmented Generation for Spoken Language Understanding", "Doi": "10.1109/ISRITI60336.2023.10467285", "Authors": ["h. yang", "m. zhang", "d. wei"], "Key Words": ["spoken language understanding", "retrieval augmented generation", "large language models"], "Abstract": "retrieval augmented generation  rag  has shown promise for enhancing natural language understanding  nlu  capabilities of large language models  llms  by retrieving relevant knowledge as prompts. extending rag to spoken language understanding  slu  represents an important research direction. this paper proposes a rag approach for improving slu. first the encoder of a pretrained automatic speech recognition model is utilized for speech retrieval over the training set. the corresponding texts and intent labels are then formulated as prompts to guide the slu decoder. furthermore a prompt attention mechanism is introduced to strengthen the attention between generation and prompts. experiments demonstrate that the proposed speech rag approach substantially outperforms conventional end to end and cascaded slu models in intent prediction from speech. this highlights the efficacy of leveraging retrieval based prompting to incorporate external knowledge for advancing slu.", "Pub Date": "2024-03-21"}
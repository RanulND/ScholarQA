{"Title": "Com-DDPG: Task Offloading Based on Multiagent Reinforcement Learning for Information-Communication-Enhanced Mobile Edge Computing in the Internet of Vehicles", "Doi": "10.1109/TVT.2023.3309321", "Authors": ["h. gao", "x. wang", "w. wei", "a. al-dulaimi", "y. xu"], "Key Words": ["mobile edge computing", "multiagent reinforcement learning", "offloading strategy", "wireless communication", "internet of vehicles"], "Abstract": "the emergence of the internet of vehicles  iov  introduces challenges regarding computation intensive and time sensitive related services for data processing and communication. limited resource availability increases the processing latency and may cause application interruption due to the mobility of vehicles. to address the real time requirements of users and tasks mobile edge computing  mec  in which data are processed at the network edge has been proposed to collaborate with the cloud to provide better performance. however the offloading strategies proposed previously have some shortcomings in addressing issues such as task dependency and resource competition. in this article we propose a novel offloading strategy for mec com ddpg in which multiagent reinforcement learning is used to enhance the offloading performance. within the iov transmission radius multiple agents work together to learn the changes in the environment such as the number of mobile devices and the queue of tasks and take appropriate action in the form of a strategy for offloading to an edge server. first we discuss models of task dependency task priority and resource consumption from the perspective of server clusters and multiple dependencies among tasks. in the proposed method the communication behavior among multiple agents is formulated  then the policy determined through reinforcement learning is executed as an offloading strategy to obtain the corresponding results. second to enhance the communication of information among multiple agents a long short term memory  lstm  network is employed as an internal state predictor to provide a more complete environmental state and a bidirectional recurrent neural network  brnn  is used to learn and enhance the features obtained from the agents' communication. finally experiments carried out based on the alibaba cluster dataset are presented. the results show that our method is superior to baseline methods in terms of energy consumption load status and latency.", "Pub Date": "2024-01-16"}
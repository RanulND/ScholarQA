{"Title": "Duration-Aware Pause Insertion Using Pre-Trained Language Model for Multi-Speaker Text-To-Speech", "Doi": "10.1109/ICASSP49357.2023.10096402", "Authors": ["d. yang", "t. koriyama", "y. saito", "t. saeki", "d. xin", "h. saruwatari"], "Key Words": ["multi-speaker tts", "pause insertion", "phrase break prediction", "phrasing", "categorized pause insertion", "bert"], "Abstract": "pause insertion also known as phrase break prediction and phrasing is an essential part of tts systems because proper pauses with natural duration significantly enhance the rhythm and intelligibility of synthetic speech. however conventional phrasing models ignore various speakers\u201a\u00e4\u00f4 different styles of inserting silent pauses which can degrade the performance of the model trained on a multi speaker speech corpus. to this end we propose more powerful pause insertion frameworks based on a pre trained language model. our approach uses bidirectional encoder representations from transformers  bert  pre trained on a large scale text corpus injecting speaker embeddings to capture various speaker characteristics. we also leverage duration aware pause insertion for more natural multi speaker tts. we develop and evaluate two types of models. the first improves conventional phrasing models on the position prediction of respiratory pauses  rps  i.e. silent pauses at word transitions without punctuation. it performs speaker conditioned rp prediction considering contextual information and is used to demonstrate the effect of speaker information on the prediction. the second model is further designed for phoneme based tts models and performs duration aware pause insertion predicting both rps and punctuation indicated pauses  pips  that are categorized by duration. the evaluation results show that our models improve the precision and recall of pause insertion and the rhythm of synthetic speech.", "Pub Date": "2023-05-05"}
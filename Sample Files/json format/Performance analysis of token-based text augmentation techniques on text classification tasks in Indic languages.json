{"Title": "Performance analysis of token-based text augmentation techniques on text classification tasks in Indic languages", "Doi": "10.1109/ICSCC59169.2023.10335009", "Authors": ["r. shirke", "a. agrawal"], "Key Words": ["nlp", "data augmentation", "indicbert", "headline classification", "sentiment classification"], "Abstract": "due to the increasing availability of large scale datasets deep learning models have become the first choice to tackle nlp tasks. however training these models might require a huge amount of labeled data. it might be difficult to achieve great results if sufficient data is not available for training which might be the case with low resource languages. fortunately text augmentation has garnered considerable attention in recent years for improving the performance of natural language processing tasks particularly in low resource settings. the majority of these recently developed text data augmentation techniques have been thoroughly tested and analyzed in the resource rich english language. however there is a lack of similar performance analysis of text augmentation techniques in indian languages. in this study we focus on the performance of token based text augmentation techniques for text classification tasks in indian languages. we conduct performance analysis of token based augmentation technique methods on headline and sentiment classification tasks in indian languages using models like bilstm and the recently introduced albert based multilingual model indicbert. we observed a significant performance boost across different languages and tasks with the bilstm model as compared to indicbert. indicbert being pretrained on 12 indian languages has already learned semantic and contextual knowledge and thus does not benefit from added variations using augmentation.", "Pub Date": "2023-12-06"}
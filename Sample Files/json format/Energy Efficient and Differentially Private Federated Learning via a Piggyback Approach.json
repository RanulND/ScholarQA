{"Title": "Energy Efficient and Differentially Private Federated Learning via a Piggyback Approach", "Authors": ["r. chen", "c. huang", "x. qin", "n. ma", "m. pan", "x. shen"], "Pub Date": "2024-03-07", "Abstract": "this artilce aims to develop a differential private federated learning  fl  scheme with the least artificial noises added while minimizing the energy consumption of participating mobile devices. by observing that some communication efficient fl approaches and even the nature of wireless communications contribute to the differential privacy  dp  preservation of training data on mobile devices in this paper we propose to jointly leverage gradient compression techniques  i.e. gradient quantization and sparsification  and additive white gaussian noises  awgn  in wireless channels to develop a piggyback dp approach for fl over mobile devices. even with the piggyback dp approach information distortion caused by gradient compression and noise perturbation may slow down fl convergence which in turn consumes more energy of mobile devices for local computing and model update communications. thus we theoretically analyze fl convergence and formulate an energy efficient fl optimization under piggyback dp transmission power and fl convergence constraints. furthermore we propose an efficient iterative algorithm where closed form solutions for artificial dp noise and power control are derived. extensive simulation and experimental results demonstrate the effectiveness of the proposed scheme in terms of energy efficiency and privacy preservation.", "Doi": "10.1109/TMC.2023.3268323", "Key Words": ["federated learning over mobile devices", "piggyback differential privacy", "gradient compression", "white gaussian noises"]}
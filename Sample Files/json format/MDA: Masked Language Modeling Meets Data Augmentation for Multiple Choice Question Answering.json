{"Title": "MDA: Masked Language Modeling Meets Data Augmentation for Multiple Choice Question Answering", "Doi": "10.1109/SWC57546.2023.10449210", "Authors": ["x. yao", "z. huang", "j. ma", "j. chen", "j. yang"], "Key Words": ["multiple choice question answering", "machine reading comprehension", "data augmentation", "masked language modeling", "self-evaluation"], "Abstract": "multiple choice question answering  mcqa  is a well established task in the field of machine reading comprehension  mrc . its objective is to identify the correct answer from a given set of options based on the provided background passage and question. recent advancements in large scale pre trained language models  plms  have yielded impressive performance in mcqa. however achieving such performance requires a significant number of training samples leading to time consuming and labor intensive sample acquisition and annotation processes. to overcome the limitation posed by the availability of training samples this paper explores the potential of leveraging the [mask] token which is commonly used in masked language modeling  mlm  during the self supervised training of plms. specifically the paper introduces a straightforward yet effective approach called [mask] based data augmentation  mda . the proposed method involves injecting [mask] tokens into background passages to create masked versions of the original data. moreover a self evaluator is introduced to regulate the process of masking production with the objective of minimizing negative impact caused by argumentation noise. the effectiveness of the proposed method is empirically validated using various benchmark mcqa datasets. experimental results demonstrate considerable improvements over state of the arts.", "Pub Date": "2024-03-01"}
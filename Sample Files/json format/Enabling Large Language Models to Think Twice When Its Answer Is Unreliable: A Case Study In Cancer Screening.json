{"Title": "Enabling Large Language Models to Think Twice When Its Answer Is Unreliable: A Case Study In Cancer Screening", "Doi": "10.1109/BIBM58861.2023.10385316", "Authors": ["m. wu", "h. lin", "x. lyu", "c. zhang", "s. yu"], "Key Words": ["large language model", "prompt optimization", "query optimization", "health care q&a", "langchain"], "Abstract": "to enhance the accuracy and reliability of the response of large language models  llms  in professional domain specific question answering this paper proposes an approach to enhance the capabilities of llms by prompting them to \"think twice.\" this methodology encourages a second pass processing allowing for deeper analysis and more refined outputs. we developed a prototype logic inspired query optimizer  pqo  to enhance the response of llm. it refines initial queries using few shot learning and self reflection leading to more insightful questions. our experimental results show that the proposed approach obtains empirically validated answers.", "Pub Date": "2024-01-18"}
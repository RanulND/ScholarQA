{"Title": "GPTSee: Enhancing Moment Retrieval and Highlight Detection via Description-Based Similarity Features", "Doi": "10.1109/LSP.2023.3340103", "Authors": ["y. sun", "y. xu", "z. xie", "y. shu", "s. du"], "Key Words": ["image description", "semantic similarity", "video moment retrieval", "video highlight detection"], "Abstract": "moment retrieval  mr  and highlight detection  hd  aim to identify relevant moments and highlights in video from corresponding natural language query. large language models  large language model  have demonstrated proficiency in various computer vision tasks. however existing methods for mr&hd have not yet been integrated with large language model. in this letter we propose a novel two stage model that takes the output of large language model as the input to the second stage transformer encoder decoder. first minigpt 4 is employed to generate the detailed description of the video frame and rewrite the query statement fed into the encoder as new features. then semantic similarity is computed between the generated description and the rewritten queries. finally continuous high similarity video frames are converted into span anchors serving as prior position information for the decoder. experiments demonstrate that our approach achieves a state of the art result and by using only span anchors and similarity scores as outputs positioning accuracy outperforms traditional methods like moment detr.", "Pub Date": "2024-02-09"}
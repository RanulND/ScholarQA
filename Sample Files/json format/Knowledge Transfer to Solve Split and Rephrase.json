{"Title": "Knowledge Transfer to Solve Split and Rephrase", "Doi": "10.1109/ICIT58056.2023.10226004", "Authors": ["a. b. alajlouni", "j. li"], "Key Words": ["split and rephrase", "natural language processing", "knowledge transfer", "pre-trained language models", "t5"], "Abstract": "the usage of large pre trained language models like bert and gpt has brought a transformative impact on various natural language processing  nlp  tasks in recent times. however a significant challenge faced in many nlp tasks is the scarcity of high quality datasets required for fine tuning these models for specific tasks. in this study we introduce an innovative framework designed to address the issue of dataset insufficiency in the split and  rephrase  sr  task. we achieve this by leveraging the knowledge embedded in a rule based model and employing it to supervise the fine tuning process of large pre trained language models enabling them to perform the sr task effectively without relying on labeled data. our framework for knowledge transfer holds promise as a potential solution for other nlp tasks involving rule based models.", "Pub Date": "2023-08-29"}
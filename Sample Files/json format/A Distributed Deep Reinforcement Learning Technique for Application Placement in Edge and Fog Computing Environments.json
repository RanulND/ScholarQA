{"Title": "A Distributed Deep Reinforcement Learning Technique for Application Placement in Edge and Fog Computing Environments", "Doi": "10.1109/TMC.2021.3123165", "Authors": ["m. goudarzi", "m. palaniswami", "r. buyya"], "Key Words": ["fog computing", "edge computing", "deep reinforcement learning", "application placement", "internet of things (iot)"], "Abstract": "fog edge computing is a novel computing paradigm supporting resource constrained internet of things  iot  devices by placement of their tasks on edge and or cloud servers. recently several deep reinforcement learning  drl  based placement techniques have been proposed in fog edge computing environments which are only suitable for centralized setups. the training of well performed drl agents requires manifold training data while obtaining training data is costly. hence these centralized drl based techniques lack generalizability and quick adaptability thus failing to efficiently tackle application placement problems. moreover many iot applications are modeled as directed acyclic graphs  dags  with diverse topologies. satisfying dependencies of dag based iot applications incur additional constraints and increase the complexity of placement problem. to overcome these challenges we propose an actor critic based distributed application placement technique working based on the importance weighted actor learner architectures  impala . impala is known for efficient distributed experience trajectory generation that significantly reduces exploration costs of agents. besides it uses an adaptive off policy correction method for faster convergence to optimal solutions. our technique uses recurrent layers to capture temporal behaviors of input data and a replay buffer to improve the sample efficiency. the performance results obtained from simulation and testbed experiments demonstrate that our technique significantly improves execution cost of iot applications up to 30% compared to its counterparts.", "Pub Date": "2023-04-04"}
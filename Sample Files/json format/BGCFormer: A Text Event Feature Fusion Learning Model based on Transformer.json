{"Title": "BGCFormer: A Text Event Feature Fusion Learning Model based on Transformer", "Doi": "10.1109/ICCCBDA56900.2023.10154819", "Authors": ["y. liu", "j. wang", "q. li"], "Key Words": ["event extraction", "graph convolution networks", "deep learning", "transformer", "information extraction"], "Abstract": "event extraction is an essential task in natural language processing as it involves extracting meaningful events from text documents which is important for a variety of applications such as information retrieval question answering and text summarization yet challenges remain when extracting events from documents which is that a document usually contain multiple sentences together form a complete event and entities in the same event may span multiple sentences. to address these challenges this paper proposes a transformer with features fusion learning model  bgcformer  which is based on a transformer architecture with gcn and encoder attention mechanism and it can build a feature fusion learning network to capture global interaction features between different sentences and entity mentions. experiments conducted on a large scale dataset have demonstrated the proposed model outperforms existing methods in terms of accuracy and efficiency.", "Pub Date": "2023-06-26"}
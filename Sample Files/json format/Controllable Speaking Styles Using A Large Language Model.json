{"Title": "Controllable Speaking Styles Using A Large Language Model", "Doi": "10.1109/ICASSP48485.2024.10448400", "Authors": ["a. sigurgeirsson", "s. king"], "Key Words": ["speech synthesis", "style modelling", "prosody"], "Abstract": "reference based text to speech  tts  models can generate multiple prosodically different renditions of the same target text. such models jointly learn a latent acoustic space during training which can be sampled from during inference. controlling these models during inference typically requires finding an appropriate reference utterance which is non trivial.large generative language models  large language model  have shown excellent performance in various language related tasks. given only a natural language query text  the \u201a\u00e4\u00f2prompt\u201a\u00e4\u00f4  such models can be used to solve specific context dependent tasks. recent work in tts has attempted similar prompt based control of novel speaking style generation. those methods do not require a reference utterance and can under ideal conditions be controlled with only a prompt. but existing methods typically require a prompt labelled speech corpus for jointly training a prompt conditioned encoder.in contrast we instead employ an large language model to directly suggest prosodic modifications for a controllable tts model using contextual information provided in the prompt. the prompt can be designed for a multitude of tasks. here we give two demonstrations  control of speaking style  prosody appropriate for a given dialogue context. the proposed method is rated most appropriate in 50% of cases vs. 31% for a baseline model.", "Pub Date": "2024-03-18"}
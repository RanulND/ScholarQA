{"Title": "Invited Paper: Software/Hardware Co-design for LLM and Its Application for Design Verification", "Doi": "10.1109/ASP-DAC58780.2024.10473893", "Authors": ["l. j. wan", "y. huang", "y. li", "h. ye", "j. wang", "x. zhang", "d. chen"], "Key Words": ["large language models", "software/hardware co-design", "functional verification"], "Abstract": "the widespread adoption of large language models  llms  is impeded by their demanding compute and memory resources. the first task of this paper is to explore optimization strategies to expedite llms including quantization pruning and operation level optimizations. one unique direction is to optimize llm inference through novel software hardware co design methods. given the accelerated llms the second task of this paper is to study llms\u201a\u00e4\u00f4 performance in the usage scenario of circuit design and verification. specifically we place a particular emphasis on functional verification. through automated prompt engineering we harness the capabilities of the established llm gpt 4 to generate high level synthesis  hls  designs with predefined errors based on 11 open source synthesizable hls benchmark suites. this dataset is a comprehensive collection of over 1000 function level designs and each of which is afflicted with up to 45 distinct combinations of defects injected into the source code. this dataset named chrysalis expands upon what\u201a\u00e4\u00f4s available in current hls error models offering a rich resource for training to improve how llms debug code. the dataset can be accessed at  https //github.com uiuc chenlab chrysalis hls.", "Pub Date": "2024-03-25"}
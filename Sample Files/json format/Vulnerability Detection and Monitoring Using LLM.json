{"Title": "Vulnerability Detection and Monitoring Using LLM", "Doi": "10.1109/WIECON-ECE60392.2023.10456393", "Authors": ["v. akuthota", "r. kasula", "s. t. sumona", "m. mohiuddin", "m. t. reza", "m. m. rahman"], "Key Words": ["language model models (llms)", "vulnerability", "chatgpt", "gpt-3.5-turbo model", "openai"], "Abstract": "large language models  llms  have evolved as a cornerstone for intricate code evaluations in the modern realm of artificial intelligence and machine learning. the prioritizing of rigorous security requirements is a crucial requirement for the business in the dynamic and ever changing world of software development. the current study has used the capabilities of the gpt 3.5  turbo model to conduct a detailed assessment of various code snippets to find any vulnerabilities. the main objective of the experiment was to introduce continuous monitoring technologies to enhance software security and release control. to obtain reliable results we used a classification report and a confusion matrix. out of these validation methods we choose accuracy as an important metric for this validation because in this experiment we need our model to predict the vulnerabilities that are present in the 2740 test cases and we would need our model to focus more on true positives tp . the ideal goal of this experiment was to predict any kind of vulnerability from the real world data. out of all test cases we were able to have an accuracy of 0.77. this demonstrates the approach potential efficacy in discovering vulnerabilities. nonetheless the study found certain parts that require improvement emphasizing the importance of continual refinement in the model methodology to ensure more thorough security assessments. this study lays the groundwork for future research into the use of powerful machine learning models in the assessment of software vulnerabilities. the findings not only highlight the effectiveness of the existing approach but also offer light on prospective future research directions paving the way for the next generation of models and evaluation techniques.", "Pub Date": "2024-03-26"}
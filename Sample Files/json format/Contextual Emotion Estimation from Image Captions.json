{"Title": "Contextual Emotion Estimation from Image Captions", "Doi": "10.1109/ACII59096.2023.10388198", "Authors": ["v. yang", "a. srivastava", "y. etesam", "c. zhang", "a. lim"], "Key Words": ["large language model", "emotion estimation", "image captioning", "context", "chatgpt", "gpt-3.5"], "Abstract": "emotion estimation in images is a challenging task typically using computer vision methods to directly estimate people\u201a\u00e4\u00f4s emotions using face body pose and contextual cues. in this paper we explore whether large language models  large language model  can support the contextual emotion estimation task by first captioning images then using an large language model for inference. first we must understand  how well do large language model perceive human emotions? and which parts of the information enable them to determine emotions? one initial challenge is to construct a caption that describes a person within a scene with information relevant for emotion perception. towards this goal we propose a set of natural language descriptors for faces bodies interactions and environments. we use them to manually generate captions and emotion annotations for a subset of 331 images from the emotic dataset. these captions offer an interpretable representation for emotion estimation towards understanding how elements of a scene affect emotion perception in large language model and beyond. secondly we test the capability of a large language model to infer an emotion from the resulting image captions. we find that gpt3.5 specifically the text davinci 003 model provides surprisingly reasonable emotion predictions consistent with human annotations but accuracy can depend on the emotion concept. overall the results suggest promise in the image captioning and large language model approach.", "Pub Date": "2024-01-15"}
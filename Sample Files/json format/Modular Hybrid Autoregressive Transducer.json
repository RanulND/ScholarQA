{"Title": "Modular Hybrid Autoregressive Transducer", "Doi": "10.1109/SLT54892.2023.10023194", "Authors": ["z. meng", "t. chen", "r. prabhavalkar", "y. zhang", "g. wang", "k. audhkhasi", "j. emond", "t. strohman", "b. ramabhadran", "w. r. huang", "e. variani", "y. huang", "p. j. moreno"], "Key Words": ["speech recognition", "text-only adaptation", "hybrid autoregressive transducer"], "Abstract": "text only adaptation of a transducer model remains challenging for end to end speech recognition since the transducer has no clearly separated acoustic model  am  language model  lm  or blank model. in this work we propose a modular hybrid autoregressive transducer  mhat  that has structurally separated label and blank decoders to predict label and blank distributions respectively along with a shared acoustic encoder. the encoder and label decoder outputs are directly projected to am and internal lm scores and then added to compute label posteriors. we train mhat with an internal lm loss and a hat loss to ensure that its internal lm becomes a standalone neural lm that can be effectively adapted to text. moreover text adaptation of mhat fosters a much better lm fusion than internal lm subtraction based methods. on google large scale production data a multi domain mhat adapted with 100b sentences achieves relative wer reductions of up to 12.4% without lm fusion and 21.5% with lm fusion from 400k hour trained hat.", "Pub Date": "2023-01-27"}
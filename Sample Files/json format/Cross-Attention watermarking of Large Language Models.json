{"Title": "Cross-Attention watermarking of Large Language Models", "Doi": "10.1109/ICASSP48485.2024.10446397", "Authors": ["f. b. baldassini", "h. h. nguyen", "c. -c. chang", "i. echizen"], "Key Words": ["large language models", "linguistic watermarking", "cross attention", "steganography"], "Abstract": "a new approach to linguistic watermarking of language models is presented in which information is imperceptibly inserted into the output text while preserving its readability and original meaning. a cross attention mechanism is used to embed watermarks in the text during inference. two methods using cross attention are presented that minimize the effect of watermarking on the performance of a pretrained model. exploration of different training strategies for optimizing the watermarking and of the challenges and implications of applying this approach in real world scenarios clarified the tradeoff between watermark robustness and text quality. watermark selection substantially affects the generated output for high entropy sentences. this proactive watermarking approach has potential application in future model development.", "Pub Date": "2024-03-18"}
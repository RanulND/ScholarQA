{"Title": "Like Attracts Like: Personalized Federated Learning in Decentralized Edge Computing", "Doi": "10.1109/TMC.2022.3230712", "Authors": ["z. ma", "y. xu", "h. xu", "j. liu", "y. xue"], "Key Words": ["decentralized edge computing", "personalized federated learning", "model pruning", "neighbor selection"], "Abstract": "the emerging personalized federated learning  pfl  methods aim to produce personalized models for different users so as to keep track of their individualized requirements in edge computing  ec . the centralized pfl methods may suffer from the communication bottleneck and single point of failure. as an alternative solution the decentralized pfl  dpfl  methods are performed in a peer to peer  p2p  manner and collaboratively train personalized models by model aggregation among congenial devices. however these dpfl methods may incur high communication cost and low resource utilization induced by large scale models. herein we take the communication constraint and heterogeneity into consideration and propose to realize communication efficient dpfl with adaptive model pruning and neighbor selection. we theoretically analyze the convergence of the proposed dpfl method and study the impacts of both model pruning and neighbor selection on training performance. furthermore we propose an efficient algorithm that combines model pruning and neighbor selection to achieve a trade off between model quality and communication cost. extensive simulation and testbed experiments on real world datasets are conducted. the experimental results demonstrate that the proposed algorithm can improve the test accuracy by at most 13% and save the traffic consumption by 45.4% on average compared with the existing pfl methods.", "Pub Date": "2024-01-08"}
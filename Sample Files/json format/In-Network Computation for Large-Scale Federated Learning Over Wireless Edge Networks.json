{"Title": "In-Network Computation for Large-Scale Federated Learning Over Wireless Edge Networks", "Doi": "10.1109/TMC.2022.3190260", "Authors": ["t. q. dinh", "d. n. nguyen", "d. t. hoang", "t. v. pham", "e. dutkiewicz"], "Key Words": ["mobile edge computing", "federated learning", "in-network computation", "large-scale distributed learning"], "Abstract": "most conventional federated learning  fl  models are using a star network topology where all users aggregate their local models at a single server  e.g. a cloud server . that causes significant overhead in terms of both communications and computing at the server delaying the training process especially for large scale fl systems with straggling nodes. this article proposes a novel edge network architecture that enables decentralizing the model aggregation process at the server thereby significantly reducing the training delay for the whole fl network. specifically we design a highly effective in network computation framework  inc  consisting of a user scheduling mechanism an in network aggregation process  ina  which is designed for both primal  and primal dual methods in distributed machine learning problems and a network routing algorithm with theoretical performance bounds. the in network aggregation process which is implemented at edge nodes and cloud node can adapt two typical methods to allow edge networks to effectively solve the distributed machine learning problems. under the proposed ina we then formulate a joint routing and resource optimization problem aiming to minimize the aggregation latency. the problem turns out to be np hard and thus we propose a polynomial time routing algorithm which can achieve near optimal performance with a theoretical bound. simulation results showed that the proposed algorithm can achieve more than 99$\\%$% of the optimal solution and reduce the fl training latency up to 5.6 times w.r.t other baselines. the proposed inc framework can not only help reduce the fl training latency but also significantly decrease cloud traffic and computing overhead. by embedding the computing aggregation tasks at the edge nodes and leveraging the multi layer edge network architecture the inc framework can liberate fl from the star topology to enable large scale fl.", "Pub Date": "2023-08-31"}
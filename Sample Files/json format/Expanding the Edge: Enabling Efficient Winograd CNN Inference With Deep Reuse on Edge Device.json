{"Title": "Expanding the Edge: Enabling Efficient Winograd CNN Inference With Deep Reuse on Edge Device", "Doi": "10.1109/TKDE.2023.3269017", "Authors": ["f. zhang", "r. wu", "j. guan", "z. zheng", "x. guo", "x. zhang", "x. du", "x. shen"], "Key Words": ["cnn", "deep reuse", "inference", "winograd"], "Abstract": "deep learning on edge devices is becoming increasingly important especially with the explosion of iot devices. for example the total number of devices connected to iot reaches 29 billion in 2022. convolutional neural networks  cnns  as common deep learning representatives are among the most popular neural networks in knowledge and data engineering. however cnn employs a high degree of computing. in comparison to the training phase the inference process is more frequently done on low power computing equipments such as edge devices. the limited computing resource and high computation pressure limit the effective use of cnn algorithms at the edge. fortunately a minimal filtering algorithm called winograd can reduce convolution calculations by minimizing multiplication operations. we find that winograd convolution can be accelerated further by deep reuse technique which reuses the similar data and computation processes. in this paper we propose a new inference method called drew which combines deep reuse with winograd for further accelerating cnns. drew handles three difficulties. first it can detect the similarities from the complex minimal filtering patterns by clustering. second it reduces the online clustering cost in a reasonable range. third it provides an adjustable method in clustering granularity balancing the performance and accuracy. we perform evaluation on raspberry pi and nvidia jetson agx xavier edge devices and experiments show that on five popular networks 1  drew further accelerates the winograd convolution by an average of 8.27\u221a\u00f3 speedup. even for the highly parallel winograd implementation drew still can provide 2.21\u221a\u00f3 speedup. 2  when drew is applied to end to end winograd cnn inferences drew achieves 5.94\u221a\u00f3 the average performance speedup with no  $< $<0.4%  accuracy loss. 3  energy consumption is an important factor for inference in practice. drew reduces the number of convolution operations to 10% of the original operations thus achieving up to 60% energy efficiency benefits than the original winograd inference.", "Pub Date": "2023-09-14"}
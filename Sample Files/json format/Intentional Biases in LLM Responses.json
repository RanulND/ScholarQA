{"Title": "Intentional Biases in LLM Responses", "Doi": "10.1109/UEMCON59035.2023.10316060", "Authors": ["n. badyal", "d. jacoby", "y. coady"], "Key Words": ["llm", "avatar", "question answering", "hallucinations", "ai bias"], "Abstract": "in this study we intentionally introduce biases into large language model responses in an attempt to create specific personas for interactive media purposes. we explore the differences between open source models such as falcon 7b and the gpt-4 model from open artificial intelliegence and we quantity some differences in responses afforded by the two systems. we find that the guardrails in the gpt-4 mixture of experts models with a supervisor while useful in assuring artificial intelliegence alignment in general are detrimental in trying to construct personas with a variety of uncommon viewpoints. this study aims to set the groundwork for future exploration in intentional biases of large language models such that these practices can be applied in the creative field and new forms of media.", "Pub Date": "2023-11-17"}
{"Title": "A Comparative Study of Cross-Sentence Features for Named Entity Recognition", "Doi": "10.1109/IDITR57726.2023.10145820", "Authors": ["s. -f. wang", "j. huang", "b. zhang", "j. li"], "Key Words": ["named entity recognition", "information extraction", "contextual feature", "span classification"], "Abstract": "recently a growing number of named entity recognition  ner  methods utilize cross sentence features  also known as contexts  to improve the performance of ner models instead of using single sentence information alone. as far as we know most ner models choose to exploit pre  and post sentences to capture cross sentence features. generally current ner studies focus only on the model architecture to capture better token representations. however there is no in depth exploration on how to better model cross sentence features. in this paper based on the span classification model we investigate the effect of cross sentence features under different settings. specifically we evaluate the impact of context stitching context window size context window padding and classifier token of pre trained language model  plm  on model performance. comparative experimental results show that appropriate incorporation of document level contexts can considerably improve the ner metrics. furthermore we find that several factors can be used to improve the performance of ner models   1  use domain specific plms but not classifier tokens   2  use only preceding contexts for generic text and random contexts for specialized text   3  truncate overly long contexts when the context window is small and preserve sentence integrity when the window is large   4  set the context window size to about 200 for the basic size plm.", "Pub Date": "2023-06-09"}
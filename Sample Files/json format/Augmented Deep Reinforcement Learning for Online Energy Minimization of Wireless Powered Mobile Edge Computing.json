{"Title": "Augmented Deep Reinforcement Learning for Online Energy Minimization of Wireless Powered Mobile Edge Computing", "Doi": "10.1109/TCOMM.2023.3251353", "Authors": ["x. chen", "w. dai", "w. ni", "x. wang", "s. zhang", "s. xu", "y. sun"], "Key Words": ["mobile edge computing", "wireless power transfer", "energy-efficient", "resource allocation", "deep q-network", "convex optimization"], "Abstract": "mobile edge computing  mec  offers an opportunity for devices relying on wireless power transfer  wpt  to accomplish computationally demanding tasks. such wpt powered mec systems have yet to be optimized for long term efficiency due to random and changing task demands and wireless channel states of the devices. this paper presents an augmented two staged deep q network  dqn  referred to as \u201a\u00e4\u00fats dqn\u201a\u00e4\u00f9 for online optimization of wpt powered mec systems where the wpt offloading schedule channel allocation and the cpu configurations of the edge server and devices are jointly optimized to minimize the long term average energy requirement of the systems. the key idea is to design a dqn for learning the channel allocation and task admission while the wpt offloading time and cpu configurations are efficiently optimized to precisely evaluate the reward of the dqn and substantially reduce its action space. another important aspect is that a new action generation method is developed to expand and diversify the actions of the dqn further accelerating its convergence. as validated by simulations the proposed ts dqn is much more energy efficient and converges much faster than its potential alternative directly using the state of the art deep deterministic policy gradient algorithm to learn all decision variables.", "Pub Date": "2023-05-17"}
{"Title": "Semi-Decentralized Federated Edge Learning With Data and Device Heterogeneity", "Doi": "10.1109/TNSM.2023.3252818", "Authors": ["y. sun", "j. shao", "y. mao", "j. h. wang", "j. zhang"], "Key Words": ["federated learning (fl)", "mobile edge computing (mec)", "non-independent and identically distributed (non-iid) data", "device heterogeneity"], "Abstract": "federated edge learning  feel  emerges as a privacy preserving paradigm to effectively train deep learning models from the distributed data in 6g networks. nevertheless the limited coverage of a single edge server results in an insufficient number of participating client nodes which may impair the learning performance. in this paper we investigate a novel feel framework namely semi decentralized federated edge learning  sd feel  where multiple edge servers collectively coordinate a large number of client nodes. by exploiting the low latency communication among edge servers for efficient model sharing sd feel incorporates more training data while enjoying lower latency compared with conventional federated learning. we detail the training algorithm for sd feel with three steps including local model update intra cluster and inter cluster model aggregations. the convergence of this algorithm is proved on non independent and identically distributed data which reveals the effects of key parameters and provides design guidelines. meanwhile the heterogeneity of edge devices may cause the straggler effect and deteriorate the convergence speed of sd feel. to resolve this issue we propose an asynchronous training algorithm with a staleness aware aggregation scheme of which the convergence is also analyzed. the simulations demonstrate the effectiveness and efficiency of the proposed algorithms for sd feel and corroborate our analysis.", "Pub Date": "2023-06-29"}
{"Title": "AMPeD: An Analytical Model for Performance in Distributed Training of Transformers", "Doi": "10.1109/ISPASS57527.2023.00037", "Authors": ["d. moolchandani", "j. kundu", "f. ruelens", "p. vrancx", "t. evenblij", "m. perumkunnil"], "Key Words": ["analytical modeling", "transformers", "distributed training", "performance"], "Abstract": "transformers are a class of machine learning models that have piqued high interest recently due to a multitude of reasons. they can process multiple modalities efficiently and have excellent scalability. despite these obvious advantages training these large models is very time consuming. hence there have been efforts to speed up the training process using efficient distributed implementations. many different types of parallelism have been identified that can be employed standalone or in combination. however naively combining different parallelization schemes can incur significant communication overheads thereby potentially defeating the purpose of distributed training. thus it becomes vital to predict the right mapping of different parallelisms to the underlying system architecture. in this work we propose amped an analytical model for performance in distributed training of transformers. it exposes all the transformer model parameters potential parallelism choices  along with their mapping onto the system  the accelerator as well as system architecture specffications as tunable knobs thereby enabling hardware software co design. with the help of 3 case studies we show that the combinations of parallelisms predicted to be efficient by amped conform with the results from the state of the art literature. using amped we also show that future distributed systems consisting of optical communication substrates can train large models up to 4\u221a\u00f3 faster as compared to the current state of the art systems without modifying the peak computational power of the accelerators. finally we validate amped with in house experiments on real systems and via published literature. the max. observed error is limited to 12%. the model is available here  https //github.com csa infra amped", "Pub Date": "2023-06-23"}
{"Title": "Flexible and Secure Code Deployment in Federated Learning using Large Language Models: Prompt Engineering to Enhance Malicious Code Detection", "Doi": "10.1109/CloudCom59040.2023.00062", "Authors": ["j. seo", "n. zhang", "c. rong"], "Key Words": ["software engineering", "federated learning", "large language models", "security"], "Abstract": "federated learning is a machine learning methodology that emphasizes data privacy involving minimal interaction with each other\u201a\u00e4\u00f4s systems primarily exchanging model parameters. however this approach can introduce challenges in system development and operation because it inherently faces statistical and system heterogeneity issues. the diverse data storage formats and system environments across clients limit the feasibility of training with a uniform code. to distribute a new code to each environment active participation of federated learning collaborators is necessary incurring time and cost. moreover it impedes adopting modern automated development and deployment paradigms such as devops or mlops. this study investigates how large language models  llms  can automatically tailor a single code to individual client environments in heterogeneous scenarios without human intervention. moreover to enable the automatic adaptation of the deployed code for conducting new experiments within the system it is imperative to assess the presence of potentially malicious code that could jeopardize data security. to address this challenge we introduce a novel prompt engineering technique to enhance llms\u201a\u00e4\u00f4 detection capabilities thereby bolstering our ability to detect malicious code effectively.", "Pub Date": "2024-03-25"}
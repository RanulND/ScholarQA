{"Title": "Image Guided Inpainting with Parameter Efficient Learning", "Doi": "10.1109/ICCVW60793.2023.00118", "Authors": ["s. lim", "s. kim"], "Key Words": ["diffusion", "parameter efficient learning", "image driven inpaint"], "Abstract": "conditional inpainting is the challenging task of generating images that fill in specific regions of an image while preserving the surrounding details based on an arbitrary binary mask and a specified condition  e.g. text or image . existing methods for conditional inpainting often struggle to preserve the appearance of the user\u201a\u00e4\u00f4s subject in the input images and can be computationally expensive to tune for each new condition. in this paper we propose a novel approach to conditional inpainting that combines an image guided inpainting model with a denoising diffusion probabilistic model  ddpm . our approach trains the ddpm model using a small number of user provided images enabling users to insert a subject into any scene even if the poses and views were not present in the tuning data. we also propose a parameter efficient method for training the ddpm that preserves its core performance while reducing the number of retrained parameters. our experimental results demonstrate that our proposed approach outperforms existing methods in terms of both reconstruction quality and computational efficiency making it well suited for use in low resource environments. overall our approach offers a valuable baseline for future research on guided inpainting and personalization.", "Pub Date": "2023-12-25"}
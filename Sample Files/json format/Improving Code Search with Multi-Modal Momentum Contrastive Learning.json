{"Title": "Improving Code Search with Multi-Modal Momentum Contrastive Learning", "Doi": "10.1109/ICPC58990.2023.00043", "Authors": ["z. shi", "y. xiong", "y. zhang", "z. jiang", "j. zhao", "l. wang", "s. li"], "Key Words": ["code search", "contrastive learning", "multi-modal momentum contrast", "pre-trained model"], "Abstract": "contrastive learning has recently been applied to enhancing the bert based pre trained models for code search. however the existing end to end training mechanism cannot sufficiently utilize the pre trained models due to the limitations on the number and variety of negative samples. in this paper we propose mococs a multi modal momentum contrastive learning method for code search to improve the representations of query and code by constructing large scale multi modal negative samples. mococs increases the number and the variety of negative samples through two optimizations  integrating multi batch negative samples and constructing multi modal negative samples. we first build momentum contrasts for query and code which enables the construction of large scale negative samples out of a mini batch. then to incorporate multi modal code information we build multi modal momentum contrasts by encoding the abstract syntax tree and the data flow graph with a momentum encoder. experiments on codesearchnet with six programming languages demonstrate that our method can further improve the effectiveness of pre trained models for code search.", "Pub Date": "2023-07-13"}
{"Title": "Optimal Lower Bounds for Quantum Learning via Information Theory", "Authors": ["s. b. hadiashar", "a. nayak", "p. sinha"], "Pub Date": "2024-02-16", "Abstract": "although a concept class may be learnt more efficiently using quantum samples as compared with classical samples in certain scenarios quantum learners are asymptotically no more efficient than classical ones in the quantum pac and agnostic learning models. lower bounds on sample complexity in these models were previously established via quantum state identification and fourier analysis. in this paper we derive optimal lower bounds for quantum sample complexity in both models via an information theoretic approach. the proofs are arguably simpler and the same ideas can potentially be used to derive optimal bounds for other problems in quantum learning theory. we then turn to a quantum analogue of the coupon collector problem a classic problem from probability theory also of importance in the study of pac learning. the quantum sample complexity of this problem has been characterised up to constant factors. first we show that the information theoretic approach mentioned above provably does not yield the optimal lower bound. as a by product we get a natural ensemble of pure states in arbitrarily high dimensions which are not easily  simultaneously  distinguishable whereas the ensemble has close to maximal holevo information. second we discover that the information theoretic approach yields an asymptotically optimal bound for an approximation variant of the problem. finally we derive a sharper lower bound for the quantum coupon collector problem via the generalised holevo curlander bounds. all the aspects of the problem we study rest on properties of the spectrum of the associated gram matrix which may be of independent interest.", "Doi": "10.1109/TIT.2023.3324527", "Key Words": ["agnostic learning", "coupon collector problem", "data processing inequality", "distinguishability", "gram matrix", "generalised holevo-curlander bounds", "index function", "information-theoretic proofs", "johnson association scheme", "pac learning", "quantum learning theory", "quantum sample complexity", "random walk", "vc. dimension", "von neumann entropy"]}
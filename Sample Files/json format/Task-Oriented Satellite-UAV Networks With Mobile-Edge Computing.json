{"Title": "Task-Oriented Satellite-UAV Networks With Mobile-Edge Computing", "Doi": "10.1109/OJCOMS.2023.3341251", "Authors": ["p. wei", "w. feng", "y. chen", "n. ge", "w. xiang", "s. mao"], "Key Words": ["offloading", "reinforcement learning", "resource allocation", "satellite-uav network", "velocity control"], "Abstract": "networked robots have become crucial for unmanned applications since they can collaborate to complete complex tasks in remote hazardous/depopulated areas. due to the cost inefficiency of deploying cellular network infrastructure in these areas hybrid satellite uav networks emerge as a promising solution. these networks provide seamless and on demand connectivity for multiple robots with various task requirements and support computation intensive and latency sensitive services through mobile edge computing  mec  based offloading. however to complete tasks in limited times the rapid collective movement of mobile robots may cause frequent service migration and a large number of gathered robots may compete for limited bandwidth resources in satellite and uav communications. as a result offloading latency may increase significantly. to address this issue the average completion time of multi robot offloading in task oriented satellite uav networks with mec is formulated as an optimization problem. unlike conventional mobility aware mec based offloading schemes joint optimization of mobility control data offloading and resource allocation is proposed using velocity control of multiple robots. according to lyapunov optimization the original optimization problem is simplified into minimizing the average completion time of offloading for all robots within uav and satellite coverage. a multi agent  $q$  learning algorithm including multi group dual agent  $q$  learning is proposed based on local state observation and global reward calculation. in each dual agent  $q$  learning one agent is responsible for velocity control and communication resource allocation while the other is responsible for data offloading and computational resource allocation. the convergence of the proposed multi agent  $q$  learning algorithm is also theoretically analyzed. simulation results show that the proposed scheme can effectively reduce the offloading latency by up to 35% in the multi robot environment over its conventional counterparts.", "Pub Date": "2024-01-01"}
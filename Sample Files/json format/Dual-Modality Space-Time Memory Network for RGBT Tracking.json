{"Title": "Dual-Modality Space-Time Memory Network for RGBT Tracking", "Authors": ["f. zhang", "h. peng", "l. yu", "y. zhao", "b. chen"], "Pub Date": "2023-06-21", "Abstract": "rgbt tracking is rapidly developing due to its complementary advantages of rgb and thermal frames. existing methods with high accuracy track at a lower speed do not make full use of the hierarchical information in the feature extraction and the historical information of the sequences. to address these issues a novel dual modality space time memory  dmstm  network is proposed for robust rgbt tracking. specifically dmstm is divided into three modules. the first module is the dual modality backbone that uses both shallow and deep information by aggregating feature maps of dimensional changes during downsampling. another module is the space time memory reader with bimodal fusion. it aggregates features of historical and current frames to share information in the time domain. the last module is the siamese head network which computes the predicted loss sum of the two modalities and backpropagates it. this avoids degrading the tracking performance due to sequence frame pairs where the training targets are not perfectly aligned. extensive experiments on three rgbt benchmark datasets show that the performance and efficiency of the proposed dmstm exceed that of the state of the art methods while running at 27.6 frames s.", "Doi": "10.1109/TIM.2023.3282668", "Key Words": ["bimodal fusion", "hierarchical feature", "rgbt tracking", "space-time memory"]}
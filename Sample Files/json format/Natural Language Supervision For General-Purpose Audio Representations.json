{"Title": "Natural Language Supervision For General-Purpose Audio Representations", "Doi": "10.1109/ICASSP48485.2024.10448504", "Authors": ["b. elizalde", "s. deshmukh", "h. wang"], "Key Words": ["contrastive learning", "general purpose audio representation", "zero-shot", "language", "sounds"], "Abstract": "audio language models jointly learn multimodal text and audio representations that enable zero shot inference. models rely on the encoders to create powerful representations of the input and generalize to multiple tasks ranging from sounds music and speech. although models have achieved remarkable performance there is still a gap with task specific models. in this paper we propose a contrastive language audio pretraining model that is pretrained with a diverse collection of 4.6m audio text pairs employing two innovative encoders for zero shot inference. to learn audio representations we trained an audio encoder on 22 audio tasks instead of the standard training of sound event classification. to learn language representations we trained an autoregressive decoder only model instead of the standard encoder only models. then the audio and language representations are brought into a joint multimodal space using contrastive learning. we used our encoders to improve the downstream performance by a large margin. we extensively evaluated the generalization of our representations on 26 downstream tasks the largest in the literature. our model achieves state of the art results in several tasks outperforming 4 different models and leading the way towards general purpose audio representations. code is on github1.", "Pub Date": "2024-03-18"}
{"Title": "Adaptive and Resilient Model-Distributed Inference in Edge Computing Systems", "Doi": "10.1109/OJCOMS.2023.3280174", "Authors": ["p. li", "e. koyuncu", "h. seferoglu"], "Key Words": ["distributed deep neural networks", "edge computing"], "Abstract": "the traditional approach to distributed deep neural network  dnn  inference in edge computing systems is data distributed inference. in this paradigm each worker has a pre trained dnn model. using the dnn model the worker processes the data that is offloaded to itself. the data distributed inference approach  i  has high communication cost especially when the size of data is large and  ii  is not efficient in terms of memory as the whole model should be stored and computed in each worker. model distributed inference is emerging as a promising solution where a dnn model is distributed across workers. although there is a huge amount of work on model distributed training the benefit of model distribution for inference is not understood well. in this paper we analyze the potential of model distributed inference in edge computing systems. then we develop an adaptive and resilient model distributed inference  ar mdi  algorithm based on our optimal model allocation formulation. ar mdi performs model allocation in a lightweight and decentralized way and it is resilient against delayed workers and failures. we implement ar mdi in a real testbed consisting of nvidia jetson tx2s and show that ar mdi improves the inference time significantly as compared to baselines when the size of data is large such as imagenet.", "Pub Date": "2023-06-20"}
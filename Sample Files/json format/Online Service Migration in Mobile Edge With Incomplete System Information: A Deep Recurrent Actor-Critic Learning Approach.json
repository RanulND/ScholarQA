{"Title": "Online Service Migration in Mobile Edge With Incomplete System Information: A Deep Recurrent Actor-Critic Learning Approach", "Doi": "10.1109/TMC.2022.3197706", "Authors": ["j. wang", "j. hu", "g. min", "q. ni", "t. el-ghazawi"], "Key Words": ["deep reinforcement learning", "multi-access edge computing", "partial observable markov decision process", "service migration"], "Abstract": "multi access edge computing  mec  is an emerging computing paradigm that extends cloud computing to the network edge to support resource intensive applications on mobile devices. as a crucial problem in mec service migration needs to decide how to migrate user services for maintaining the quality of service when users roam between mec servers with limited coverage and capacity. however finding an optimal migration policy is intractable due to the dynamic mec environment and user mobility. many existing studies make centralized migration decisions based on complete system level information which is time consuming and also lacks desirable scalability. to address these challenges we propose a novel learning driven method which is user centric and can make effective online migration decisions by utilizing incomplete system level information. specifically the service migration problem is modeled as a partially observable markov decision process  pomdp . to solve the pomdp we design a new encoder network that combines a long short term memory  lstm  and an embedding matrix for effective extraction of hidden information and further propose a tailored off policy actor critic algorithm for efficient training. the extensive experimental results based on real world mobility traces demonstrate that this new method consistently outperforms both the heuristic and state of the art learning driven algorithms and can achieve near optimal results on various mec scenarios.", "Pub Date": "2023-10-03"}
{"Title": "Collaborative Reinforcement Learning for Multi-Service Internet of Vehicles", "Doi": "10.1109/JIOT.2022.3213993", "Authors": ["s. s. shinde", "d. tarchi"], "Key Words": ["computation offloading", "internet of vehicles (iov)", "network selection", "reinforcement learning (rl)"], "Abstract": "internet of vehicles  iov  is a recently introduced paradigm aiming at extending the internet of things  iot  toward the vehicular scenario in order to cope with its specific requirements. nowadays there are several types of vehicles with different characteristics requested services and delivered data types. in order to efficiently manage such heterogeneity edge computing facilities are often deployed in the urban environment usually co located with the roadside units  rsus  for creating what is referenced as vehicular edge computing  vec . in this article we consider a joint network selection and computation offloading optimization problem in multiservice vec environments aiming at minimizing the overall latency and the consumed energy in an iov scenario. two novel collaborative  $q$  learning based approaches are proposed where vehicle to infrastructure  v2i  and vehicle to vehicle  v2v  communication paradigms are exploited respectively. in the first approach we define a collaborative  $q$  learning method in which through v2i communications several vehicles participate in the training process of a centralized  $q$  agent. in the second approach by exploiting the v2v communications each vehicle is made aware of the surrounding environment and the potential offloading neighbors leading to better decisions in terms of network selection and offloading. in addition to the tabular method an advanced deep learning based approach is also used for the action value estimation allowing to handle more complex vehicular scenarios. simulation results show that the proposed approaches improve the network performance in terms of latency and consumed energy with respect to some benchmark solutions.", "Pub Date": "2023-01-23"}
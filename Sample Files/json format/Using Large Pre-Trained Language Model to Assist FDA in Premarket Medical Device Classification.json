{"Title": "Using Large Pre-Trained Language Model to Assist FDA in Premarket Medical Device Classification", "Doi": "10.1109/SoutheastCon51012.2023.10115070", "Authors": ["z. xu"], "Key Words": ["fda premarket regulation", "bert", "pre-trained models", "natural language processing"], "Abstract": "this paper proposes a possible method using natural language processing that might assist in the fda medical device marketing process. actual device descriptions are taken and matched with the device description in fda title 21 of cfr to determine their corresponding device type. both pre trained word embeddings such as fasttext and large pre trained sentence embedding models such as sentence transformers are evaluated on their accuracy in characterizing a piece of device description. an experiment is also done to test whether these models can identify the devices wrongly classified in the fda database. the result shows that sentence transformer with t5 and mpnet and gpt-3 semantic search embedding show high accuracy in identifying the correct classification by narrowing down the correct label to be contained in the first 15 most likely results as compared to 2585 types of device descriptions that must be manually searched through. on the other hand all methods demonstrate high accuracy in identifying completely incorrectly labeled devices but all fail to identify false device classifications that are wrong but closely related to the true label.", "Pub Date": "2023-05-08"}
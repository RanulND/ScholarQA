{"Title": "Zero-Shot Information Extraction with Community-Fine-Tuned Large Language Models From Open-Ended Interview Transcripts", "Doi": "10.1109/ICMLA58977.2023.00138", "Authors": ["n. kazi", "i. kahanda", "s. i. rupassara", "j. w. kindt"], "Key Words": ["machine learning", "text mining", "data extraction", "data analysis", "zero-shot", "large language models", "open-ended survey interviews", "text data analysis efficiency"], "Abstract": "machine learning holds significant promise for automating and optimizing text data analysis. however resource intensive tasks like data annotation model training and parameter tuning often limit its practicality for one time data extraction medium sized datasets or short term projects. there are many community fine tuned large language models  cllms  that are fine tuned on task specific datasets and can demonstrate impressive performance on unseen data without further fine tuning. adopting a hybrid approach of leveraging cllms for rapid text data extraction and subsequently hand curating the inaccurate outputs can yield high quality results workload balance and improved efficiency. this project applies cllms to three tasks involving the analysis of open ended survey responses  semantic text matching exact answer extraction and sentiment analysis. we present our overall process and discuss several seemingly simple yet effective techniques that we employ to improve model performance without fine tuning the cllms on our own data. our results demonstrate high precision in semantic text matching  0.92  and exact answer extraction  0.90  while the sentiment analysis model shows room for improvement  precision  0.65 recall  0.94 f1  0.77 . this study showcases the potential of cllms in open ended survey text data analysis particularly in scenarios with limited resources and scarce labeled data.", "Pub Date": "2024-03-19"}
{"Title": "Generalized Kronecker-based Adapters for Parameter-efficient Fine-tuning of Vision Transformers", "Doi": "10.1109/CRV60082.2023.00020", "Authors": ["a. edalati", "m. g. abdel hameed", "a. mosleh"], "Key Words": ["parameter-efficient fine-tuning", "kronecker product", "adapters", "transformers"], "Abstract": "while large transformer based vision models have achieved remarkable performance on a variety of computer vision  cv  applications they are cumbersome to fine tune for target tasks. however such models pre trained on large scale datasets are suspected to exhibit a low intrinsic dimension during fine tuning. this suggests fewer parameters can be optimized during the fine tuning stage to achieve a similar level of performance. parameter efficient fine tuning  peft  methods have been introduced to leverage this property by limiting the optimization to a subspace of the trainable parameters during fine tuning. utilizing low rank projection matrices as adapter modules has been shown to be a good approach. however it has been predominantly explored for transformer based language models and their linear layers while there is an increasing interest to use convolutional layers jointly with linear layers in transformer based vision models. in this work we introduce adapters to bypass gradient updating of the pre trained transformer blocks of vision models during fine tuning. our adapters are designed using sequences of low rank kronecker products that provide a factorized representation of large tensors resulting in an efficient fine tuning parameter space for fine tuning. since our adapter weights are merged with the original pre trained model weights the proposed peft method does not add extra computations or memory footprints in the inference stage. experimental results for image classification using vit i.e. the original transformer based vision model and the convolution enhanced transformer models  ceit and cvt substantiate the effectiveness of our proposed approach. our proposed method outperforms state of the art peft methods.", "Pub Date": "2023-08-29"}
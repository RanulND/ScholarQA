{"Title": "Energy Efficient Computation Offloading in Aerial Edge Networks With Multi-Agent Cooperation", "Doi": "10.1109/TWC.2023.3235997", "Authors": ["w. liu", "b. li", "w. xie", "y. dai", "z. fei"], "Key Words": ["mobile edge computing", "unmanned aerial vehicle", "computation offloading", "deep reinforcement learning", "digital twin"], "Abstract": "with the high flexibility of supporting resource intensive and time sensitive applications unmanned aerial vehicle  uav  assisted mobile edge computing  mec  is proposed as an innovational paradigm to support the mobile users  mus . as a promising technology digital twin  dt  is capable of timely mapping the physical entities to virtual models and reflecting the mec network state in real time. in this paper we first propose an mec network with multiple movable uavs and one dt empowered ground base station to enhance the mec service for mus. considering the limited energy resource of both mus and uavs we formulate an online problem of resource scheduling to minimize the weighted energy consumption of them. to tackle the difficulty of the combinational problem we formulate it as a markov decision process  mdp  with multiple types of agents. since the proposed mdp has huge state space and action space we propose a deep reinforcement learning approach based on multi agent proximal policy optimization  mappo  with beta distribution and attention mechanism to pursue the optimal computation offloading policy. numerical results show that our proposed scheme is able to efficiently reduce the energy consumption and outperforms the benchmarks in performance convergence speed and utilization of resources.", "Pub Date": "2023-09-11"}
{"Title": "Deep Reinforcement Learning for Shared Offloading Strategy in Vehicle Edge Computing", "Doi": "10.1109/JSYST.2022.3190926", "Authors": ["x. peng", "z. han", "w. xie", "c. yu", "p. zhu", "j. xiao", "j. yang"], "Key Words": ["deep reinforcement learning (drl)", "internet of vehicles (iovs)", "task shared offloading", "vehicular edge computing (vec)"], "Abstract": "vehicular edge computing  vec  effectively reduces the computing load of vehicles by offloading computing tasks from vehicle terminals to edge servers. however offloading of tasks increase in quantity the transmission time and energy of the network. in order to reduce the computing load of edge servers and improve the system response a shared offloading strategy based on deep reinforcement learning is proposed for the complex computing environment of internet of vehicles  iovs . the shared offloading strategy exploits the commonality of vehicles task requests similar computing tasks coming from different vehicles can share the computing results of former task submitted. the shared offloading strategy can be adapted to the complex scenarios of the iovs. each vehicle can share the offloading conditions of the vec servers and then adaptively select three computing modes  local execution task offloading and shared offloading. in this article the network state and offloading strategy space are the input of the deep reinforcement learning  drl . through the drl each task unit selects the offloading strategy with the optimal energy consumption at each time period in the dynamic iovs transmission and computing environment. compared with the existing proposals and drl based algorithms it can effectively reduce the delay and energy consumption required for tasks offloading.", "Pub Date": "2023-06-08"}
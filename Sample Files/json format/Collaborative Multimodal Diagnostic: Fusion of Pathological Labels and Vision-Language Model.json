{"Title": "Collaborative Multimodal Diagnostic: Fusion of Pathological Labels and Vision-Language Model", "Doi": "10.1109/ICHIH60370.2023.10396187", "Authors": ["w. chen", "y. li", "b. ou", "p. tan"], "Key Words": ["langchain", "chest x-ray", "multimodal language macromodel"], "Abstract": "large vision language models are remarkable and significantly improve the semantic understanding of images and demonstrate the ability in varies tasks. for those models they were mostly trained using massive datasets with image text pairs across various scenarios. nevertheless most of them provide a general understanding and superficial semantic information about images and cannot infer in depth results in specific domains such as radiology. model fine tune technology with biomedical reports can be applied to enhance the performance of analytics however it is resource intensive and difficult to further expand. in this work we proposed a novel framework combining computer vision network and vision language model which is able to analyze and answer the query on the chest radiographs. a state of the art network is used to pre process the radiographs and extract the detailed pathological labels. the relevant label information will be integrated into the flow as a system message prompt allowing the vision language model to deduce deeper levels of disease information without the need for prerequisite model fine tuning. our approach opens up a new methodology for chest radiograph analytics and reasoning about biomedical images.", "Pub Date": "2024-01-23"}
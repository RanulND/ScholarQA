{"Title": "LogiQA 2.0\u201a\u00c4\u00eeAn Improved Dataset for Logical Reasoning in Natural Language Understanding", "Doi": "10.1109/TASLP.2023.3293046", "Authors": ["h. liu", "j. liu", "l. cui", "z. teng", "n. duan", "m. zhou", "y. zhang"], "Key Words": ["reading comprehension", "logical reasoning", "natural language inference", "textual inference"], "Abstract": "nlp research on logical reasoning regains momentum with the recent releases of a handful of datasets notably logiqa and reclor. logical reasoning is exploited in many probing tasks over large pre trained language models  plms  and downstream tasks like question answering and dialogue systems. in this article we release logiqa 2.0. the dataset is an amendment and re annotation of logiqa in 2020 a large scale logical reasoning reading comprehension dataset adapted from the chinese civil service examination. we increase the data size refine the texts with manual translation by professionals and improve the quality by removing items with distinctive cultural features like chinese idioms. furthermore we conduct a fine grained annotation on the dataset and turn it into a two way natural language inference  nli  task resulting in 35 k premise hypothesis pairs with gold labels making it the first large scale nli dataset for complex logical reasoning. compared to question answering natural language inference excels in generalizability and helps downstream tasks better. we establish a baseline for logical reasoning in nli and incite further research.", "Pub Date": "2023-08-09"}
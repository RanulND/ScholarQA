{"Title": "A Co-Scheduling Framework for DNN Models on Mobile and Edge Devices With Heterogeneous Hardware", "Doi": "10.1109/TMC.2021.3107424", "Authors": ["z. xu", "d. yang", "c. yin", "j. tang", "y. wang", "g. xue"], "Key Words": ["mobile computing", "edge computing", "deep learning", "deep reinforcement learning", "on-device dnn inference"], "Abstract": "with the emergence of more and more powerful chipsets and hardware and the rise of artificial intelligence of things  aiot  there is a growing trend for bringing deep neural network  dnn  models to empower mobile and edge devices with intelligence such that they can support attractive artificial intelliegence applications on the edge in a real time or near real time manner. to leverage heterogeneous computational resources  such as cpu gpu dsp etc  to effectively and efficiently support concurrent inference of multiple dnn models on a mobile or edge device we propose a novel online co scheduling framework based on deep reinforcement learning  drl  which we call cosrel. cosrel has the following desirable features  1  it achieves significant speedup over commonly used methods by efficiently utilizing all the computational resources on heterogeneous hardware  2  it leverages emerging deep reinforcement learning  drl  to make dynamic and wise online scheduling decisions based on system runtime state  3  it is capable of making a good tradeoff among inference latency throughput and energy efficiency  and 4  it makes no changes to given dnn models thus preserves their accuracies. to validate and evaluate cosrel we conduct extensive experiments on an off the shelf android smartphone with widely used dnn models to compare it with three commonly used baselines. our experimental results show that 1  cosrel consistently and significantly outperforms all the baselines in terms of both throughput and latency  and 2  cosrel is generally superior to all the baselines in terms of energy efficiency.", "Pub Date": "2023-02-03"}
{"Title": "Document-Level Mathematical Relation Extraction Using Pre-Training Models", "Doi": "10.1109/ICCWAMTIP60502.2023.10387128", "Authors": ["g. zhengyong", "z. xiuqin"], "Key Words": ["mathematical relation extraction", "docre", "pre-training model", "adaptive thresholding", "evidence context pooling", "evidence retrieval"], "Abstract": "mathematical relation extraction is pivotal for identifying relationships between entities in texts a crucial step in aiding automated systems to comprehend the semantics of mathematical content. while prior studies have concentrated on sentence level relation extraction  re  their applicability in real world scenarios remains limited. document level re  docre  in contrast poses a more complex challenge necessitating multi sentence reasoning and the prediction of relationships across entire documents. the scarcity of high  quality datasets attributed to the constraints of manual data annotation further complicates this task. in our study we focus on extracting relationships from mathematical documents through document level re techniques. to effectively tackle the complexities of multi label and multi entity scenarios in document level re we introduce two innovative methods  adaptive thresholding and evidence context pooling. these approaches allow document level re systems to focus on relevant text significantly enhancing relation extraction capabilities. furthermore we implement a self training strategy to learn evidence retrieval knowledge from a large amount of distantly supervised data that lacks specific evidence annotations. our experimental findings affirm the success of these methods showcasing an impressive accuracy rate reaching up to 90.14% in the domain of mathematical relation extraction.", "Pub Date": "2024-01-18"}
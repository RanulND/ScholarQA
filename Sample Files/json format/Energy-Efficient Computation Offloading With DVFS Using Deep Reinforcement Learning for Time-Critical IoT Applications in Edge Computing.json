{"Title": "Energy-Efficient Computation Offloading With DVFS Using Deep Reinforcement Learning for Time-Critical IoT Applications in Edge Computing", "Doi": "10.1109/JIOT.2022.3153399", "Authors": ["s. k. panda", "m. lin", "t. zhou"], "Key Words": ["deep reinforcement learning (drl)", "dynamic voltage and frequency scaling", "edge computing (ec)", "edge server", "energy consumption", "internet of things (iot)", "offloading"], "Abstract": "internet of things  iot  is a technology that allows ordinary physical devices to collect process and share data with other physical devices and systems over the internet. it provides pervasively connected infrastructures to support innovative applications and services that can automate otherwise intensely laborious manual effort. edge computing  ec  complements the powerful centralized cloud servers by providing powerful computation capability close to the data source minimizing communication latency and securing data privacy. the energy consumption problem has continued to receive much attention from the iot community in applying various techniques to reduce energy consumption while still meeting the computational demand. in this article we propose an application deadline aware data offloading scheme using deep reinforcement learning and dynamic voltage and frequency scaling  dvfs  in an ec environment to reduce the energy consumption of iot devices. the proposed scheme learns the optimal data distribution policies and local computation dvfs frequency scaling by interacting with the system environment and learning the behavior of the device network and edge servers. the proposed scheme was tested on multiple ec environments with different iot devices. experimental results show that this scheme can reduce energy consumption while achieving the iot application and services timing and computational goals. the proposed scheme has substantial energy savings when compared with the native linux governors.", "Pub Date": "2023-04-06"}
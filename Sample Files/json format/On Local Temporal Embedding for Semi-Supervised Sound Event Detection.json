{"Title": "On Local Temporal Embedding for Semi-Supervised Sound Event Detection", "Doi": "10.1109/TASLP.2024.3369529", "Authors": ["l. gao", "q. mao", "m. dong"], "Key Words": ["local temporal embedding", "masked spectrogram modeling", "self-supervision", "semi-supervised sound event detection"], "Abstract": "semi supervised sound event detection  ssed  task requires recognizing the categories of events and marking each event onset and offset times in a mixed audio recording using a small amount of weakly labeled and a large scale of unlabeled data. so exploring local temporal information i.e. local discrimination and local correlations in the time domain is essential for ssed and in particular for precise event boundary detection. besides as manual labeled datasets are scarce ssed tasks require effectively exploiting unlabelled data to reduce overfitting typically through regularization techniques. recently self supervised learning provided a viable solution to leverage unlabeled data for effective feature learning in various downstream tasks. in this paper we propose lte net a novel multitask framework to learn the local temporal embedding for ssed. specifically lte net first locally down samples the input spectrogram and learns the token embeddings with a high temporal resolution  i.e. local discrimination . then lte net effectively models the local correlations among the token embeddings through self supervised masked spectrogram modeling. finally a novel joint  self  and semi supervision  regularization framework is employed for the training of lte net to effectively leverage unlabeled data in ssed. extensive experiments on dcase 2019 2020 and 2021 ssed datasets show that lte net significantly outperformed existing methods and achieved 2.1% to 8.7% 2.1% to 3.9% and 1.2% to 6.1% performance gains on the evaluation set in 2019 2020 and 2021 datasets respectively.", "Pub Date": "2024-03-07"}
{"Title": "Improving Audio Captioning Models with Fine-Grained Audio Features, Text Embedding Supervision, and LLM Mix-Up Augmentation", "Doi": "10.1109/ICASSP48485.2024.10447215", "Authors": ["s. -l. wu", "x. chang", "g. wichern", "j. -w. jung", "f. germain", "j. le roux", "s. watanabe"], "Key Words": ["aac", "beats", "llm", "mix-up", "infonce"], "Abstract": "automated audio captioning  aac  aims to generate informative descriptions for various sounds from nature and or human activities. in recent years aac has quickly attracted research interest with state of the art systems now relying on a sequence to sequence  seq2seq  backbone powered by strong models such as transformers. following the macro trend of applied machine learning research in this work we strive to improve the performance of seq2seq aac models by extensively leveraging pretrained models and large language models  llms . specifically we utilize beats to extract fine grained audio features. then we employ instructor llm to fetch text embeddings of captions and infuse their language modality knowledge into beats audio features via an auxiliary infonce loss function. moreover we propose a novel data augmentation method that uses chatgpt to produce caption mix ups  i.e. grammatical and compact combinations of two captions  which together with the corresponding audio mixtures increase not only the amount but also the complexity and diversity of training data. during inference we propose to employ nucleus sampling and a hybrid reranking algorithm which has not been explored in aac research. combining our efforts our model achieves a new state of the art 32.6 spider fl score on the clotho evaluation split and wins the 2023 dcase aac challenge.", "Pub Date": "2024-03-18"}
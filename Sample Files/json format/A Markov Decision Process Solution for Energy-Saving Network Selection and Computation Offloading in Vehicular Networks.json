{"Title": "A Markov Decision Process Solution for Energy-Saving Network Selection and Computation Offloading in Vehicular Networks", "Doi": "10.1109/TVT.2023.3264504", "Authors": ["s. s. shinde", "d. tarchi"], "Key Words": ["vehicular edge computing", "network selection", "computation offloading", "energy saving mechanisms", "markov decision process"], "Abstract": "vehicular edge computing  vec  enables the integration of edge computing facilities in vehicular networks  vns  allowing data intensive and latency critical applications and services to end users. though vec brings several benefits in terms of reduced task computation time energy consumption backhaul link congestion and data security risks vec servers are often resource constrained. therefore the selection of proper edge nodes and the amount of data to be offloaded becomes important for having vec process benefits. however with the involvement of high mobility vehicles and dynamically changing vehicular environments proper vec node selection and data offloading can be challenging. in this work we consider a joint network selection and computation offloading problem over a vec environment for minimizing the overall latency and energy consumption during vehicular task processing considering both user and infrastructure side energy saving mechanisms. we have modeled the problem as a sequential decision making problem and incorporated it in a markov decision process  mdp . numerous vehicular scenarios are considered based upon the users' positions the states of the surrounding environment and the available resources for creating a better environment model for the mdp analysis. we use a value iteration algorithm for finding an optimal policy of the mdps over an uncertain vehicular environment. simulation results show that the proposed approaches improve the network performance in terms of latency and consumed energy.", "Pub Date": "2023-09-18"}
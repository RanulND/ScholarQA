{"Title": "8-b Precision 8-Mb ReRAM Compute-in-Memory Macro Using Direct-Current-Free Time-Domain Readout Scheme for AI Edge Devices", "Doi": "10.1109/JSSC.2022.3200515", "Authors": ["j. -m. hung", "t. -h. wen", "y. -h. huang", "s. -p. huang", "f. -c. chang", "c. -i. su", "w. -s. khwa", "c. -c. lo", "r. -s. liu", "c. -c. hsieh", "k. -t. tang", "y. -d. chih", "t. -y. j. chang", "m. -f. chang"], "Key Words": ["artificial intelligence (ai)", "computing-in-memory", "convolutional neural network (cnn) edge processors", "multiply-and-accumulate (mac)", "resistive random access memory (reram)"], "Abstract": "compute in memory  nvcim  macros based on non volatile memory make it possible for artificial intelligence  ai  edge devices to perform energy efficient multiply and accumulate  mac  operations by minimizing the movement of data between the processors and memory. however nvcim imposes tradeoffs between energy efficiency computing latency and readout accuracy against process variation. to overcome these challenges this work proposed a nvcim macro featuring  1  a direct current free time space based in memory computing  dcfts imc  scheme  2  a wordline based serial access computing  wsac  scheme  3  an integration based voltage to time converter  ivtc   and 4  a hidden latency time to mac value conversion  hltmc  scheme. the proposed 22 nm 8 mb resistive random access memory cim  reram cim  macro was fabricated to demonstrate mac operations with 8 b input 8 b weight and 19 b output. our nvcim macro achieved computing latency of 14.4 ns under 8 b precision with an energy efficiency of 21.6 tops w.", "Pub Date": "2022-12-27"}
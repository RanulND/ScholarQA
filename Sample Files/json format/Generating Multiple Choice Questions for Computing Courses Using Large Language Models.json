{"Title": "Generating Multiple Choice Questions for Computing Courses Using Large Language Models", "Doi": "10.1109/FIE58773.2023.10342898", "Authors": ["a. tran", "k. angelikas", "e. rama", "c. okechukwu", "d. h. smith", "s. macneil"], "Key Words": ["large language models", "generative ai", "multiple-choice questions", "computing education"], "Abstract": "generating high quality multiple choice questions  mcqs  is a time consuming activity that has led practitioners and researchers to develop community question banks and reuse the same questions from semester to semester. this results in generic mcqs which are not relevant to every course. template based methods for generating mcqs require less effort but are similarly limited. at the same time advances in natural language processing have resulted in large language models  large language model  that are capable of doing tasks previously reserved for people such as generating code code explanations and programming assignments. in this paper we investigate whether these generative capabilities of large language model can be used to craft high quality m cqs more efficiently thereby enabling instructors to focus on personalizing mcqs to each course and the associated learning goals. we used two large language model gpt-3 and gpt 4 to generate isomorphic mcqs based on mcqs from the canterbury question bank and an introductory to low level c programming course. we evaluated the resulting mcqs to assess their ability to generate correct answers based on the question stem a task that was previously not possible. finally we investigate whether there is a correlation between model performance and the discrimination score of the associated mcq to understand whether low discrimination questions required the model to do more inference and therefore perform poorly. gpt-4 correctly generated the answer for 78.5% of mcqs based only on the question stem. this suggests that instructors could use these models to quickly draft quizzes such as during a live class to identify misconceptions in real time. we also replicate previous findings that gpt-3 performs poorly on answering or in our case generating correct answers to mcqs. we also present cases we observed where large language model struggled to produce correct answers. finally we discuss implications for computing education.", "Pub Date": "2024-01-05"}
{"Title": "Computation Offloading for Edge Intelligence in Two-Tier Heterogeneous Networks", "Doi": "10.1109/TNSE.2023.3332949", "Authors": ["j. zhao", "q. li", "x. ma", "f. r. yu"], "Key Words": ["edge intelligence", "computation offloading", "resource allocation", "spectrum sharing", "heterogeneous networks"], "Abstract": "drivenby the increasing need of massive data analysis and the rising concern about data privacy implementing machine learning  ml  at network edge is drawing increasing attention where local users are expected to process massive raw data without sharing data to a remote central server. however due to the limited computing power of user equipments how to deal with the rich data is a critical problem for each user. based on computation offloading and edge learning we propose an edge intelligence  ei  learning framework in two tier heterogeneous networks to alleviate the computing pressure of users. focusing on the minimum time delay of model training we analyze the completion time of local learning in parallel manner and obtain the optimal offloading ratio in the proposed ei framework. aiming at the strict interference constraint of the macrocell base station  mbs  a priority based power allocation algorithm is designed. the analysis and simulation results verify the proposed algorithm can improve the data transmission rate and reduce the task completion time while satisfying the interference constraints of the mbs and maximum tolerable delay of learning tasks. in addition the partial computation offloading can effectively improve the learning accuracy within a given learning time budget.", "Pub Date": "2024-02-22"}
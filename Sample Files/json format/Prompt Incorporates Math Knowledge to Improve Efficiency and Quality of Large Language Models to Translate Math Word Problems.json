{"Title": "Prompt Incorporates Math Knowledge to Improve Efficiency and Quality of Large Language Models to Translate Math Word Problems", "Doi": "10.1109/IEIR59294.2023.10391245", "Authors": ["h. wu", "x. yu"], "Key Words": ["prompt engineering", "large language models", "natural language translation"], "Abstract": "large language models  large language model  models perform excellently in normal translation tasks  but are not effective in translating math word problems  mwps  with large language model. the main problems can be summarized into two categories  one is that large language model are unable to accurately translate specific mathematical knowledge in mwps such as formulas and mathematical patterns. the other is that large language model often generate redundant content unrelated to the translation of mwps. this research aims to investigate how to define the format of prompt and incorporate mathematical knowledge to improve the efficiency and quality of translating mwps by large language model. firstly the input and output formats of prompt are defined to reduce the generation of content unrelated to the translation of mwps. secondly it is found that simply defining the roles and capabilities of large language model in a zero shot setting cannot improve the effectiveness of large language model in translating mwps and even leads to a decrease in translation quality. this paper finds that the reason for the low quality phenomenon of large language model in translating mwps is due to the lack of corresponding mathematical knowledge therefore this paper summarizes some of the mathematical knowledge that needs to be involved in translating mwps and integrates it into prompt so that the effect of large language model in translating mwps has been significantly improved.", "Pub Date": "2024-01-16"}
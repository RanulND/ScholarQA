{"Title": "Cost-Efficient Sharing Algorithms for DNN Model Serving in Mobile Edge Networks", "Doi": "10.1109/TSC.2023.3247049", "Authors": ["h. dai", "j. wu", "y. wang", "j. yen", "y. zhang", "c. xu"], "Key Words": ["cost efficiency", "deep neural network", "mobile edge computing", "model sharing", "online algorithm"], "Abstract": "with the fast growth of mobile edge computing  mec  the deep neural network  dnn  has gained more opportunities in application to various mobile services. given the tremendous number of learning parameters and large model size the dnn model is often trained in cloud center and then dispatched to end devices for inference via edge network. therefore maximizing the cost efficiency of learned model dispatch in the edge network would be a critical problem for the model serving in various application contexts. to reach this goal in this article we focus mainly on reducing the total model dispatch cost in the edge network while maintaining the efficiency of the model inference. we first study this problem in its off line form as a baseline where a sequence of $n$n requests can be pre defined in advance and exploit dynamic programming techniques to obtain a fast optimal algorithm in time complexity of $o m^{2}n $o m2n  under a semi homogeneous cost model in a $m$m sized network. then we design and implement a 2.5 competitive algorithm for its online case with a provable lower bound of 2 for any deterministic online algorithm. we verify our results through careful algorithmic analysis and validate their actual performance via a trace based study based on a public open international mobile network dataset.", "Pub Date": "2023-08-08"}
{"Title": "Toward Auto-Modeling of Formal Verification for NextG Protocols: A Multimodal Cross- and Self-Attention Large Language Model Approach", "Doi": "10.1109/ACCESS.2024.3366803", "Authors": ["j. yang", "y. wang"], "Key Words": ["formal verification", "cross-attention", "self-attention", "natural language protocol", "formal flow graph"], "Abstract": "this paper introduces auto modeling of formal verification with real world prompting for 5g and nextg protocols  avre  a novel system designed for the formal verification of next generation  nextg  communication protocols addressing the increasing complexity and scalability challenges in network protocol design and verification. utilizing large language models  llms  avre transforms protocol descriptions into dependency graphs and formal models efficiently resolving ambiguities and capturing design intent. the system integrates a transformer model with llms to autonomously establish quantifiable dependency relationships through cross  and self attention mechanisms. enhanced by iterative feedback from the hyfuzz experimental platform avre significantly advances the accuracy and relevance of formal verification in complex communication protocols offering a groundbreaking approach to validating sophisticated communication systems. we compare cal\u201a\u00e4\u00f4s performance with state of the art llm based models and traditional time sequence models demonstrating its superiority in accuracy and robustness achieving an accuracy of 95.94% and an auc of 0.98. this nlp based approach enables for the first time the creation of exploits directly from design documents making remarkable progress in scalable system verification and validation.", "Pub Date": "2024-02-27"}
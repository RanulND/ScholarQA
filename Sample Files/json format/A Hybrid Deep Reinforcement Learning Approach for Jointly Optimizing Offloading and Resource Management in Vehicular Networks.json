{"Title": "A Hybrid Deep Reinforcement Learning Approach for Jointly Optimizing Offloading and Resource Management in Vehicular Networks", "Doi": "10.1109/TVT.2023.3312340", "Authors": ["c. -l. chen", "b. bhargava", "v. aggarwal", "b. tonshal", "a. gopal"], "Key Words": ["multiple-access edge computing", "caching", "software-defined networking", "deep reinforcement learning"], "Abstract": "satisfying the quality of service of data intensive autonomous driving applications has become challenging. in this work we propose a novel methodology that optimizes communication computation and caching configurations in a vehicular multi access edge computing  mec  system to minimize the average latency of the tasks from the vehicles and maximize the number of tasks finished within the latency requirements. the communication model characterizes bandwidth and power allocation of uplink and downlink transmission in the vehicular mec system. our caching model includes variables for each edge server in determining the trade off between flexibility and hit rate. finally the computation model characterizes computation resource allocation. our method for solving the optimization problem consists of two main steps. first the deep q learning algorithm deals with the optimal assignment of tasks to the edge servers. then a greedy approach is applied to the communication computation and caching subproblems to decide the bandwidth and power cpu and caching strategy respectively. simulation results show that our algorithm outperforms several baselines in minimizing latency and maximizing the number of tasks finished within latency requirements and verify the benefit of including different resource allocation variables in our optimization.", "Pub Date": "2024-02-12"}
{"Title": "Automatic Recognition of Emotions in Speech With Large Self-Supervised Learning Transformer Models", "Doi": "10.1109/AIBThings58340.2023.10292462", "Authors": ["m. p. gavali", "a. verma"], "Key Words": ["speech emotion recognition", "self-supervised learning", "emotion ai", "transformers", "speech processing", "acoustic features"], "Abstract": "speech emotion recognition  ser  is an important area of research in the realm of collaborative and social robotics which aims to enhance human robot interaction  hri  and serves as a feedback mechanism for affective computing. despite the recent progress in ser research area it remains a challenging research problem due to the profound variations in the complexity subjectivity and contextual heterogeneity of human emotional expressions. consequently the inherent difficulties of modeling paralinguistic emotional information embedded in speech signals are further compounded when employing supervised learning as it necessitates annotated labels for a large scale dataset for satisfactory model performance. to this end self supervised learning  ssl  approach is widely adopted in the speech domain to addresses this problem of limited availability of annotated data.therefore the focus of our research is to investigate and evaluate several state of the art large attention based self supervised learning  ssl  models for the task of automatic speech emotion recognition  ser  on the challenging ravdess dataset. results of the four large ssl models on the ravdess dataset are promising. in particular hubert large model achieved highest accuracy of 88% with a much lower training time and lower model size on disk compared to the rest of the models.", "Pub Date": "2023-10-30"}
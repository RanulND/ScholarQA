{"Title": "Privacy Preservation for Federated Learning With Robust Aggregation in Edge Computing", "Doi": "10.1109/JIOT.2022.3229122", "Authors": ["w. liu", "x. xu", "d. li", "l. qi", "f. dai", "w. dou", "q. ni"], "Key Words": ["edge computing", "federated learning (fl)", "privacy preservation", "security"], "Abstract": "benefiting from the powerful data analysis and prediction capabilities of artificial intelligence  ai  the data on the edge is often transferred to the cloud center for centralized training to obtain an accurate model. to resist the risk of privacy leakage due to frequent data transmission between the edge and the cloud federated learning  fl  is engaged in the edge paradigm uploading the model updated on the edge server  es  to the central server for aggregation instead of transferring data directly. however the adversarial es can infer the update of other ess from the aggregated model and the update may still expose some characteristics of data of other ess. besides there is a certain probability that the entire aggregation is disrupted by the adversarial ess through uploading a malicious update. in this article a privacy preserving fl scheme with robust aggregation in edge computing is proposed named fl raec. first the hybrid privacy preserving mechanism is constructed to preserve the integrity and privacy of the data uploaded by the ess. for the robust model aggregation a phased aggregation strategy is proposed. specifically anomaly detection based on autoencoder is performed while some ess are selected for anonymous trust verification at the beginning. in the next stage via multiple rounds of random verification the trust score of each es is assessed to identify the malicious participants. eventually fl raec is evaluated in detail depicting that fl raec has strong robustness and high accuracy under different attacks.", "Pub Date": "2023-04-06"}
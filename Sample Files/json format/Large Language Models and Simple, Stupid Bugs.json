{"Title": "Large Language Models and Simple, Stupid Bugs", "Doi": "10.1109/MSR59073.2023.00082", "Authors": ["k. jesse", "t. ahmed", "p. t. devanbu", "e. morgan"], "Key Words": ["language models", "prompting", "deep learning", "software engineering"], "Abstract": "with the advent of powerful neural language models artificial intelliegence based systems to assist developers in coding tasks are becoming widely available  copilot is one such system. copilot uses codex a large language model  large language model  to complete code conditioned on a preceding \"prompt\". codex however is trained on public github repositories viz. on code that may include bugs and vulnerabilities. previous studies   show codex reproduces vulnerabilities seen in training. in this study we examine how prone codex is to generate an interesting bug category single statement bugs commonly referred to as simple stupid bugs or sstubs in the msr community. we find that codex and similar large language model do help avoid some sstubs but do produce known verbatim sstubs as much as 2x as likely than known verbatim correct code. we explore the consequences of the codex generated sstubs and propose avoidance strategies that suggest the possibility of reducing the production of known verbatim sstubs and increase the possibility of producing known verbatim fixes.", "Pub Date": "2023-07-12"}
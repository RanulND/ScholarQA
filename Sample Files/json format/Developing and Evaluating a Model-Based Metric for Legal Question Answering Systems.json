{"Title": "Developing and Evaluating a Model-Based Metric for Legal Question Answering Systems", "Doi": "10.1109/BigData59044.2023.10386689", "Authors": ["d. bakir", "b. yildiz", "m. s. aktas"], "Key Words": ["question answering systems", "model-based evaluation metric", "natural language processing", "transformer models", "large language model"], "Abstract": "in the complicated world of legal law question answering  qa  systems only work if they can give correct situation aware and logically sound answers. traditional evaluation methods which rely on superficial similarity measures can\u201a\u00e4\u00f4t catch the complex accuracy and reasoning needed in legal answers. this means that evaluation methods need to change completely. to fix the problems with current methods this study presents a new model based evaluation metric that is designed to work well with legal qa systems. we are looking into the basic ideas that are needed for this kind of metric as well as the problems of putting it into practice in the real world finding the right technological frameworks creating good evaluation methods. we talk about a theory framework that is based on legal standards and computational linguistics. we also talk about how the metric was created and how it can be used in real life. our results which come from thorough tests show that our suggested measure is better than existing ones. it is more reliable accurate and useful for judging legal quality assurance systems.", "Pub Date": "2024-01-22"}
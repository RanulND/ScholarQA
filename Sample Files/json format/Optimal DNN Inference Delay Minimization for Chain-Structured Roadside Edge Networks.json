{"Title": "Optimal DNN Inference Delay Minimization for Chain-Structured Roadside Edge Networks", "Doi": "10.1109/TVT.2023.3290019", "Authors": ["x. wan", "t. ji", "x. guan", "a. zhu", "f. ye"], "Key Words": ["smart edge", "edge computing", "dnn offloading"], "Abstract": "edge artificial intelligence  artificial intelliegence  has emerged as a promising paradigm catering to overwhelming explosions of smart applications by offloading the computation intensive deep neural network  dnn  inference to an edge network for processing. the surging of edge artificial intelliegence brings new vigor and vitality to shape the prospect of smart transportation. however when considering the cooperation between heterogeneous edge devices and the operation precedence between dnn tasks it is still challenging to decompose a dnn across multiple edge devices in an edge network with a general topology to minimize dnn inference delay. in this article we devise a polynomial time optimal solution to the dnn inference offloading problem for smart roadside applications in which the roadside edge network is usually organized with chain topology. specifically the dnn inference offloading problem for the roadside edge network with chain topology is transformed into an equivalent graph optimization problem. theoretical analysis and extensive evaluations validate the performance of the proposed solution in minimizing the total inference delay.", "Pub Date": "2023-12-18"}
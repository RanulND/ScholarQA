{"Title": "On Codex Prompt Engineering for OCL Generation: An Empirical Study", "Doi": "10.1109/MSR59073.2023.00033", "Authors": ["s. abukhalaf", "m. hamdaqa", "f. khomh"], "Key Words": ["codex", "prompt engineering", "object constraint language (ocl)", "code generation", "large language models"], "Abstract": "the object constraint language  ocl  is a declarative language that adds constraints and object query expressions to meta object facility  mof  models. ocl can provide precision and conciseness to uml models. nevertheless the unfamiliar syntax of ocl has hindered its adoption by software practitioners. large language model such as gpt 3 have made significant progress in many nlp tasks such as text generation and semantic parsing. similarly researchers have improved on the downstream tasks by fine tuning large language model for the target task. codex a gpt-3 descendant by openai has been fine tuned on publicly available code from github and has proven the ability to generate code in many programming languages powering the artificial intelliegence pair programmer copilot. one way to take advantage of codex is to engineer prompts for the target downstream task. in this paper we investigate the reliability of the ocl constraints generated by codex from natural language specifications. to achieve this we compiled a dataset of 15 uml models and 168 specifications from various educational resources. we manually crafted a prompt template with slots to populate with the uml information and the target task in the prefix format to complete the template with the generated ocl constraint. we used both zero  and few shot learning methods in the experiments. the evaluation is reported by measuring the syntactic validity and the execution accuracy metrics of the generated ocl constraints. moreover to get insight into how close or natural the generated ocl constraints are compared to human written ones we measured the cosine similarity between the sentence embedding of the correctly generated and human written ocl constraints. our findings suggest that by enriching the prompts with the uml information of the models and enabling few shot learning the reliability of the generated ocl constraints increases. furthermore the results reveal a close similarity based on sentence embedding between the generated ocl constraints and the human written ones in the ground truth implying a level of clarity and understandability in the generated ocl constraints by codex.", "Pub Date": "2023-07-12"}
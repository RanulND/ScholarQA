{"Title": "FeatureMix: A General Adversarial Defense Method for Pretrained Language Models", "Doi": "10.1109/GLOBECOM54140.2023.10436846", "Authors": ["h. dong", "l. wu", "z. guan"], "Key Words": ["adversarial machine learning", "pretrained language model", "adversarial training", "data augmentation"], "Abstract": "pretrained language models  plms  that are trained over large scale data and then finetuned on downstream tasks have achieved great success. however they are vulnerable to adversarial attacks. adversarial training with both clean and adversarial data is a widely used technique to improve model robustness. in this paper we propose featuremix a straightforward yet effective adversarial defense strategy for plms by finetuning on both discrete adversarial examples and online virtual examples. during finetuning we augment clean data with discrete attacks first and generate virtual examples in each finetuning epoch by randomly mixing local latent features in the hidden layers of augmented data pairs. the virtual examples serve as additional training signals regularizing the plms to favor mixing of latent features between discrete augmented examples and thus enhance adversarial robustness. the experimental evaluation results show that featuremix outperforms prevailing baseline methods in terms of robustness against adversarial attacks without significantly reducing generalization performance.", "Pub Date": "2024-02-26"}
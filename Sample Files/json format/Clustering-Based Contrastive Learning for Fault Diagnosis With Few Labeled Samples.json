{"Title": "Clustering-Based Contrastive Learning for Fault Diagnosis With Few Labeled Samples", "Authors": ["y. dai", "z. mei", "j. li", "z. li", "k. wei", "m. ding", "s. guo", "w. chen"], "Pub Date": "2024-01-04", "Abstract": "in recent years the utilization of deep learning  dl  for fault diagnosis has become more and more prevalent. however most dl methods rely on a large amount of labeled data to train models which could lead to their poor generalization ability when applied to different scenarios. moreover labels are precious and not easily accessible in practical industrial production environments. to overcome these drawbacks we propose a clustering based contrastive learning  ccl  framework. specifically data augmentation  da  is first applied to the raw data by converting them into two related views using a dropout method. next we adopt an inter instance contrasting module based on dynamic clustering to learn the discriminability representation of the neural network model. this module seeks to maximize the similarity of the same sample features while minimizing the similarity between different sample features. finally an intra instance temporal contrast module is designed to learn the intra instance temporal relationship by undertaking a challenging cross prediction task to establish robust temporal representations. the effectiveness of our proposed method is demonstrated by the experimental results of three public rotating machinery datasets and one dataset collected from 15 pumps in the tengzhou factory. in the most difficult task where only 1% of the data are labeled the proposed ccl can improve the accuracy by a maximum of 23.13% over the supervised learning baseline. this method can significantly improve the diagnostic performance and generalization ability of the model with limited labels.", "Doi": "10.1109/TIM.2023.3346494", "Key Words": ["contrastive learning (cl)", "fault diagnosis", "few labeled data", "self-supervised learning (ssl)"]}
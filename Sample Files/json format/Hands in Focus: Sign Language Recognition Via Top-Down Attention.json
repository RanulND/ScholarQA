{"Title": "Hands in Focus: Sign Language Recognition Via Top-Down Attention", "Doi": "10.1109/ICIP49359.2023.10222729", "Authors": ["n. sarhan", "c. wilms", "v. closius", "u. brefeld", "s. frintrop"], "Key Words": ["sign language recognition", "top-down attention", "deep learning"], "Abstract": "in this paper we propose a novel sign language recognition  slr  model that leverages the task specific knowledge to incorporate top down  td  attention to focus the processing of the network on the most relevant parts of the input video sequence. for slr this includes information about the hands\u201a\u00e4\u00f4 shape orientation and positions and motion trajectory. our model consists of three streams that process rgb optical flow and td attention data. for the td attention we generate pixel precise attention maps focusing on both hands thereby retaining valuable hand information while eliminating distracting background information. our proposed method outperforms state of the art on a challenging large scale dataset by over 2% and achieves strong results with a much simpler architecture compared to other systems on the newly released autsl dataset .", "Pub Date": "2023-09-11"}
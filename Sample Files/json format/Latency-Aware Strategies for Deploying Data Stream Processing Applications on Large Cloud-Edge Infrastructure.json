{"Title": "Latency-Aware Strategies for Deploying Data Stream Processing Applications on Large Cloud-Edge Infrastructure", "Doi": "10.1109/TCC.2021.3097879", "Authors": ["a. d. s. veith", "m. dias de assun\u221a\u00df\u221a\u00a3o", "l. lef\u221a\u00aevre"], "Key Words": ["data stream processing", "edge computing", "aggregate end-to-end latency", "operator placement"], "Abstract": "internet of things  iot  applications often require the processing of data streams generated by devices dispersed over a large geographical area. traditionally these data streams are forwarded to a distant cloud for processing thus resulting in high application end to end latency. recent work explores the combination of resources located in clouds and at the edges of the internet called cloud edge infrastructure for deploying data stream processing  dsp  applications. most previous work however fails to scale to very large iot settings. this paper introduces deployment strategies for the placement of data stream processing  dsp  applications onto cloud edge infrastructure. the strategies split an application graph into regions and consider regions with stringent time requirements for edge placement. the proposed aggregate end to end latency strategy with region patterns and latency awareness  aels+rp+la  decreases the number of evaluated resources when computing an operator placement by considering the communication overhead across computing resources. simulation results show that unlike the state of the art aggregate end to end latency strategy with region patterns and latency awareness  aels+rp+la  scales to environments with more than 100k resources with negligible impact on the application end to end latency.", "Pub Date": "2023-03-07"}
{"Title": "MEC-DA: Memory-Efficient Collaborative Domain Adaptation for Mobile Edge Devices", "Doi": "10.1109/TMC.2023.3282941", "Authors": ["x. zhou", "y. tian", "x. wang"], "Key Words": ["cloud-edge based collaborative learning", "domain adaptation", "knowledge distillation", "memory efficiency"], "Abstract": "it is prevalent for a mobile edge device to conduct local inference using a compact machine learning model which achieves lower latency and less compromise of data privacy as compared to cloud based inference. to work in a new environment the compact model needs to be adapted to the target data from the environment so as to maintain a high inference accuracy. however directly applying domain adaptation to the compact model leads to a low inference accuracy. hence a scheme called memory efficient collaborative domain adaptation  mec da  is developed in this paper to boost the compact model inference accuracy on the target data while preserving data privacy. it first deploys a large model to the mobile edge devices where domain adaptation is conducted to adapt the large model to the target data. this process requires training of the large model which causes high memory consumption. a new method called lite residual hypothesis transfer  lrht  is thus designed to achieve memory efficient domain adaptation. the knowledge of the large model is then transferred to the compact model via knowledge distillation. to prevent the compact model from forgetting the knowledge of the source data a collaborative knowledge distillation  co kd  method is developed to unify the source data on the server and the target data on an edge device to update the compact model. mec da can protect data privacy and handle participant mobility properly via secure aggregation and user selection respectively. extensive experiments on several tasks of object recognition show that mec da improves the inference accuracy by up to 12.5% as compared to the state of the art schemes.", "Pub Date": "2024-04-04"}
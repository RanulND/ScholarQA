{"Title": "Generative Linguistic Representation for Spoken Language Identification", "Doi": "10.1109/ASRU57964.2023.10389776", "Authors": ["p. shen", "x. lu", "h. kawai"], "Key Words": ["spoken language identification", "openai whisper", "linguistic representation extraction", "cross-domain robustness"], "Abstract": "effective extraction and application of linguistic features are central to the enhancement of spoken language identification  lid  performance. with the success of recent large models such as gpt and whisper the potential to leverage such pre trained models for extracting linguistic features for lid tasks has become a promising area of research. in this paper we explore the utilization of the decoder based network from the whisper model to extract linguistic features through its generative mechanism for improving the classification accuracy in lid tasks. we devised two strategies   one based on the language embedding method and the other focusing on direct optimization of lid outputs while simultaneously enhancing the speech recognition tasks. we conducted experiments on the large scale multilingual datasets mls voxlingua107 and commonvoice to test our approach. the experimental results demonstrated the effectiveness of the proposed method on both in domain and out of domain datasets for lid tasks.", "Pub Date": "2024-01-19"}
{"Title": "Spatial-DCCRN: DCCRN Equipped with Frame-Level Angle Feature and Hybrid Filtering for Multi-Channel Speech Enhancement", "Doi": "10.1109/SLT54892.2023.10022488", "Authors": ["s. lv", "y. fu", "y. jv", "l. xie", "w. zhu", "w. rao", "y. wang"], "Key Words": ["multi-channel", "spatial-dccrn", "speech enhancement"], "Abstract": "recently multi channel speech enhancement has drawn much interest due to the use of spatial information to distinguish target speech from interfering signal. to make full use of spatial information and neural network based masking estimation we propose a multi channel denoising neural network   spatial dccrn. firstly we extend s dccrn to multi  channel scenario aiming at performing cascaded sub channel and full channel processing strategy which can model different channels separately. moreover instead of only adopting multi channel spectrum or concatenating first channel magnitude and ipd as the model inputs we apply an angle feature extraction module  afe  to extract frame level angle feature embeddings which can help the model to apparently perceive spatial information. finally since the phenomenon of residual noise will be more serious when the noise and speech exist in the same time frequency  tf  bin we particularly design a masking and mapping filtering method to substitute the traditional filter and sum operation with the purpose of cascading coarsely denoising dereverberation and residual noise suppression. the proposed model spatial dccrn has surpassed eabnet fasnet as well as several competitive models on the l3das22 challenge dataset. not only the 3d scenario spatial dccrn outperforms state of the art  sota  model mimo unet by a large margin in multiple evaluation metrics on the multi channel conferencingspeech2021 challenge dataset. ablation studies also demonstrate the effectiveness of different contributions.", "Pub Date": "2023-01-27"}
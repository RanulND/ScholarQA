{"Title": "Improving Code Extraction from Coding Screencasts Using a Code-Aware Encoder-Decoder Model", "Doi": "10.1109/ASE56229.2023.00184", "Authors": ["a. malkadi", "a. tayeb", "s. haiduc"], "Key Words": ["code extraction", "coding screencasts", "code-aware model", "optical character recognition"], "Abstract": "accurate automatic code extraction from tutorial videos is crucial for software developers seeking to reuse the code contained in these videos. current methods using optical character recognition  ocr  often yield inaccurate results due to code complexity and variations in screencast formats. to address this issue we introduce codet5 ocrfix an approach that leverages the pre trained code aware large language model codet5 to enhance code extraction accuracy by post processing ocred code. we first collect a large and diverse dataset of source code screenshots captured from more than 10k java projects from github. we then apply the most widely used ocr engine for the task of code extraction from videos tesseract on these screenshots and collect the ocred code along with the ground truth code extracted from the java files. we built a training dataset of more than 585k pairs of ocred and ground truth code pairs which we then used to fine tune codet5 obtaining our model codet5 ocrfix. an empirical evaluation on both screenshots and screencast frames shows that codet5 ocrfix outperforms baseline code extraction models and is also more time efficient. our approach therefore improves the state of the art in code extraction techniques from screencasts and images.", "Pub Date": "2023-11-08"}
{"Title": "Energy Estimates Across Layers of Computing: From Devices to Large-Scale Applications in Machine Learning for Natural Language Processing, Scientific Computing, and Cryptocurrency Mining1", "Doi": "10.1109/HPEC58863.2023.10363573", "Authors": ["s. shankar"], "Key Words": ["moore's law", "from bits to architectures and applications", "energy per instruction", "energy per bit", "instructions per second", "specialized architectures", "energy for machine learning and artificial intelligence", "natural language processing", "chatgpt", "energy for high performance scientific computations", "energy for crypto coin mining", "bitcoin", "thermodynamical limit", "biological limit", "atp", "sustainable computing", "energy as a design parameter"], "Abstract": "estimates of energy usage in layers of computing from devices to algorithms have been determined and analyzed. building on the previous analysis  energy needed from single devices and systems including three large scale computing applications such as artificial intelligence  artificial intelliegence /machine learning for natural language processing scientific simulations and cryptocurrency mining have been estimated. in contrast to the bit level switching in which transistors achieved energy efficiency due to geometrical scaling higher energy is expended both at the at the instructions and simulations levels of an application. additionally the analysis based on artificial intelliegence ml accelerators indicate that changes in architectures using an older semiconductor technology node have comparable energy efficiency with a different architecture using a newer technology. further comparisons of the energy in computing systems with the thermodynamic and biological limits indicate that there is a 27\u201a\u00e4\u00ec36 orders of magnitude higher energy requirements for total simulation of an application. these energy estimates underscore the need for serious considerations of energy efficiency in computing by including energy as a design parameter enabling growing needs of compute intensive applications in a digital world.", "Pub Date": "2023-12-25"}
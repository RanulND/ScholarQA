{"Title": "Shortcut Learning Explanations for Deep Natural Language Processing: A Survey on Dataset Biases", "Doi": "10.1109/ACCESS.2024.3360306", "Authors": ["v. dogra", "s. verma", "kavita", "m. wo\u2248\u222bniak", "j. shafi", "m. f. ijaz"], "Key Words": ["dataset biases", "deep learning", "natural language processing", "shortcut learning", "transfer learning"], "Abstract": "the introduction of pre trained large language models  large language model  has transformed nlp by fine tuning task specific datasets enabling notable advancements in news classification language translation and sentiment analysis. this has revolutionized the field driving remarkable breakthroughs and progress. however the growing recognition of bias in textual data has emerged as a critical focus in the nlp community revealing the inherent limitations of models trained on specific datasets. large language model exploit these dataset biases and artifacts as expedient shortcuts for prediction. the reliance of large language model on dataset bias and artifacts as shortcuts for prediction has hindered their generalizability and adversarial robustness. addressing this issue is crucial to enhance the reliability and resilience of large language model in various contexts. this survey provides a comprehensive overview of the rapidly growing body of research on shortcut learning in language models classifying the research into four main areas  the factors of shortcut learning the origin of bias the detection methods of dataset biases and understanding mitigation strategies to address data biases. the goal of this study is to offer a contextualized in depth look at the state of learning models highlighting the major areas of attention and suggesting possible directions for further research.", "Pub Date": "2024-02-23"}
{"Title": "Improving Few-Shot Performance of DST Model Through Multitask to Better Serve Language-Impaired People", "Doi": "10.1109/ICASSPW59220.2023.10193387", "Authors": ["m. sun", "q. gao", "y. mou", "g. dong", "r. liu", "w. guo"], "Key Words": ["dialogue state tracking", "few-shot", "multitask", "large-scale pre-trained models"], "Abstract": "artificial intelligence based virtual assistants make people\u201a\u00e4\u00f4s daily life more convenient. however the utterances of language impaired people are limited and different in characteristics and domains from that of ordinary people. so it is difficult for language impaired people to benefit from standard data driven artificial intelligence algorithms. in this paper we propose a multi task training method for the dialogue state tracking  dst  task in dialogue systems that make up virtual assistants improving the performance of t5 on the few shot cross domain dst task. specifically we consider two ways of handling dst task  predicting the dialogue state from the beginning or updating the dialogue state every turn and accordingly design the main task and auxiliary task for the model. experiments show that our method outperforms most previous works on the multiwoz 2.0 and 2.1 datasets for the few shot cross domain dst task. for the artificial crafted language impaired dataset our method can effectively improve the few shot cross domain performance of the model. additionally we analyzed the possible reason why this multitasking approach works well.", "Pub Date": "2023-08-02"}
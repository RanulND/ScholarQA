{"Title": "How Secure is Code Generated by ChatGPT?", "Doi": "10.1109/SMC53992.2023.10394237", "Authors": ["r. khoury", "a. r. avila", "j. brunelle", "b. m. camara"], "Key Words": ["large language models", "chatgpt", "code security", "automatic code generation"], "Abstract": "in recent years large language models have been responsible for great advances in the field of artificial intelligence  ai . chatgpt in particular an ai chatbot developed and recently released by openai has taken the field to the next level. the conversational model is able not only to process human like text but also to translate natural language into code. however the safety of programs generated by chatgpt should not be overlooked. in this paper we perform an experiment to address this issue. specifically we ask chatgpt to generate a number of computer programs in order to evaluate the security of the resulting source code. we further investigate whether chatgpt can be prodded to improve code security by appropriate prompts and discuss the ethical aspects of using ai to generate code. results suggest that chatgpt is aware of potential vulnerabilities but nonetheless often generates source code that are not robust to certain attacks.", "Pub Date": "2024-01-29"}
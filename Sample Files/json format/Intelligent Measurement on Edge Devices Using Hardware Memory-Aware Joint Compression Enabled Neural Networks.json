{"Title": "Intelligent Measurement on Edge Devices Using Hardware Memory-Aware Joint Compression Enabled Neural Networks", "Authors": ["b. yao", "l. liu", "y. peng", "x. peng"], "Pub Date": "2023-12-22", "Abstract": "applying neural network  nn  on edge devices is crucial for intelligent measurement. however the limited memory resource is one of the main challenges for deploying nn with high spatial complexity. to address this issue a hardware memory aware joint compression  major  is proposed in this article. first a trainable joint compression framework is established for the parallel operation of pruning and quantization. then a partial memory bottleneck penalty regularizer is designed to guide the compression to meet actual hardware memory demands accurately. the proposed method is evaluated on sloc4 whu rs19 rsscn7 and opt aircraft v1.0 remote sensing image datasets using vgg resnet 20/50 mobilenetv1 efficientnet b0 densenet 121 and resnext 50 for the satellite onboard processing platform which is a typical hardware memory limited device. the experimental results show that major could reduce the model\u201a\u00e4\u00f4s partial peak memory size up to  $23.19\\times $  ensuring it fits within the target platform\u201a\u00e4\u00f4s capacity with less than 3% accuracy loss. furthermore the proposed method is evaluated on cifar-10 using vgg resnet 20 and mobilenetv1 for four edge hardware with different memory sizes. it achieves a remarkable compression ratio of up to 94.92% while ensuring that model accuracy loss remains below 3%. compared with other compression methods major accurately reduces model memory size to match the capacity of the various target hardware. the partial memory bottleneck in nns could be significantly eliminated.", "Doi": "10.1109/TIM.2023.3341126", "Key Words": ["edge computing", "intelligent measurement", "memory constrained hardware", "model compression", "neural network (nn)", "pruning", "quantization"]}
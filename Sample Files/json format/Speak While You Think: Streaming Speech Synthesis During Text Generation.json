{"Title": "Speak While You Think: Streaming Speech Synthesis During Text Generation", "Doi": "10.1109/ICASSP48485.2024.10446214", "Authors": ["a. dekel", "s. shechtman", "r. fernandez", "d. haws", "z. kons", "r. hoory"], "Key Words": ["incremental tts", "speech generation", "large language models (llms)"], "Abstract": "large language models  large language model  demonstrate impressive capabilities yet interaction with these models is mostly facilitated through text. using text to speech to synthesize large language model outputs typically results in notable latency which is impractical for fluent voice conversations. we propose llm2speech an architecture to synthesize speech while text is being generated by an large language model which yields significant latency reduction. llm2speech mimics the predictions of a non streaming teacher model while limiting the exposure to future context in order to enable streaming. it exploits the hidden embeddings of the large language model a by product of the text generation that contains informative semantic context. experimental results show that llm2speech maintains the teacher\u201a\u00e4\u00f4s quality while reducing the latency to enable natural conversations.", "Pub Date": "2024-03-18"}
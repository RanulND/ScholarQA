{"Title": "LASP: Text-to-Text Optimization for Language-Aware Soft Prompting of Vision & Language Models", "Doi": "10.1109/CVPR52729.2023.02225", "Authors": ["a. bulat", "g. tzimiropoulos"], "Key Words": ["transfer", "meta", "low-shot", "continual", "or long-tail learning"], "Abstract": "soft prompt learning has recently emerged as one of the methods of choice for adapting v&l models to a downstream task using a few training examples. however current methods significantly overfit the training data suffering from large accuracy degradation when tested on unseen classes from the same domain. to this end in this paper we make the following 4 contributions   1  to alleviate base class overfitting we propose a novel language  aware soft prompting  lasp  learning method by means of a text to text cross entropy loss that maximizes the probability of the learned prompts to be correctly classified with respect to pre defined hand crafted textual prompts.  2  to increase the representation capacity of the prompts we propose grouped lasp where each group of prompts is optimized with respect to a separate subset of textual prompts.  3  we identify a visual language misalignment introduced by prompt learning and lasp and more importantly propose a re calibration mechanism to address it.  4  we show that lasp is inherently amenable to including during training virtual classes i.e. class names for which no visual samples are available further increasing the robustness of the learned prompts. through evaluations on 11 datasets we show that our approach  a  significantly outperforms all prior works on soft prompting and  b  matches and surpasses for the first time the accuracy on novel classes obtained by hand crafted prompts and clip for 8 out of 11 test datasets. code will be made available here.", "Pub Date": "2023-08-22"}
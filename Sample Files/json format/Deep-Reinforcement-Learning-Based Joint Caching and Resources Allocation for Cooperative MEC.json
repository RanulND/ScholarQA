{"Title": "Deep-Reinforcement-Learning-Based Joint Caching and Resources Allocation for Cooperative MEC", "Doi": "10.1109/JIOT.2023.3333826", "Authors": ["w. zhang", "g. zhang", "s. mao"], "Key Words": ["cooperative mec servers", "deep reinforcement learning (drl)", "hierarchical reinforcement learning (hrl)", "joint caching and resources allocation", "mobile-edge computing (mec)"], "Abstract": "the emergence of new applications has led to a high demand for mobile edge computing  mec  which is a promising paradigm with a cloud like architecture deployed at the network edge to provide computation and storage services to mobile users  mus . since mec servers have limited resources compared to the remote cloud it is crucial to optimize resource allocation in mec systems and balance the load among cooperating mec servers. caching application data for different types of computing services  css  at mec servers can also be highly beneficial. in this article we investigate the problem of hierarchical joint caching and resource allocation in a cooperative mec system which is formulated as an infinite horizon cost minimization markov decision process  mdp . to deal with the large state and action spaces we decompose the problem into two coupled subproblems and develop a hierarchical reinforcement learning  hrl  based solution. the lower layer uses the deep  $q$  network  dqn  to obtain service caching and workload offloading decisions while the upper layer leverages dqn to obtain load balancing decisions among cooperative mec servers. the feasibility and effectiveness of our proposed schemes are validated by our evaluation results.", "Pub Date": "2024-03-27"}
{"Title": "Unsupervised Sentence Embedding Model Based on Contrastive Learning", "Doi": "10.1109/ICCCS57501.2023.10151113", "Authors": ["m. wang", "j. wang", "j. gan", "z. li"], "Key Words": ["contrastive learning", "unsupervised learning", "agent tasks", "sentence embedding"], "Abstract": "the unsupervised sentence embedding model of the contrastive learning framework simcse uses dropout noise as a data expansion method which often defaults to having sentences of the same length to have more similar semantic information and the random nature of dropout may lead to loss of semantic information or large differences due to sentence embedding. for this reason we propose two agent tasks random deletion as well as r dropout to solve these problems. we conducted experiments on the text semantic similarity task on the publicly available datasets sts12 16 sts b and sick r. the experimental results show that our proposed sentence embedding model improves the average spearman correlation coefficient to 77.67 % compared with the benchmark models is bertbase ct bertbase and simcse  we also used the seneval toolkit to evaluate the quality of sentence embed dings generated by the model and used sentence embeddings as features of migration tasks mr subj mpqa trec and mrpc for classification tasks using seneval and the experimental results showed that our proposed sentence embedding model achieves better performance in the accuracy of classification in all cases.", "Pub Date": "2023-06-26"}
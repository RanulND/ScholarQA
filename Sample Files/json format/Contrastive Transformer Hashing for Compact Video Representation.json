{"Title": "Contrastive Transformer Hashing for Compact Video Representation", "Authors": ["x. shen", "y. zhou", "y. -h. yuan", "x. yang", "l. lan", "y. zheng"], "Pub Date": "2023-11-07", "Abstract": "video hashing learns compact representation by mapping video into low dimensional hamming space and has achieved promising performance in large scale video retrieval. it is challenging to effectively exploit temporal and spatial structure in an unsupervised setting. to fulfill this gap this paper proposes contrastive transformer hashing  cth  for effective video retrieval. specifically cth develops a bidirectional transformer autoencoder based on which visual reconstruction loss is proposed. cth is more powerful to capture bidirectional correlations among frames than conventional unidirectional models. in addition cth devises multi modality contrastive loss to reveal intrinsic structure among videos. cth constructs inter modality and intra modality triplet sets and proposes multi modality contrastive loss to exploit inter modality and intra modality similarities simultaneously. we perform video retrieval tasks on four benchmark datasets i.e. ucf101 hmdb51 svw30 fcvid using the learned compact hash representation and extensive empirical results demonstrate the proposed cth outperforms several state of the art video hashing methods.", "Doi": "10.1109/TIP.2023.3326994", "Key Words": ["hashing", "transformer", "video representation", "retrieval"]}
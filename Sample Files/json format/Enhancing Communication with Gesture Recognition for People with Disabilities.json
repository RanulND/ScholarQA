{"Title": "Enhancing Communication with Gesture Recognition for People with Disabilities", "Doi": "10.1109/ICMNWC60182.2023.10435809", "Authors": ["a. kumar", "k. joshi", "s. chattopadhyay", "y. kaushik", "h. anandaram", "v. taneja"], "Key Words": ["sign language", "gesture recognition", "computer vision", "convolutional neural network"], "Abstract": "gesture recognition plays a vital role in the era of smart city and visual perception. this work introduces an innovative smart application designed to enhance inclusive communication for individuals with disabilities. by leveraging real time sign language detection and interpretation the application harnesses advanced technologies such as artificial intelligence computer vision and gesture recognition. its main goal is to overcome communication barriers facilitating smooth conversations between sign language users and non sign language users. this article provides a comprehensive analysis of the application design features and functionality emphasizing its potential to bridge the communication gap. through an evaluation of effectiveness usability and user satisfaction the research showcases the transformative impact of the application on sign language communication. the findings highlight the significant role of this technology in promoting inclusivity empowerment and equal participation across various domains for individuals with disabilities. additionally the article discusses implications limitations and identifies future research directions for the further development and implementation of the application. the model is trained on a large corpus downloaded from kaggle and can be used to interpret sign language. the user simply needs to perform their sign gesture and the model will automatically read and convert it to text in real time. it achieved 97.3% final accuracy hence can be used by sign language users to communicate with non sign language users effectively.", "Pub Date": "2024-02-22"}
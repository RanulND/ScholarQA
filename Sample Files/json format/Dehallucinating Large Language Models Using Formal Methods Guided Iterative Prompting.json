{"Title": "Dehallucinating Large Language Models Using Formal Methods Guided Iterative Prompting", "Doi": "10.1109/ICAA58325.2023.00029", "Authors": ["s. jha", "s. k. jha", "p. lincoln", "n. d. bastian", "a. velasquez", "s. neema"], "Key Words": ["large-language-models", "hallucinations", "formal-methods"], "Abstract": "large language models  large language model  such as chatgpt have been trained to generate human like responses to natural language prompts. large language model use a vast corpus of text data for training and can generate coherent and contextually relevant responses to a wide range of questions and statements. despite this remarkable progress large language model are prone to hallucinations making their application to safety critical applications such as autonomous systems difficult. the hallucinations in large language model refer to instances where the model generates responses that are not factually accurate or contextually appropriate. these hallucinations can occur due to a variety of factors such as the model\u201a\u00e4\u00f4s lack of real world knowledge the influence of biased or inaccurate training data or the model\u201a\u00e4\u00f4s tendency to generate responses based on statistical patterns rather than a true understanding of the input. while these hallucinations are a nuisance in tasks such as text summarization and question answering they can be catastrophic when large language model are used in autonomy relevant applications such as planning. in this paper we focus on the application of large language model in autonomous systems and sketch a novel self monitoring and iterative prompting architecture that uses formal methods to detect these errors in the large language model response automatically. we exploit the dialog capability of large language model to iteratively steer them to responses that are consistent with our correctness specification. we report preliminary experiments that show the promise of the proposed approach on tasks such as automated planning.", "Pub Date": "2023-08-10"}
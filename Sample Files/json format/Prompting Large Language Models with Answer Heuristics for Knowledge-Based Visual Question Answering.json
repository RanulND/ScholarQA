{"Title": "Prompting Large Language Models with Answer Heuristics for Knowledge-Based Visual Question Answering", "Doi": "10.1109/CVPR52729.2023.01438", "Authors": ["z. shao", "z. yu", "m. wang", "j. yu"], "Key Words": ["vision", "language", "and reasoning"], "Abstract": "knowledge based visual question answering  vqa  requires external knowledge beyond the image to answer the question. early studies retrieve required knowledge from explicit knowledge bases  kbs  which often introduces irrelevant information to the question hence restricting the performance of their models. recent works have sought to use a large language model  i.e. gpt-3   as an implicit knowledge engine to acquire the necessary knowledge for answering. despite the encouraging results achieved by these methods we argue that they have not fully activated the capacity of gpt-3 as the provided input information is insufficient. in this paper we present prophet a conceptually simple framework designed to $prompt$ gpt-3 with answer heuristics for knowledge based vqa. specifically we first train a vanilla vqa model on a specific knowledge based vqa dataset without external knowledge. after that we extract two types of complementary answer heuristics from the model  answer candidates and answer aware examples. finally the two types of answer heuristics are encoded into the prompts to enable gpt-3 to better comprehend the task thus enhancing its capacity. prophet significantly outperforms all existing state of the art methods on two challenging knowledge based vqa datasets ok vqa and a okvqa delivering 61.1% and 55.7% accuracies on their testing sets respectively.", "Pub Date": "2023-08-22"}
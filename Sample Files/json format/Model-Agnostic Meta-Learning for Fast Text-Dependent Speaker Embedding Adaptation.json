{"Title": "Model-Agnostic Meta-Learning for Fast Text-Dependent Speaker Embedding Adaptation", "Doi": "10.1109/TASLP.2023.3275029", "Authors": ["w. lin", "m. -w. mak"], "Key Words": ["deep speaker embedding", "text-dependent speaker verification", "meta-learning", "model adaptation", "maml"], "Abstract": "by constraining the lexical content of input speech text dependent speaker verification  td sv  offers more reliable performance than text independent speaker verification  ti sv  when dealing with short utterances. because speech with constrained lexical content is harder to collect often td models are fine tuned from a ti model using a small target phrase dataset. however sometimes the target phrase dataset is too tiny for fine tuning which is the main obstacle for deploying td sv. one solution is to fine tune the model using medium size multi phrase td data and then deploy the model on the target phrase. although this strategy does help in some cases the performance is still sub optimal because the model is not optimized for the target phrase. inspired by the recent progress in meta learning we propose a three stage pipeline for adapting a ti model to a td model for the target phrase. firstly a ti model is trained using a large amount of speech data. then we use a multi phrase td dataset to tune the ti model via model agnostic meta learning. finally we perform fast adaptation using a small target phrase dataset. results show that the three stage pipeline consistently outperforms multi phrase and target phrase fine tuning.", "Pub Date": "2023-05-17"}
{"Title": "From Gestures to Audio: A Dataset Building Approach for Egyptian Sign Language Translation to Arabic Speech", "Doi": "10.1109/IMSA58542.2023.10217562", "Authors": ["y. ismail", "a. tarek", "o. zakaria", "s. taha", "s. masoud", "k. sobh", "a. t. salah", "g. khoriba"], "Key Words": ["egyptian sign language", "deep learning", "dataset collection", "hearing impairments", "hand gesture recognition", "assistive technologies", "deaf community", "sign language recognition"], "Abstract": "the communication barriers faced by people with disabilities particularly the deaf or hard of hearing nonverbal deaf mute and blind have a significant impact on their quality of life and social inclusion. our research aims to provide real time translation from sign language to speech and vice versa. the ability to provide real time speech to text and text to sign language translation will help alleviate these barriers improve communication and increase social inclusivity for this community ensuring they are not left out in conversations and social interactions. a significant amount of data is required to develop a deep learning model that automatically translates egyptian sign language to audio. due to the unavailability of large scale datasets for egyptian sign language we present a dataset building approach to address this issue. in this paper we discuss collecting and preprocessing the dataset which includes extracting audio video scrapping cropping the required part of the video containing the sign language translator and applying human and hand recognition models to identify the translators and their gestures respectively. the resulting dataset will be used to train deep learning models to translate egyptian sign language to audio as an end to end approach. the dataset will be available in our research github.", "Pub Date": "2023-08-24"}
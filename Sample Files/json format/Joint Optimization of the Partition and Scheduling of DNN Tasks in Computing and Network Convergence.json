{"Title": "Joint Optimization of the Partition and Scheduling of DNN Tasks in Computing and Network Convergence", "Doi": "10.1109/LNET.2023.3260567", "Authors": ["z. zhang", "q. li", "l. lu", "d. guo", "y. zhang"], "Key Words": ["computing and network convergence", "deep neural network", "end-edge-network-cloud", "collaborative inference"], "Abstract": "computing and network convergence  cnc  is a new network architecture based on computing evolution and network integration. deep neural networks  dnns  inference imposes a heavy computational burden on mobile devices. in this letter an end edge network cloud  eenc  collaborative inference architecture is proposed to reduce the dnn inference latency and maximize the computing potential of the cnc. a heuristic centralized dnn task offloading algorithm  cdto  is proposed for the fine grained partition and scheduling problems of multiple dnn inference tasks. the cdto algorithm can significantly reduce the makespan of dnn inference tasks and effectively improve the concurrent capacity of dnn tasks.", "Pub Date": "2023-06-09"}
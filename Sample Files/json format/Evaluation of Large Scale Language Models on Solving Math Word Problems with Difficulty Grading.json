{"Title": "Evaluation of Large Scale Language Models on Solving Math Word Problems with Difficulty Grading", "Doi": "10.1109/IEIR59294.2023.10391224", "Authors": ["x. he", "h. gao", "j. he", "c. sun"], "Key Words": ["large language models", "gpt", "math word problem", "automatic answering"], "Abstract": "with the advancement of artificial intelligence large language models have achieved remarkable success particularly in natural language processing. however their performance in solving math word problems  mwps  has been challenged by the difficulty of these problems especially in high difficulty scenarios. this research aims to evaluate the answer accuracy of large language models taking gpt 3.5 as an example in mwp tasks focusing on graded difficulty levels of the problems. we transform the existing math23k dataset into a math application problem dataset with multiple difficulty levels aiming to reflect the diverse complexities of real world application scenarios. through systematic experimental analysis we delve into the performance of these models on problems of varying difficulty and reveal the relationship between model performance and problem difficulty. experimental results indicate that these large language models excel in solving simple and moderately low difficulty problems but exhibit a general decline in performance when faced with moderately high and complicated problems. furthermore our study unveils that models are more susceptible to the complexity and ambiguity of problem descriptions particularly in high difficulty scenarios.", "Pub Date": "2024-01-16"}
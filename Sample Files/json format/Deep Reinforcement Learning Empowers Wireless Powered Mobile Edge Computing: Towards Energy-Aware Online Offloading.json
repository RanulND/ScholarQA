{"Title": "Deep Reinforcement Learning Empowers Wireless Powered Mobile Edge Computing: Towards Energy-Aware Online Offloading", "Doi": "10.1109/TCOMM.2023.3283792", "Authors": ["x. jiao", "y. wang", "s. guo", "h. zhang", "h. dai", "m. li", "p. zhou"], "Key Words": ["wireless powered mobile edge computing", "deep reinforcement learning", "online offloading decision", "charging resource allocation"], "Abstract": "deep integration of wireless power transmission and mobile edge computing  mec  promotes wireless powered mec to become a new research hotspot in the field of internet of things. in this paper we focus on the joint optimization problem of online offloading decision and charging resource allocation for minimizing task accomplishing time in dynamic time varying wireless channel scenarios. the optimal solution involves addressing a mixed integer programming problem in real time which is proved to be np hard and imposes nontrivial challenges to design with conventional optimization methods. to efficiently address this problem we leverage the deep reinforcement learning  drl  technology to propose an energy aware online offloading algorithm called eaoo. eaoo algorithm learns empirically the online offloading decision policies via a well designed drl framework and adopts the feasible solution region analysis method to implement the charging resource allocation. we further propose a novel feasible decision vector generation method and incorporate the crossover and mutation technology to expand the offloading vector search space with the provable feasibility guarantee. extensive experimental results show that our eaoo algorithm outperforms existing baseline algorithms and achieves near optimal performance with low cpu execution latency which well satisfies the practical requirements of real time and efficiency.", "Pub Date": "2023-09-15"}
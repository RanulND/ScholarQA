{"Title": "Hierarchical Personalized Federated Learning Over Massive Mobile Edge Computing Networks", "Doi": "10.1109/TWC.2023.3260141", "Authors": ["c. you", "k. guo", "h. h. yang", "t. q. s. quek"], "Key Words": ["pfl", "hierarchical aggregation", "massive mec"], "Abstract": "personalized federated learning  pfl  is a new federated learning  fl  paradigm particularly tackling the heterogeneity issues brought by various mobile user equipments  ues  in mobile edge computing  mec  networks. however due to the ever increasing number of ues and the complicated administrative work it brings it is desirable to switch the pfl algorithm from its conventional two layer framework to a multiple layer one. in this paper we propose hierarchical pfl  hpfl  an algorithm for deploying pfl over massive mec networks. the ues in hpfl are divided into multiple clusters and the ues in each cluster forward their local updates to the edge server  es  synchronously for edge model aggregation while the ess forward their edge models to the cloud server semi asynchronously for global model aggregation. the above training manner leads to a tradeoff between the training loss in each round and the round latency. hpfl combines the objectives of training loss minimization and round latency minimization while jointly determining the optimal bandwidth allocation as well as the es scheduling policy in the hierarchical learning framework. extensive experiments verify that hpfl not only guarantees convergence in hierarchical aggregation frameworks but also has advantages in round training loss maximization and round latency minimization.", "Pub Date": "2023-11-10"}
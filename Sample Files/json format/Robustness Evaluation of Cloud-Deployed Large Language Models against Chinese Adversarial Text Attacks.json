{"Title": "Robustness Evaluation of Cloud-Deployed Large Language Models against Chinese Adversarial Text Attacks", "Doi": "10.1109/CloudNet59005.2023.10490064", "Authors": ["y. zhang", "l. ye", "b. li", "h. zhang"], "Key Words": ["adversarial attack", "adversarial example", "large language model", "chatgpt", "robustness"], "Abstract": "in the evolving digital realm large language models  llms  like chatgpt which recently achieved state of the art results across diverse nlp tasks are extensively used. deployed on the cloud chatgpt allows interaction via its api providing rich and high quality solutions. however its vulnerability to adversarial attacks potentially compromising the quality and reliability of cloud services and leading to information leakage raises security concerns. investigating the robustness of chatgpt against adversarial attacks enables a preliminary understanding of its weaknesses and facilitates the subsequent integration of targeted defensive mechanisms into the cloud framework. most current research on the robustness of llms against adversarial attacks focuses on bert with few studies on chatgpt under similar conditions. this paper explores the robustness of chatgpt against chinese adversarial text attacks in text classification tasks and proposes a chatgpt based adversarial text fluency evaluation method that eliminates the need for human involvement. experiments conducted on the real world dataset thucnews examined the robustness of chinese bert and chatgpt against adversarial attacks generated via various chinese adversarial text generation methods. a multidimensional assessment revealed that both models are susceptible to attacks leading to decreased text classification accuracy. the attack success rate on chatgpt reached nearly 45%.", "Pub Date": "2024-04-09"}
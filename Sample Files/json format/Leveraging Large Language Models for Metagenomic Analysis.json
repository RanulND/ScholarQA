{"Title": "Leveraging Large Language Models for Metagenomic Analysis", "Doi": "10.1109/SPMB59478.2023.10372773", "Authors": ["m. s. refahi", "b. a. sokhansanj", "g. l. rosen"], "Key Words": ["dna sequence analysis", "metagenomics", "taxonomic classification", "microbiome", "natural language processing."], "Abstract": "analyzing sequencing data from microbiome experiments is challenging since samples can contain tens of thousands of unique taxa  and their genes  and populations of millions of cells. reducing the dimensionality of metagenomic data is a crucial step in improving the interpretability of complex genetic information as metagenomic datasets typically encompass a wide range of genetic diversity and variations.in this study we implement roberta a state of the art large language model and pre train it on relatively large genomic datasets to obtain a model that can be used to generate embeddings that can help simplify complex metagenomic data sets. the pre training process enables roberta to capture the inherent characteristics and patterns present in the genomic sequences. we then evaluate the effectiveness of embeddings generated using the pre trained roberta model in downstream tasks with a particular focus on taxonomic classification. to assess whether our method can be generalizable we conduct extensive downstream analysis on three distinct datasets  16s rrna 28s rrna and its. by utilizing datasets containing 16s rrna exclusive to bacteria and eukaryotic mitochondria as well as datasets containing 28s rrna and its specific to eukaryotes  such as fungi  we were able to assess the performance of roberta embeddings across diverse genomic regions. we tune the roberta model through hyperparameter optimization on each dataset. our results demonstrate that roberta embeddings exhibit promising results in taxonomic classification compared to conventional methods.", "Pub Date": "2023-12-29"}
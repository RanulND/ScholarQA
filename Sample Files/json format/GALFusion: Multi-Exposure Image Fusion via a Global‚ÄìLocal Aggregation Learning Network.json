{"Title": "GALFusion: Multi-Exposure Image Fusion via a Global\u201a\u00c4\u00ecLocal Aggregation Learning Network", "Authors": ["j. lei", "j. li", "j. liu", "s. zhou", "q. zhang", "n. k. kasabov"], "Pub Date": "2023-04-28", "Abstract": "the goal of multi exposure image fusion is to generate synthetic results with abundant details and balanced exposure from low dynamic range  ldr  images. the existing multi exposure fusion  mef  methods often use convolution operations to extract features. however these methods only consider the pixel values in local view field and ignore the long range dependencies between pixels. to solve the aforementioned problem we propose a global\u201a\u00e4\u00eclocal aggregation network for fusing extreme exposure images in an unsupervised way. firsty we design a collaborative aggregation module  cam  composed of two submodules covering a nonlocal attention inference  nlai  module and a local adaptive learning module to mine the relevant features from source images. so that we successfully formulate a feature extraction mechanism with aggregating global and local information. secondly we provide a special fusion module  fm  to reconstruct fused images which effectively avoids artifacts and suppresses information decay. moreover we further fine tune the fusion results by a recursive refinement module  rrm  to capture more textural details from source images. the results of both comparative and ablation analyses on two datasets demonstrate that galfusion achieves the best marks in terms of mef structure similarity index measure  ssim  and peak signal to noise ratio  psnr  outperforming the existing 12 state of the art fusion methods.", "Doi": "10.1109/TIM.2023.3267525", "Key Words": ["collaborative extraction", "image fusion", "multi-exposure image", "nonlocal attention (nla)", "recursive refinement network"]}
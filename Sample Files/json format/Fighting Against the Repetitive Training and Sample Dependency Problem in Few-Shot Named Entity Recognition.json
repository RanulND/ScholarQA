{"Title": "Fighting Against the Repetitive Training and Sample Dependency Problem in Few-Shot Named Entity Recognition", "Doi": "10.1109/ACCESS.2024.3374727", "Authors": ["c. tian", "w. yin", "d. li", "m. -f. moens"], "Key Words": ["artificial intelligence", "data mining", "feature extraction", "few-shot learning", "named entity recognition", "natural language processing", "text analysis"], "Abstract": "few shot named entity recognition  ner  systems recognize entities using a few labeled training examples. the general pipeline consists of a span detector to identify entity spans in text and an entity type classifier to assign types to entities. current span detectors rely on extensive manual labeling to guide training. almost every span detector requires initial training on basic span features followed by adaptation to task specific features. this process leads to repetitive training of the basic span features among span detectors. additionally metric based entity type classifiers such as prototypical networks typically employ a specific metric that gauges the distance between the query sample and entity type referents ultimately assigning the most probable entity type to the query sample. however these classifiers encounter the sample dependency problem primarily stemming from the limited samples available for each entity type referent. to address these challenges we proposed an improved few shot ner pipeline. first we introduce a steppingstone span detector that is pre trained on open domain wikipedia data. it can be used to initialize the pipeline span detector to reduce the repetitive training of basic features. second we leverage a large language model  llm  to set reliable entity type referents eliminating reliance on few shot samples of each type. our model exhibits superior performance with fewer training steps and human labeled data compared with baselines as demonstrated through extensive experiments on various datasets. particularly in fine grained few shot ner settings our model outperforms strong baselines including chatgpt. we will publicly release the code datasets llm outputs and model checkpoints.", "Pub Date": "2024-03-14"}
{"Title": "Enhancing Numerical Reasoning Performance by Augmenting Distractor Numerical Values", "Doi": "10.1109/BigComp60711.2024.00045", "Authors": ["y. -c. hwang", "j. lim", "y. -j. lee", "h. -j. choi"], "Key Words": ["data augmentation", "numerical reasoning", "large language model", "math word problem"], "Abstract": "large language models have exhibited remarkable proficiency in various domains and tasks including numerical reasoning task. however datasets for numerical reasoning tasks targeted by large language model often contain relatively few number of numerical values within the context. this raises doubts about whether large language model can infer well and provide accurate answers even when presented with contexts including many numerical values. indeed in a simple pilot study we have found that large language model ability to distinguish between essential and non essential numerical values when solving numerical reasoning tasks is quite poor. to relieve this phenomenon this paper proposes a framework to improve the robustness of large language model in handling irrelevant numerical values for problem solving by augmenting the original context of the problem while adding extra numerical values to the context. the experiment demonstrated that the model trained on the augmented dataset by our methodology increased robustness in numerical reasoning tasks with higher accuracies.", "Pub Date": "2024-04-11"}
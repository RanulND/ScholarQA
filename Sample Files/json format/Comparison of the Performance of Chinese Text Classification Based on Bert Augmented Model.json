{"Title": "Comparison of the Performance of Chinese Text Classification Based on Bert Augmented Model", "Doi": "10.1109/CSRSWTC60855.2023.10427146", "Authors": ["p. z. hou", "s. j. yu"], "Key Words": ["bert model", "text clasification", "model enhancement", "domain adaptation"], "Abstract": "with the continuous generation of large amounts of chinese text data such as social media news comments etc. text classification technology has become increasingly important. future development trends may include designing more in depth models combined with pre trained models such as bert or gpt to improve classification accuracy. at the same time multilingual and cross domain text classification will also become a research hotspot to adapt to the needs of different languages and industries. with the continuous advancement of technology chinese text classification is expected to play a greater role in information filtering public opinion analysis smart medical and other fields. bert is a powerful pre trained model capable of capturing rich semantic information. combining it with other neural networks can integrate bert context understanding capabilities and the characteristics of other networks to obtain a richer and more expressive feature representation. this article will use various recurrent neural networks and convolutional neural networks combined with the bert model to observe the performance capabilities and applicability of different combined models.", "Pub Date": "2024-02-16"}
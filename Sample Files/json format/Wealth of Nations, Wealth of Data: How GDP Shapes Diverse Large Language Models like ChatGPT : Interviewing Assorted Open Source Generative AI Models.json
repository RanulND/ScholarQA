{"Title": "Wealth of Nations, Wealth of Data: How GDP Shapes Diverse Large Language Models like ChatGPT : Interviewing Assorted Open Source Generative AI Models", "Doi": "10.1109/BigData59044.2023.10386329", "Authors": ["a. kaplunovich"], "Key Words": ["llm", "generative ai", "gdp per capita", "aws sagemaker", "huggingface", "inference analysis", "automation", "chatgpt"], "Abstract": "generative large language models  such as chatgpt  are increasingly influencing various aspects of our lives partly due to their training on vast datasets that encompassing big data paradigms and range of topics. \"intervista\" an award winning italian film by federico fellini focuses on his interview with a japanese tv crew. inspired by this we conducted interviews with a diverse set of open source and openai models to explore various political economic and cultural aspects of life evaluating large language model performance. we also examined whether a correlation exists between a country\u201a\u00e4\u00f4s gdp per capita and the quality of the model\u201a\u00e4\u00f4s answers. to this end we utilized a huggingface model leaderboard to select appropriate models and deployed them in an aws sagemaker gpu environment. the identical questions were posed about nearly 200 countries and the responses were analyzed to verify their accuracy and correlation with gross domestic product  gdp . we were amazed by the diversity quantity and quality of existing pretrained open source large language model. our journey provided insights into model selection inference pipeline automation gpu configuration generated texts benchmarking and systematic evaluation of model quality. overall leading large language model performed well providing reasonable responses for many countries. however we discovered that the depth and detail of the answers were influenced by a country\u201a\u00e4\u00f4s gdp per capita with higher income nations receiving more accurate responses.", "Pub Date": "2024-01-22"}
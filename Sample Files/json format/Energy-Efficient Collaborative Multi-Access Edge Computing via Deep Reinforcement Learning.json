{"Title": "Energy-Efficient Collaborative Multi-Access Edge Computing via Deep Reinforcement Learning", "Doi": "10.1109/TII.2022.3213603", "Authors": ["l. tan", "z. kuang", "j. gao", "l. zhao"], "Key Words": ["collaborative computing offloading", "deep reinforcement learning (drl)", "multi-access edge computing (mec)", "resource allocation"], "Abstract": "the joint problem of task offloading collaborative computing and resource allocation for multi access edge computing  mec  is a challenging issue. in this article splitting computing tasks at mec servers through collaboration among mec servers and a cloud server we investigate the joint problem of collaborative task offloading and resource allocation. a collaborative task offloading computing resource allocation and subcarrier and power allocation problem in mec is formulated. the goal is to minimize the total energy consumption of the mec system while satisfying a delay constraint. the formulated problem is a nonconvex mixed integer optimization problem. in order to solve the problem we propose a deep reinforcement learning  drl  based bilevel optimization framework. the task offloading decision computing collaboration decision and power and subcarriers allocation subproblems are solved at the upper level whereas the computing resource allocation subproblem is solved at the lower level. we combine dueling dqn and double dqn and add adaptive parameter space noise to improve drl performance in mec. simulation results demonstrate that the proposed algorithm achieves near optimal performance in energy efficiency and task completion rate compared with other drl based approaches and other benchmark schemes under various network parameter settings.", "Pub Date": "2023-05-24"}
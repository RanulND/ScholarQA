{"Title": "Foundation Model Assisted Automatic Speech Emotion Recognition: Transcribing, Annotating, and Augmenting", "Doi": "10.1109/ICASSP48485.2024.10448130", "Authors": ["t. feng", "s. narayanan"], "Key Words": ["speech", "emotion recognition", "foundation model", "large language model"], "Abstract": "significant advances are being made in speech emotion recognition  ser  using deep learning models. nonetheless training ser systems remains challenging requiring both time and costly resources. like many other machine learning tasks acquiring datasets for ser requires substantial data annotation efforts including transcription and labeling. these annotation processes present challenges when attempting to scale up conventional ser systems. recent developments in foundational models have had a tremendous impact giving rise to applications such as chatgpt. these models have enhanced human computer interactions including bringing unique possibilities for streamlining data collection in fields like ser. in this research we explore the use of foundational models to assist in automating ser from transcription and annotation to augmentation. our study demonstrates that these models can generate transcriptions to enhance the performance of ser systems that rely solely on speech data. furthermore we note that annotating emotions from transcribed speech remains a challenging task. however combining outputs from multiple large language model enhances the quality of annotations. lastly our findings suggest the feasibility of augmenting existing speech emotion datasets by annotating unlabeled speech samples.", "Pub Date": "2024-03-18"}
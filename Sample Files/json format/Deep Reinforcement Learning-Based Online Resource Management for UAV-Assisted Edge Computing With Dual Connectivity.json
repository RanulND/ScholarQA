{"Title": "Deep Reinforcement Learning-Based Online Resource Management for UAV-Assisted Edge Computing With Dual Connectivity", "Doi": "10.1109/TNET.2023.3263538", "Authors": ["l. t. hoang", "c. t. nguyen", "a. t. pham"], "Key Words": ["lyapunov optimization", "mobile edge computing", "deep reinforcement learning (drl)", "queueing networks"], "Abstract": "mobile edge computing  mec  is a key technology towards delay sensitive and computation intensive applications in future cellular networks. in this paper we consider a multi user multi server system where the cellular base station is assisted by a uav both of which provide additional mec services to the terrestrial users. via dual connectivity  dc  each user can simultaneously offload tasks to the macro base station and the uav mounted mec server for parallel computing while also processing some tasks locally. we aim to propose an online resource management framework that minimizes the average power consumption of the whole system considering long term constraints on queue stability and computational delay of the queueing system. due to the coexistence of two servers the problem is highly complex and formulated as a multi stage mixed integer non linear programming  minlp  problem. to solve the minlp with reduced computational complexity we first adopt lyapunov optimization to transform the original multi stage problem into deterministic problems that are manageable in each time slot. afterward the transformed problem is solved using an integrated learning optimization approach where model free deep reinforcement learning  drl  is combined with model based optimization. via extensive simulation and theoretical analyses we show that the proposed framework is guaranteed to converge and can produce nearly the same performance as the optimal solution obtained via an exhaustive search.", "Pub Date": "2023-12-19"}
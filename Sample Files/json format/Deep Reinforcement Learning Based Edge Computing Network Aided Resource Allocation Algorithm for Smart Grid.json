{"Title": "Deep Reinforcement Learning Based Edge Computing Network Aided Resource Allocation Algorithm for Smart Grid", "Doi": "10.1109/ACCESS.2022.3221740", "Authors": ["y. chi", "y. zhang", "y. liu", "h. zhu", "z. zheng", "r. liu", "p. zhang"], "Key Words": ["deep reinforcement learning", "delay sensitive", "edge computing network", "resource allocation", "smart grid", "user request"], "Abstract": "the dramatic increase in the volume of users and services makes scheduling network resources for smart grids a key challenge. network slicing is an important technology to solve this problem. we introduce edge computing networks into the smart grid to intelligently allocate resources based on users\u201a\u00e4\u00f4 quality of service  qos  and available resources. however existing heuristic resource scheduling algorithms often lead to resource fragmentation and thus fall into local optima. to this end we propose a deep reinforcement learning  drl  based virtual network embedding algorithm to optimize the resource allocation strategy of smart grids from a network virtualization perspective. we extract the network properties of the smart grid to construct a policy network as a training environment for drl agents. finally drl derives the probability of each node being embedded based on the extracted attributes of edge computing nodes and completes user request  ur  embedding based on this probability. the experimental results show that the algorithm proposed in this paper has excellent performance with guaranteed low latency 21% improvement in long term revenue and 5.6% improvement in ur success rate compared with the other two algorithms.", "Pub Date": "2023-01-23"}
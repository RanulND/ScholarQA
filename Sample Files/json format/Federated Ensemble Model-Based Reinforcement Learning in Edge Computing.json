{"Title": "Federated Ensemble Model-Based Reinforcement Learning in Edge Computing", "Doi": "10.1109/TPDS.2023.3264480", "Authors": ["j. wang", "j. hu", "j. mills", "g. min", "m. xia", "n. georgalas"], "Key Words": ["deep reinforcement learning", "distributed machine learning", "edge computing", "federated learning"], "Abstract": "federated learning  fl  is a privacy preserving distributed machine learning paradigm that enables collaborative training among geographically distributed and heterogeneous devices without gathering their data. extending fl beyond the supervised learning models federated reinforcement learning  frl  was proposed to handle sequential decision making problems in edge computing systems. however the existing frl algorithms directly combine model free rl with fl thus often leading to high sample complexity and lacking theoretical guarantees. to address the challenges we propose a novel frl algorithm that effectively incorporates model based rl and ensemble knowledge distillation into fl for the first time. specifically we utilise fl and knowledge distillation to create an ensemble of dynamics models for clients and then train the policy by solely using the ensemble model without interacting with the environment. furthermore we theoretically prove that the monotonic improvement of the proposed algorithm is guaranteed. the extensive experimental results demonstrate that our algorithm obtains much higher sample efficiency compared to classic model free frl algorithms in the challenging continuous control benchmark environments under edge computing settings. the results also highlight the significant impact of heterogeneous client data and local model update steps on the performance of frl validating the insights obtained from our theoretical analysis.", "Pub Date": "2023-05-11"}
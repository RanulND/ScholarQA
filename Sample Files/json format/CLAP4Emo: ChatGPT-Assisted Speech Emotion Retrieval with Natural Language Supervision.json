{"Title": "CLAP4Emo: ChatGPT-Assisted Speech Emotion Retrieval with Natural Language Supervision", "Doi": "10.1109/ICASSP48485.2024.10447102", "Authors": ["w. -c. lin", "s. ghaffarzadegan", "l. bondi", "a. kumar", "s. das", "h. -h. wu"], "Key Words": ["speech emotion retrieval", "contrastive language-audio pretraining", "large language models", "foundation model"], "Abstract": "speech emotion retrieval is an important technique for large scale and high quality data collection. conventional approach using ensemble of classification models might limit the retrieved emotion diversity and or underperform in out of domain acoustic conditions. natural language is diverse and agnostic to specific acoustic concepts embedding a huge potential for developing language based speech emotion retrieval system. in this paper we introduce clap4emo a novel framework to retrieve emotional speech via natural language prompts based on contrastive language audio pretraining. to compensate for the absence of training captions in existing public datasets we propose a systematic framework that applies chatgpt to generate emotion captions. the experimental results demonstrate that our method can effectively improve the retrieved sample diversity while maintaining high precision across five benchmark datasets. by leveraging large language models we establish a connection between audio and language for emotion description culminating in an intuitive and interactive retrieval system. we release the generated emotion captions at  https //github.com boschresearch/soundsee emo caps", "Pub Date": "2024-03-18"}
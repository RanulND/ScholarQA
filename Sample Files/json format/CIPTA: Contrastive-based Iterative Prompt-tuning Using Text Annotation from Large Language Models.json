{"Title": "CIPTA: Contrastive-based Iterative Prompt-tuning Using Text Annotation from Large Language Models", "Doi": "10.1109/ICECAI58670.2023.10176586", "Authors": ["y. yan", "w. du", "d. yang", "d. yin"], "Key Words": ["public opinion analysis", "few-shot learning", "prompt tuning", "large language model", "contrastive learning"], "Abstract": "in recent years public opinion analysis has become increasingly important due to the widespread use of social media platforms and the growing influence of online information on public security. prompt tuning a typical few shot learning method ensures that the model quickly adapts to opinion analysis with different classification rules. however existing prompt tuning for opinion analysis cannot guarantee the effectiveness of the model in zero shot or one shot cases. in this study we propose the contrastive based iterative prompt tuning method using text annotation from large language models  llms  cipta for low resource public opinion analysis. specifically with a small amount of manually labeled data cipta leverages the knowledge from llms to text annotation and utilizes unsupervised contrastive embedding training to optimize text representation. based on the prompt tuning method and the iterative training over unlabeled data the model further utilizes the knowledge from the pre training stage. experiment results on tweet data show that our cipta achieves encouraging performance in public opinion analysis.", "Pub Date": "2023-07-13"}
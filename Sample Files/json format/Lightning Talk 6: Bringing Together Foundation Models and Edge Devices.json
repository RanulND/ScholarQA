{"Title": "Lightning Talk 6: Bringing Together Foundation Models and Edge Devices", "Doi": "10.1109/DAC56929.2023.10247694", "Authors": ["n. j. eliopoulos", "y. -h. lu"], "Key Words": ["edge computing", "deep learning", "foundation model", "transformer neural network", "energy efficiency"], "Abstract": "deep learning models have been widely used in natural language processing and computer vision. these models require heavy computation large memory and massive amounts of training data. deep learning models may be deployed on edge devices when transferring data to cloud is infeasible or undesirable. running these models on edge devices require significant improvement in the efficiency by reducing the models\u201a\u00e4\u00f4 resource demands. existing methods to improve efficiency often require new architectures and retraining. the recent trend in machine learning is to create general purpose models  called foundation models . these pre trained models can be repurposed for different applications. this paper reviews the methods for improving efficiency of machine learning models the rise of foundation models challenges and possible solutions improving efficiency of pre trained models. future solutions for better efficiency should focus on improving existing trained models with no or limited training.", "Pub Date": "2023-09-15"}
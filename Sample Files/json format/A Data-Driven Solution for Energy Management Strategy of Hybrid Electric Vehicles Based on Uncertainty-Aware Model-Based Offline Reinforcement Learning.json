{"Title": "A Data-Driven Solution for Energy Management Strategy of Hybrid Electric Vehicles Based on Uncertainty-Aware Model-Based Offline Reinforcement Learning", "Doi": "10.1109/TII.2022.3213026", "Authors": ["b. hu", "y. xiao", "s. zhang", "b. liu"], "Key Words": ["data-driven", "energy management strategy (ems)", "hybrid electric vehicle (hev)", "model-based", "offline reinforcement learning (rl)"], "Abstract": "energy management strategy  ems  is the key technology to improving the fuel efficiency of hybrid electric vehicles  hev . in recent years the development of artificial intelligence has enabled tremendous advances by utilizing reinforcement learning  rl  for training and deploying deep neural network based ems. however in contrast to the fields of deep learning such as computer vision and natural language processing which mainly rely on large scale offline datasets most rl based policies must be trained online by trial and error with the initial performance being almost arbitrary. such a paradigm is considered inefficient and unsafe for industrial automation and can only be used to tackle the ems problems in the simulation world. considering that large historical interactive datasets are readily available in the ems domain if an rl algorithm can be used to extract a policy purely offline from the prior collected dataset and improve upon data logging policy the current issues including sample inefficiency unsafe exploration and simulation to real gap that prevent the widespread use of rl methods could be mitigated to a great extent. to this end this article presents a feasible algorithmic framework for model based offline rl. unlike vanilla rl approaches without any consideration against distributional shift a data driven dynamic model is built before the policy training using rl. after that two techniques namely conservative mdp and state regularization are augmented which are proved to be effective against model overexploitation. by incorporating the guidance of uncertainty awareness a near optimal policy can be obtained by using only the dataset from a suboptimal controller.", "Pub Date": "2023-05-24"}
{"Title": "Front-End Fusion and Large-Scale Weakly Supervised Decoding Module Based Myanmar Speech Recognition", "Doi": "10.1109/IALP61005.2023.10337260", "Authors": ["j. cui", "j. yang"], "Key Words": ["low-resource", "myanmar", "transfer learning", "auto- regressive language model"], "Abstract": "end to end  e2e  speech recognition based on deep neural networks has become the mainstream approach for building high performance speech recognition systems. training e2e models relies on large scale datasets of \u201a\u00e4\u00faaudio  text\u201a\u00e4\u00f9 pairs which presents challenges for researching speech recognition in non general purpose languages under extremely low resource conditions. unsupervised pre trained models have achieved good performance in many low resource automatic speech recognition and have been widely applied. in this paper under extremely low resource conditions we build a baseline system for myanmar language speech recognition based on speech self supervised learning front end models. moreover we explore methods to further improve the speech recognition performance for myanmar language based on this baseline system and propose and implement two optimization methods   1  linear fusion of acoustic spectral features with self supervised speech representation features to extract richer and more accurate speech features and  2  introducing a multilingual multitask weakly supervised pre trained whisper model as the decoder module for myanmar language speech recognition system. experimental results show that the myanmar language speech recognition baseline system constructed in this study has a character error rate of 21.5%. after introducing the proposed improvement methods in this study the character error rate decreases to 16.0%.", "Pub Date": "2023-12-12"}
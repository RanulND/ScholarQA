{"Title": "How Does Pre-Trained Wav2Vec 2.0 Perform on Domain-Shifted Asr? an Extensive Benchmark on Air Traffic Control Communications", "Doi": "10.1109/SLT54892.2023.10022724", "Authors": ["j. zuluaga-gomez", "a. prasad", "i. nigmatulina", "s. s. sarfjoo", "p. motlicek", "m. kleinert", "h. helmke", "o. ohneiser", "q. zhan"], "Key Words": ["automatic speech recognition", "wav2vec 2.0", "self-supervised pre-training", "air traffic control communications"], "Abstract": "recent work on self supervised pre training focus on leveraging large scale unlabeled speech data to build robust end to end  e2e  acoustic models  am  that can be later fine tuned on downstream tasks e.g. automatic speech recognition  asr . yet few works investigated the impact on performance when the data properties substantially differ between the pre training and fine tuning phases termed domain shift. we target this scenario by analyzing the robustness of wav2vec 2.0 and xls r models on downstream asr for a completely unseen domain air traffic control  atc  communications. we benchmark these two models on several open source and challenging atc databases with signal to noise ratio between 5 to 20 db. relative word error rate  wer  reductions between 20% to 40% are obtained in comparison to hybrid based asr baselines by only fine tuning e2e acoustic models with a smaller fraction of labeled data. we analyze wers on the low resource scenario and gender bias carried by one atc dataset.", "Pub Date": "2023-01-27"}
{"Title": "CRA: Text to Image Retrieval for Architecture Images by Chinese CLIP", "Doi": "10.1109/CMVIT57620.2023.00015", "Authors": ["s. wang", "y. yan", "x. yang", "k. huang"], "Key Words": ["text-to-image retrieval", "chinese clip", "contrastive learning"], "Abstract": "text to image retrieval is revolutionized since the contrastive language image pre training model was proposed. most existing methods learn a latent representation of text and then align its embedding with the corresponding image\u201a\u00e4\u00f4s embedding from an image encoder. recently several chinese clip models have supported a good representation of paired image text sets. however adapting the pre trained retrieval model to a professional domain still remains a challenge mainly due to the large domain gap between the professional and general text image sets. in this paper we introduce a novel contrastive tuning model named cra using chinese texts to retrieve architecture related images by fine tuning the pre trained chinese clip. instead of fine tuning the whole clip model we engage the locked image text tuning  lit  strategy to adapt the architecture terminology sets by tuning the text encoder and freezing the pre trained large scale image encoder. we further propose a text image dataset of architectural design. on the text to image retrieval task we improve the metric of r@20 from 44.92% by the original chinese clip model to 74.61% by our cra model in the test set.", "Pub Date": "2023-06-26"}
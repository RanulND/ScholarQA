{"Title": "An Investigation of Monotonic Transducers for Large-Scale Automatic Speech Recognition", "Doi": "10.1109/SLT54892.2023.10022569", "Authors": ["n. moritz", "f. seide", "d. le", "j. mahadeokar", "c. fuegen"], "Key Words": ["speech recognition", "monotonic transducer", "gtc-t", "rnn-t"], "Abstract": "the two most popular loss functions for streaming end to end automatic speech recognition  asr  are rnn transducer  rnn t  and connectionist temporal classification  ctc . between these two loss types we can classify the monotonic rnn t  monornn t  and the recently proposed ctc like transducer  ctc t . monotonic transducers have a few advantages. first rnn t can suffer from runaway hallucination where a model keeps emitting non blank symbols without advancing in time. secondly monotonic transducers consume exactly one model score per time step and are therefore more compatible with traditional fst based asr decoders. however the monornn t so far has been found to have worse accuracy than rnn t. it does not have to be that way  by regularizing the training via joint las training or parameter initialization from rnn t both monornn t and ctc t perform as well or better than rnn t. this is demonstrated for librispeech and for a large scale in house data set.", "Pub Date": "2023-01-27"}
{"Title": "A Contextualized Transformer-Based Method for Cyberbullying Detection", "Doi": "10.1109/DSAA60987.2023.10302478", "Authors": ["n. rezvani", "a. beheshti", "x. zhang"], "Key Words": ["cyberbullying detection", "attention based models", "transfer learning", "contextualization"], "Abstract": "automatic detection of cyberbullying is a challenging task due to the availability of limited trained data which is usually noisy and inherently multimodal. transfer learning over pre trained bert based language models has succeeded in various complex use cases like sequence to sequence translation and text classification. these methods mainly utilize transformer models to learn the word and sentence level relationships. while they have demonstrated promising results they only focus on textual features without taking contextual and structural information into account. moreover due to the data heavy nature of bert based models they may fail to model all the desired relationships if not adequate training data is provided to them during the fine tuning process. in this paper we propose a novel session level contextualized transformer based architecture for cyberbullying detection  sectr cd  which can leverage transfer learning for modeling word level attention while also being able to model sentence level relationships in large bodies of text. the model is also capable of utilizing other contextual features from various modalities like images and social information. our experimental results indicate remarkable improvement in the cyberbullying detection task even in the presence of limited training samples.", "Pub Date": "2023-11-06"}
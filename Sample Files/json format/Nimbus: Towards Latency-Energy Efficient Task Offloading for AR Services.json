{"Title": "Nimbus: Towards Latency-Energy Efficient Task Offloading for AR Services", "Doi": "10.1109/TCC.2022.3146615", "Authors": ["v. cozzolino", "l. tonetto", "n. mohan", "a. y. ding", "j. ott"], "Key Words": ["edge computing", "augmented reality", "optimization", "resource management", "cloud computing"], "Abstract": "widespread adoption of mobile augmented reality  ar  and virtual reality  vr  applications depends on their smoothness and immersiveness. modern ar applications applying computationally intensive computer vision algorithms can burden today mobile devices and cause high energy consumption and or poor performance. to tackle this challenge it is possible to offload part of the computation to nearby devices at the edge. however this calls for smart task placement strategies in order to efficiently use the resources of the edge infrastructure. in this paper we introduce nimbus \u201a\u00e4\u00ee a task placement and offloading solution for a multi tier edge cloud infrastructure where deep learning tasks are extracted from the ar application pipeline and offloaded to nearby gpu powered edge devices. our aim is to minimize the latency experienced by end users and the energy costs on mobile devices. our multifaceted evaluation based on benchmarked performance of ar tasks shows the efficacy of our solution. overall nimbus reduces the task latency by $\\sim 4\\times$\u201a\u00e0\u00ba4\u221a\u00f3 and the energy consumption by $\\sim$\u201a\u00e0\u00ba77% for real time object detection in ar applications. we also benchmark three variants of our offloading algorithm disclosing the trade off of centralized versus distributed execution.", "Pub Date": "2023-06-06"}
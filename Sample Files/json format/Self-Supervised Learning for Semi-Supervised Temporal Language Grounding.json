{"Title": "Self-Supervised Learning for Semi-Supervised Temporal Language Grounding", "Doi": "10.1109/TMM.2022.3228167", "Authors": ["f. luo", "s. chen", "j. chen", "z. wu", "y. -g. jiang"], "Key Words": ["temporal language grounding", "semi-supervised learning", "contrastive learning"], "Abstract": "given a text description temporal language grounding  tlg  aims to localize temporal boundaries of the segments that contain the specified semantics in an untrimmed video. tlg is inherently a challenging task as it requires comprehensive understanding of both sentence semantics and video contents. previous works either tackle this task in a fully supervised setting that requires a large amount of temporal annotations or in a weakly supervised setting that usually cannot achieve satisfactory performance. since manual annotations are expensive to cope with limited annotations we tackle tlg in a semi supervised way by incorporating self supervised learning and propose self supervised semi supervised temporal language grounding  s$^{4}$tlg . s$^{4}$tlg consists of two parts   1  a pseudo label generation module that adaptively produces instant pseudo labels for unlabeled samples based on predictions from a teacher model   2  a self supervised feature learning module with inter modal and intra modal contrastive losses to learn video feature representations under the constraints of video content consistency and video text alignment. we conduct extensive experiments on the activitynet cd ood and charades cd ood datasets. the results demonstrate that our proposed s$^{4}$tlg can achieve competitive performance compared to fully supervised state of the art methods while only requiring a small portion of temporal annotations.", "Pub Date": "2023-12-08"}
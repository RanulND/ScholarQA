{"Title": "Research on Offloading Strategy of Twin UAVs Edge Computing Tasks for Emergency Communication", "Doi": "10.1109/TNSM.2023.3310486", "Authors": ["b. ji", "m. zhang", "j. huang", "y. wang", "l. xing", "t. li", "c. han", "s. mumtaz"], "Key Words": ["awmen", "td3-bc-r", "ac-r", "td3-r", "ddpg-r"], "Abstract": "aiming to solve the problem of interruption of normal communication service caused by the damage of ground communication facilities after disaster an air ground integrated mobile edge network  awmen  offloading model was established under the constraints of communication security energy consumption and coverage. the traditional method needs to be re iterated every time the preset environmental state changes which will waste a lot of communication resources and computing resources greatly reduce the efficiency and face the risk of data privacy disclosure. however the deep reinforcement learning method under the federated learning framework will be more flexible and applicable to dynamic scenarios. a markov decision process model is constructed based on the unmanned aerial vehicles  uav  and the environment. the experience trajectory is designed by interacting with the external environment and the optimal offloading strategy is obtained. the twin delayed deep deterministic policy gradient of behavior cloning  td3 bc r  is compared with baseline method  0 1 mode  actor critic  ac r  deep deterministic policy gradient  ddpg r  and twin delayed deep deterministic policy gradient  td3 r  the experiment shows that the total time cost of td3 bc r is reduced by more than 1/3 and low latency transmission is also achieved.", "Pub Date": "2024-02-07"}
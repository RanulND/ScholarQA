{"Title": "SAKP: A Korean Sentiment Analysis Model via Knowledge Base and Prompt Tuning", "Doi": "10.1109/CCAI57533.2023.10201257", "Authors": ["h. wen", "z. zhang"], "Key Words": ["korean sentiment classification", "knowledge base", "pre-trained language model", "prompt", "korean natural language processing"], "Abstract": "with the help of pre trained language models tasks such as sentiment analysis and text classification have achieved good results. with the advent of prompt tuning especially previous studies have shown that in the case of few data the prompt tuning method has significant advantages over the general tuning method of additional classifiers. at present there are relatively few studies on sentiment analysis of korean chinese texts.this paper proposes a low resource sentiment classification method based on pre trained language models  plms  combined with prompt tuning. in this work we chose to use the pre trained language model klue and elaborated a korean prompt template with an expanded knowledge base and filtering in the verbalizer section. we focus on collecting external knowledge and integrating it into the utterance to form a prompt tuning of knowledge to improve and stabilize the prompt tuning. specifically we use the k means clustering algorithm to construct the label wordspace of the external knowledge base  knowledge base  extended language and use plm itself to refine the extended labeled wordspace before using the extended labeled wordspace for prediction. a large number of experiments on the few shot emotion classification task prove the effectiveness of knowledge prompt tuning.", "Pub Date": "2023-08-03"}
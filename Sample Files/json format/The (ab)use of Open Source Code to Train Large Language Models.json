{"Title": "The (ab)use of Open Source Code to Train Large Language Models", "Doi": "10.1109/NLBSE59153.2023.00008", "Authors": ["a. al-kaswan", "m. izadi"], "Key Words": ["nlp", "large-language-models", "gpt", "deep-learning", "software-engineering", "memorization", "open-source", "copyleft", "copyright"], "Abstract": "in recent years large language models  large language model  have gained significant popularity due to their ability to generate human like text and their potential applications in various fields such as software engineering. large language model for code are commonly trained on large unsanitized corpora of source code scraped from the internet. the content of these datasets is memorized and emitted by the models often in a verbatim manner. in this work we will discuss the security privacy and licensing implications of memorization. we argue why the use of copyleft code to train large language model is a legal and ethical dilemma. finally we provide four actionable recommendations to address this issue.", "Pub Date": "2023-07-26"}
{"Title": "Recognizing British Sign Language Using Deep Learning: A Contactless and Privacy-Preserving Approach", "Doi": "10.1109/TCSS.2022.3210288", "Authors": ["h. hameed", "m. usman", "a. tahir", "k. ahmad", "a. hussain", "m. a. imran", "q. h. abbasi"], "Key Words": ["british sign language (bsl)", "contactless monitoring", "deep learning (dl)", "micro-doppler signatures", "radio frequency (rf) sensing"], "Abstract": "sign language is utilized by deaf mute to communicate through hand movements body postures and facial emotions. the motions in sign language comprise a range of distinct hand and finger articulations that are occasionally synchronized with the head face and body. automatic sign language recognition  slr  is a highly challenging area and still remains in its infancy compared with speech recognition after almost three decades of research. current wearable and vision based systems for slr are intrusive and suffer from the limitations of ambient lighting and privacy concerns. to the best of our knowledge our work proposes the first contactless british sign language  bsl  recognition system using radar and deep learning  dl  algorithms. our proposed system extracts the 2 d spatiotemporal features from the radar data and applies the state of the art dl models to classify spatiotemporal features from bsl signs to different verbs and emotions such as help drink eat happy hate and sad. we collected and annotated a large scale benchmark bsl dataset covering 15 different types of bsl signs. our proposed system demonstrates highest classification performance with a multiclass accuracy of up to 90.07% at a distance of 141 cm from the subject using the vggnet model.", "Pub Date": "2023-08-02"}
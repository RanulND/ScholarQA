{"Title": "Mapache: Masked Parallel Transformer for Advanced Speech Editing and Synthesis", "Doi": "10.1109/ICASSP48485.2024.10448121", "Authors": ["g. c\u221a\u00b0mbara", "p. l. tobing", "m. babianski", "r. vipperla", "d. w. r. shmelkin", "g. coccia", "o. angelini", "a. joly", "m. lajszczak", "v. pollet"], "Key Words": ["text-to-speech", "speech editing", "transformers", "diffusion", "generative ai"], "Abstract": "recent advancements in generative ai such as scaled transformer large language models  llm  and diffusion decoders have revolutionized speech synthesis. with speech encompassing the complexities of natural language and audio dimensionality many recent models have relied on autoregressive modeling of quantized speech tokens. such an approach limits speech synthesis to left to right generation making these models unsuitable for speech edits free from audio discontinuities. we introduce mapache a novel architecture that combines a non autoregressive masked speech language model with acoustic diffusion modeling offering a unique fully parallel pipeline. mapache excels in precise speech editing that is indiscernible to human listeners exhibiting inpainting and zero shot synthesis capabilities that either surpass or rival those of other state of the art models that specialize in just one of these tasks. this paper also sheds light on optimizing the decoding process for such non autoregressive models.", "Pub Date": "2024-03-18"}
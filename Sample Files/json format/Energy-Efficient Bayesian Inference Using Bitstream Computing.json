{"Title": "Energy-Efficient Bayesian Inference Using Bitstream Computing", "Doi": "10.1109/LCA.2023.3238584", "Authors": ["s. khoram", "k. daruwalla", "m. lipasti"], "Key Words": ["bayesian neural networks", "special-purpose hardware", "stochastic computing"], "Abstract": "uncertainty quantification is critical to many machine learning applications especially in mobile and edge computing tasks like self driving cars robots and mobile devices. bayesian neural networks can be used to provide these uncertainty quantifications but they come at extra computation costs. however power and energy can be limited at the edge. in this work we propose using stochastic bitstream computing substrates for deploying bnns which can significantly reduce power and costs. we design our bayesian bitstream processor hardware for an audio classification task as a test case and show that it can outperform a micro controller baseline in energy by two orders of magnitude and delay by an order of magnitude at lower power.", "Pub Date": "2023-05-12"}
{"Title": "Exploring code2vec and ASTminer for Python Code Embeddings", "Doi": "10.1109/SEAI59139.2023.10217505", "Authors": ["l. h. ngo", "v. sekar", "e. leclercq", "j. rivalan"], "Key Words": ["machine learning", "neural network", "distributed representations", "code search"], "Abstract": "automated understanding of code meaning and use has become an intrinsic part of software development recently. neural models are being used in various natural language processing tasks as they can represent natural language using vectors that carry semantic meanings. although code is not natural language we believe neural models to be capable of learning semantics and syntactic properties available in code snippets. to achieve such goal we represent a code snippet using its abstract syntax tree  ast  syntactic paths to capture regularities that reflect common code patterns. this representation lowers significantly learning effort while being scalable to multiple problems and large code bases. in our work we adopt astminer with code2vec to represent code snippets as continuously distributed code vectors called \"code embeddings\" used to predict the semantic properties of the snippets. this approach decomposes code into a collection of ast paths and learns each path atomic representation while learning how to aggregate them. code2vec is then paired with other neural models which represent query to create a hybrid model for the task of code search. while code2vec was originally developed for java only we present in this article our efforts to extend the method to python language.", "Pub Date": "2023-08-23"}
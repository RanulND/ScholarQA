{"Title": "Intelligent Delay-Aware Partial Computing Task Offloading for Multiuser Industrial Internet of Things Through Edge Computing", "Doi": "10.1109/JIOT.2021.3123406", "Authors": ["x. deng", "j. yin", "p. guan", "n. n. xiong", "l. zhang", "s. mumtaz"], "Key Words": ["deep reinforcement learning (rl)", "industrial internet of things (iiot)", "industry 4.0", "mobile-edge computing (mec)", "partial computation offloading"], "Abstract": "the development of industrial internet of things  iiot  and industry 4.0 has completely changed the traditional manufacturing industry. intelligent iiot technology usually involves a large number of intensive computing tasks. resource constrained iiot devices often cannot meet the real time requirements of these tasks. as a promising paradigm the mobile edge computing  mec  system migrates the computation intensive tasks from resource constrained iiot devices to nearby mec servers thereby obtaining lower delay and energy consumption. however considering the varying channel conditions as well as the distinct delay requirements for various computing tasks it is challenging to coordinate the computing task offloading among multiple users. in this article we propose an autonomous partial offloading system for delay sensitive computation tasks in multiuser iiot mec systems. our goal is to provide offloading services with minimum delay for better quality of service  qos . enlighten by the recent advancement of reinforcement learning  rl  we propose two rl based offloading strategies to automatically optimize the delay performance. specifically we first implement the  $q$  learning algorithm to provide a discrete partial offloading decision. then to further optimize the system performance with more flexible task offloading the offloading decisions are given as continuous based on deep deterministic policy gradient  ddpg . the simulation results show that the  $q$  learning scheme reduces the delay by 23% and the ddpg scheme reduces the delay by 30%.", "Pub Date": "2023-02-06"}
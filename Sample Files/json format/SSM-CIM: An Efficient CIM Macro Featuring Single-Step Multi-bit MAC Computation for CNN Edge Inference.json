{"Title": "SSM-CIM: An Efficient CIM Macro Featuring Single-Step Multi-bit MAC Computation for CNN Edge Inference", "Doi": "10.1109/TCSI.2023.3301814", "Authors": ["h. zhang", "s. he", "x. lu", "x. guo", "s. wang", "y. du", "l. du"], "Key Words": ["cnn inference accelerator", "multi-bit multiplyand-accumulate", "compute-in-memory", "charge domain computing"], "Abstract": "compute in memory  cim  is a promising approach to solving the memory wall problem existing in traditional computing architectures. in this paper we introduce ssm cim a charge domain static random access memory  sram  based cim macro designed for area energy efficient convolutional neural network  cnn  inference. ssm cim utilizes an original sign magnitude data encoding method for both inputs and weights. by codesigning four adjacent sram computing cells and employing a 3 bit digital to analog converter  dac  ssm cim performs accurate 4 bit multiply and accumulate  mac  computation in a single step eliminating the peripheral digital shift and add circuits. to digitize the mac computing results a dedicated multi reference assisted sar adc is designed by reusing the reference voltages from the dac which offers significant power and area savings. in addition analog computing errors and quantization errors are analyzed to ensure the multi bit computing accuracy of ssm cim. ssm cim is implemented and evaluated using 28 nm global foundry process. the post layout simulation results validate the excellent computing linearity and accuracy of ssm cim. benefitting from the compact layout design and fully parallel computing flow the  $144\\times 256$  macro achieves a peak throughput of 2.3 tops an area efficiency of 10.2 tops mm2 and an energy efficiency of 205.4 tops w with 4 bit weights and 4 bit inputs.", "Pub Date": "2023-10-25"}
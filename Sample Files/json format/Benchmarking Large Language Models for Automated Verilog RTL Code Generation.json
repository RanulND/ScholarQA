{"Title": "Benchmarking Large Language Models for Automated Verilog RTL Code Generation", "Doi": "10.23919/DATE56975.2023.10137086", "Authors": ["s. thakur", "b. ahmad", "z. fan", "h. pearce", "b. tan", "r. karri", "b. dolan-gavitt", "s. garg"], "Key Words": ["transformers", "verilog", "gpt", "llm"], "Abstract": "automating hardware design could obviate a signif icant amount of human error from the engineering process and lead to fewer errors. verilog is a popular hardware description language to model and design digital systems thus generating verilog code is a critical first step. emerging large language models  llms  are able to write high quality code in other programming languages. in this paper we characterize the ability of llms to generate useful verilog. for this we fine tune pre trained llms on verilog datasets collected from github and verilog textbooks. we construct an evaluation framework comprising test benches for functional analysis and a flow to test the syntax of verilog code generated in response to problems of varying difficulty. our findings show that across our problem scenarios the fine tuning results in llms more capable of producing syntactically correct code  25.9% overall . further when analyzing functional correctness a fine tuned open source codegen llm can outperform the state of the art commercial codex llm  6.5% overall . we release our training evaluation scripts and llm checkpoints as open source contributions.", "Pub Date": "2023-06-02"}
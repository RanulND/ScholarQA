{"Title": "Benchmarking Large Language Models for Automated Verilog RTL Code Generation", "Doi": "10.23919/DATE56975.2023.10137086", "Authors": ["s. thakur", "b. ahmad", "z. fan", "h. pearce", "b. tan", "r. karri", "b. dolan-gavitt", "s. garg"], "Key Words": ["transformers", "verilog", "gpt", "llm"], "Abstract": "automating hardware design could obviate a signif icant amount of human error from the engineering process and lead to fewer errors. verilog is a popular hardware description language to model and design digital systems thus generating verilog code is a critical first step. emerging large language models  large language model  are able to write high quality code in other programming languages. in this paper we characterize the ability of large language model to generate useful verilog. for this we fine tune pre trained large language model on verilog datasets collected from github and verilog textbooks. we construct an evaluation framework comprising test benches for functional analysis and a flow to test the syntax of verilog code generated in response to problems of varying difficulty. our findings show that across our problem scenarios the fine tuning results in large language model more capable of producing syntactically correct code  25.9% overall . further when analyzing functional correctness a fine tuned open source codegen large language model can outperform the state of the art commercial codex large language model  6.5% overall . we release our training evaluation scripts and large language model checkpoints as open source contributions.", "Pub Date": "2023-06-02"}
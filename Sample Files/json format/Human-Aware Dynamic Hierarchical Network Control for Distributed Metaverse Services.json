{"Title": "Human-Aware Dynamic Hierarchical Network Control for Distributed Metaverse Services", "Doi": "10.1109/JSAC.2023.3345399", "Authors": ["q. chen", "r. li", "x. xu", "j. wu", "h. jiang", "m. qiu"], "Key Words": ["human-aware", "dynamic network control", "multi-agent", "distributed coordination", "nr-u", "ris", "metaverse"], "Abstract": "metaverse has emerged as a revolutionary technique for transforming the way people interact with digital content which relies on a distributed computing and communication infrastructure encompassing terminal users edge servers and cloud servers. however the rapid evolution of the metaverse presents challenges that surpass the capabilities of existing communication and network infrastructures particularly on network bandwidth and latency. additionally human experience becomes a critical factor in this domain. therefore we introduce a human aware hierarchical software defined network  sdn  architecture consisting of a metaverse cloud layer a mobile edge computing  mec  server empowered edge layer and a distributed terminal layer. each mec server dynamically controls a multi antenna base station  bs  and several reconfigurable intelligent surfaces  riss  according to the terminal immersive experience requirements in real time. to overcome the bandwidth limitation we propose a novel smart reconfigurable spatial reuse new radio in unlicensed spectrum  nr u  framework which can realize customizable communications through flexibly and coordinately reconfiguring beams among the coordination between bss and riss. the objective function is formulated as a lyapunov optimization based decentralized partially observable markov decision process  dec pomdp  problem to maximize the spectral efficiency while guaranteeing the latency and reliability requirements in metaverse via a joint user selection phase shift control and beam coordination strategy. to solve the above non convex strongly coupled and mixed integer nonlinear programming  minlp  we propose a novel multi agent hierarchical deep reinforcement learning  mahdrl  algorithm that integrates deep q network  dqn  to solve discrete problems deep deterministic policy gradient  ddpg  to solve continuous problems and mixing network to capture complex interactions between multiple agents. numerical results demonstrate the effectiveness of the proposed algorithm and verify the performance improvements compared to traditional multi agent deep reinforcement learning  madrl  algorithms.", "Pub Date": "2024-02-29"}
{"Title": "QuAsyncFL: Asynchronous Federated Learning With Quantization for Cloud\u201a\u00c4\u00ecEdge\u201a\u00c4\u00ecTerminal Collaboration Enabled AIoT", "Doi": "10.1109/JIOT.2023.3290818", "Authors": ["y. liu", "p. huang", "f. yang", "k. huang", "l. shu"], "Key Words": ["artificial intelligence of things (aiot)", "asynchronous federated learning", "cloud\u201a\u00e4\u00ecedge\u201a\u00e4\u00ecterminal collaboration", "communication efficiency", "quantization"], "Abstract": "federated learning is a promising technique that facilitates cloud\u201a\u00e4\u00ecedge\u201a\u00e4\u00ecterminal collaboration in artificial intelligence of things  aiot . it will enable model training without centralizing data addressing privacy and security concerns. however when applied to aiot this technique faces several challenges such as low communication efficiency among terminal devices edges and cloud platforms. in this article we propose a novel approach called asynchronous federated learning with quantization  quasyncfl  which combines asynchronous federated learning with an unbiased nonuniform quantizer to address the issue of low communication efficiency. moreover we provide a detailed theoretical analysis of convergence with quantized gradients proving that the model could converge to a certain bound. our experiments demonstrate that quasyncfl outperforms the original approach achieving significant improvements in terms of communication efficiency. the research results represent a further step toward developing cloud\u201a\u00e4\u00ecedge\u201a\u00e4\u00ecterminal collaboration enabled aiot.", "Pub Date": "2023-12-27"}
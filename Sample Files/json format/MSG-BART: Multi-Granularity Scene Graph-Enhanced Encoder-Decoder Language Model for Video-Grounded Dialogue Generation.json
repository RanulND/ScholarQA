{"Title": "MSG-BART: Multi-Granularity Scene Graph-Enhanced Encoder-Decoder Language Model for Video-Grounded Dialogue Generation", "Doi": "10.1109/ICASSP48485.2024.10447469", "Authors": ["h. liu", "z. chen", "h. li", "p. wang", "y. wang", "y. wang"], "Key Words": ["multi-granularity scene graph", "multi-pointer network", "video-grounded dialogue generation"], "Abstract": "generating dialogue grounded in videos requires a high level of understanding and reasoning about the visual scenes in the videos. however existing large visual language models are not effective due to their latent features and decoder only structure especially with respect to spatio temporal relationship reasoning. in this paper we propose a novel approach named msg bart which enhances the integration of video information by incorporating a multi granularity spatio temporal scene graph into an encoder decoder pre trained language model. specifically we integrate the global and local scene graph into the encoder and decoder respectively to improve both overall perception and target reasoning capability. to further improve the information selection capability we propose a multi pointer network to facilitate selection between text and video. extensive experiments are conducted on three video grounded dialogue benchmarks which show the significant superiority of the proposed msg bart compared to a range of state of the art approaches.", "Pub Date": "2024-03-18"}
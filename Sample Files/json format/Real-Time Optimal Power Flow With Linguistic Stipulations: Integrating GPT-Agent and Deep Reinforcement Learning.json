{"Title": "Real-Time Optimal Power Flow With Linguistic Stipulations: Integrating GPT-Agent and Deep Reinforcement Learning", "Doi": "10.1109/TPWRS.2023.3338961", "Authors": ["z. yan", "y. xu"], "Key Words": ["optimal power flow", "large language models", "qualitative objectives", "deep reinforcement learning", "generative pre-trained transformer (gpt)"], "Abstract": "practical operations of a power system need to comply with grid codes which are usually grounded in linguistic stipulations that may be hard to quantify in conventional optimal power flow  opf  models. in the lights of recent breakthrough in large language models  large language model  this letter proposes an opf model with linguistic stipulations and a solution method by integrating the generative pre trained transformer  gpt  based large language model agent in the primal dual deep reinforcement learning  drl  training loop. for the first time conventionally unquantifiable linguistic stipulations expressed in natural language can be directly modeled as the objectives and constraints in the opf problem. the gpt agent is used to interpret satisfactions of linguistic stipulations as rewards and constraints. the non differentiable rewards obtained by gpt agent are optimized through interactions with environments in the drl process. once sufficiently trained the drl agent can solve the opf model in real time. the proposed method is demonstrated on the ieee 118 bus system.", "Pub Date": "2024-02-23"}
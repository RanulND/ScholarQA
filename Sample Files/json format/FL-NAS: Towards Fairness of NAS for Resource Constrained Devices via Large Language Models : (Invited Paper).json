{"Title": "FL-NAS: Towards Fairness of NAS for Resource Constrained Devices via Large Language Models : (Invited Paper)", "Doi": "10.1109/ASP-DAC58780.2024.10473847", "Authors": ["r. qin", "y. hu", "z. yan", "j. xiong", "a. abbasi", "y. shi"], "Key Words": ["neural architecture search", "hardware efficiency", "large language model", "fairness"], "Abstract": "neural architecture search  nas  has become the de fecto tools in the industry in automating the design of deep neural networks for various applications especially those driven by mobile and edge devices with limited computing resources. the emerging large language models  llms  due to their prowess have also been incorporated into nas recently and show some promising results. this paper conducts further exploration in this direction by considering three important design metrics simultaneously i.e. model accuracy fairness and hardware deployment efficiency. we propose a novel llm based nas framework fl nas in this paper and show experimentally that fl nas can indeed find high performing dnns beating state of the art dnn models by orders of magnitude across almost all design considerations.", "Pub Date": "2024-03-25"}
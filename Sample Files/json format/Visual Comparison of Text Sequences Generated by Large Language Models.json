{"Title": "Visual Comparison of Text Sequences Generated by Large Language Models", "Doi": "10.1109/VDS60365.2023.00007", "Authors": ["r. sevastjanova", "s. vogelbacher", "a. spitz", "d. keim", "m. el-assady"], "Key Words": ["causal language models", "text generation", "prompt output comparison"], "Abstract": "causal language models have emerged as the leading technology for automating text generation tasks. although these models tend to produce outputs that resemble human writing they still suffer from quality issues  e.g. social biases . researchers typically use automatic analysis methods to evaluate the model limitations such as statistics on stereotypical words. since different types of issues are embedded in the model parameters the development of automated methods that capture all relevant aspects remains a challenge. to tackle this challenge we propose a visual analytics approach that supports the exploratory analysis of text sequences generated by causal language models. our approach enables users to specify starting prompts and effectively groups the resulting text sequences. to this end we leverage a unified ontology driven embedding space serving as a shared foundation for the thematic concepts present in the generated text sequences. visual summaries provide insights into various levels of granularity within the generated data. among others we propose a novel comparison visualization that slices the embedding space and represents the differences between two prompt outputs in a radial layout. we demonstrate the effectiveness of our approach through case studies showcasing its potential to reveal model biases and other quality issues.", "Pub Date": "2023-12-18"}
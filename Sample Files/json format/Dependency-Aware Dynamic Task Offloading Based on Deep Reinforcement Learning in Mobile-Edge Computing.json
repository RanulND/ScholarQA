{"Title": "Dependency-Aware Dynamic Task Offloading Based on Deep Reinforcement Learning in Mobile-Edge Computing", "Doi": "10.1109/TNSM.2023.3319294", "Authors": ["j. fang", "d. qu", "h. chen", "y. liu"], "Key Words": ["mobile edge computing", "task offloading", "optimization algorithm", "deep reinforcement learning"], "Abstract": "the rapid advancement of mobile edge computing  mec  networks has enabled the augmentation of the computational power of mobile devices  mds  by offloading computationally intensive tasks to resource rich edge nodes. this paper discusses the decision making process for task offloading and resource allocation among multiple mobile devices connected to a base station. the primary objective is to minimize the time taken to complete tasks while simultaneously reducing energy consumption on the device under a time varying wireless fading channel. this objective is formulated as an energy efficiency cost  eec  minimization problem which cannot be solved by conventional methods. to address this challenge we propose a dynamic offloading decision algorithm of dependent tasks  doda dt  that adjusts local task execution based on edge node status. the proposed algorithm facilitates fair competition among all devices for edge resources. additionally we use a deep reinforcement learning  drl  algorithm based on an actor critic learning structure to train the system to quickly identify near optimal solutions. numerical simulations demonstrate that the proposed algorithm effectively reduces the total cost of the task in comparison to previous algorithms.", "Pub Date": "2024-04-15"}
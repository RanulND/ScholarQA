{"Title": "Domain Adaptive Code Completion via Language Models and Decoupled Domain Databases", "Doi": "10.1109/ASE56229.2023.00076", "Authors": ["z. tang", "j. ge", "s. liu", "t. zhu", "t. xu", "l. huang", "b. luo"], "Key Words": ["domain adaptive code completion", "retrieval-augment language model"], "Abstract": "large language models  llms  have demonstrated remarkable performance in code completion. however due to the lack of domain specific knowledge they may not be optimal in completing code that requires intensive domain knowledge for example completing the library names. although there are several works that have confirmed the effectiveness of fine tuning techniques to adapt language models for code completion in specific domains. they are limited by the need for constant fine tuning of the model when the project is in constant iteration. to address this limitation in this paper we propose $k$ nm lm a retrieval augmented language model  r lm  that integrates domain knowledge into language models without fine tuning. different from previous techniques our approach is able to automatically adapt to different language models and domains. specifically it utilizes the in domain code to build the retrieval based database decoupled from lm and then combines it with lm through bayesian inference to complete the code. the extensive experiments on the completion of intra project and intra scenario have confirmed that $k$ nm lm brings about appreciable enhancements when compared to codegpt and unixcoder. a deep analysis of our tool including the responding speed storage usage specific type code completion and api invocation completion has confirmed that $k$ nm lm provides satisfactory performance which renders it highly appropriate for domain adaptive code completion. furthermore our approach operates without the requirement for direct access to the language model parameters. as a result it can seamlessly integrate with black box code completion models making it easy to integrate our approach as a plugin to further enhance the performance of these models.", "Pub Date": "2023-11-08"}
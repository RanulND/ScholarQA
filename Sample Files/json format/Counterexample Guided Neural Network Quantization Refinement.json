{"Title": "Counterexample Guided Neural Network Quantization Refinement", "Authors": ["j. b. p. matos", "e. b. de lima filho", "i. bessa", "e. manino", "x. song", "l. c. cordeiro"], "Pub Date": "2024-03-20", "Abstract": "deploying neural networks  nns  in low resource domains is challenging because of their high computing memory and power requirements. for this reason nns are often quantized before deployment but such an approach degrades their accuracy. thus we propose the counterexample guided neural network quantization refinement  ceg4n  framework which combines search based quantization and equivalence checking. the former minimizes computational requirements while the latter guarantees that the behavior of an nn does not change after quantization. we evaluate ceg4n on a diverse set of benchmarks including large and small nns. our technique successfully quantizes the networks in the chosen evaluation set while producing models with up to 163% better accuracy than state of the art techniques.", "Doi": "10.1109/TCAD.2023.3335313", "Key Words": ["equivalent quantization (eq)", "neural network equivalence (nne)", "neural network (nn) quantization"]}
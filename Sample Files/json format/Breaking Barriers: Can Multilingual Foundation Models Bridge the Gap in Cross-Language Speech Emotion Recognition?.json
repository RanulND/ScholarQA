{"Title": "Breaking Barriers: Can Multilingual Foundation Models Bridge the Gap in Cross-Language Speech Emotion Recognition?", "Doi": "10.1109/SNAMS60348.2023.10375468", "Authors": ["m. shoukat", "m. usama", "h. s. ali", "s. latif"], "Key Words": ["cross-language", "speech emotion recognition", "foundation models", "transformers", "multilingual data", "self-supervised learning"], "Abstract": "speech emotion recognition  ser  faces challenges in cross language scenarios due to differences in linguistic and cultural expression of emotions across languages. recently large multilingual foundation models pre trained on massive corpora have achieved performance on natural language understanding tasks by learning cross lingual representations. their ability to understand relationships between languages without direct translation opens up possibilities for more applicable multilingual models. in this paper we evaluate the capabilities of foundation models  wav2vec2 xlsr whisper and mms  to bridge the gap in cross language ser. specifically we analyse their performance on benchmark cross language ser datasets involving four languages for emotion classification. our experiments show that the foundation model outperforms cnn lstm baselines establishing their superiority in cross lingual transfer learning for emotion recognition. however self supervised pre training plays a key role and inductive biases alone are insufficient for high cross lingual generalisability. foundation models also demonstrate gains over baselines with limited target data and better performance on noisy data. our findings indicate that while foundation models hold promise pre training remains vital for handling linguistic variations across languages for ser.", "Pub Date": "2024-01-02"}
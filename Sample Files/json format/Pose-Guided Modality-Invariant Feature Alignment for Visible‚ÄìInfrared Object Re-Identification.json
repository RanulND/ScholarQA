{"Title": "Pose-Guided Modality-Invariant Feature Alignment for Visible\u201a\u00c4\u00ecInfrared Object Re-Identification", "Authors": ["m. liu", "y. sun", "x. wang", "y. bian", "z. zhang", "y. wang"], "Pub Date": "2024-04-15", "Abstract": "visible\u201a\u00e4\u00ecinfrared object reidentification  vi reid  is the task of identifying the same object across cameras with different modalities. it is more challenging than the common reid task since the complex intraclass interference and large modality divergence. existing works mainly tend to adopt the instance level or modality center level metric learning to extract the global features or rigid local features without considering modality alignment comprehensively leading to a limited capacity of modality invariant feature learning. in response to these challenges a new approach for vi reid called pose guided modality invariant feature alignment  pmfa  is proposed which can simultaneously eliminate the intraclass interference in each modality and bridge the gap between different modalities. specifically a pose guided feature enhancement  pfe  block is presented to enhance feature discrimination by introducing person key part features which can eliminate the intraclass interference effectively and guide the reid model to learn cross modality consistent features of the same person at the same time. in addition a modal feature alignment learning  mfal  method is proposed to address the substantial modality differences from two perspectives i.e. aligning feature distributions and hierarchical aggregation. the design not only narrows the modality gap from an explicit distribution discrepancy perspective but also comprehensively considers both intramodality and intermodality constraints. comprehensive experiments conducted on two challenging datasets demonstrate the superiority of the pmfa approach compared with the latest state of the art  sota  methods. particularly on the sysu mm01 dataset the pmfa approach can achieve 74.22% for rank 1 accuracy and 70.27% for map score respectively. the source code is available at  https //github.com syq2021/pmfa.", "Doi": "10.1109/TIM.2024.3384558", "Key Words": ["cross modality", "feature alignment", "object reidentification", "visible\u201a\u00e4\u00ecinfrared"]}
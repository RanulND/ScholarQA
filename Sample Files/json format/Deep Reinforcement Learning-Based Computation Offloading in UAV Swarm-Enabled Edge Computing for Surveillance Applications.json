{"Title": "Deep Reinforcement Learning-Based Computation Offloading in UAV Swarm-Enabled Edge Computing for Surveillance Applications", "Doi": "10.1109/ACCESS.2023.3292938", "Authors": ["s. m. a. huda", "s. moh"], "Key Words": ["aerial computing", "computation offloading", "deep reinforcement learning", "double deep q-learning", "mobile edge computing", "multi-agent reinforcement learning", "unmanned aerial vehicle"], "Abstract": "the rapid development of the internet of things and wireless communication has resulted in the emergence of many latency constrained and computation intensive applications such as surveillance virtual reality and disaster monitoring. to satisfy the computational demand and reduce the prolonged transmission delay to the cloud mobile edge computing  mec  has evolved as a potential candidate that can improve task completion efficiency in a reliable fashion. owing to its high mobile nature and ease of use as promising candidates unmanned aerial vehicles  uavs  can be incorporated with mec to support such computation intensive and latency critical applications. however determining the ideal offloading decision for the uav on basis of the task characteristics still remains a crucial challenge. in this paper we investigate a surveillance application scenario of a hierarchical uav swarm that includes an uav enabled mec with a team of uavs surveilling the area to be monitored. to determine the optimal offloading policy we propose a deep reinforcement learning based computation offloading  drlco  scheme using double deep q learning which minimizes the weighted sum cost by jointly considering task execution delay and energy consumption. a performance study shows that the proposed drlco technique significantly outperforms conventional schemes in terms of offloading cost energy consumption and task execution delay. the better convergence and effectiveness of the proposed method over conventional schemes are also demonstrated.", "Pub Date": "2023-07-11"}
{"Title": "A Survey of Text Representation and Embedding Techniques in NLP", "Doi": "10.1109/ACCESS.2023.3266377", "Authors": ["r. patil", "s. boit", "v. gudivada", "j. nandigam"], "Key Words": ["natural language processing", "embeddings", "text representation", "word vectors", "survey", "word embeddings", "literature review", "nlp", "language models"], "Abstract": "natural language processing  nlp  is a research field where a language in consideration is processed to understand its syntactic semantic and sentimental aspects. the advancement in the nlp area has helped solve problems in the domains such as neural machine translation name entity recognition sentiment analysis and chatbots to name a few. the topic of nlp broadly consists of two main parts  the representation of the input text  raw data  into numerical format  vectors or matrix  and the design of models for processing the numerical data. this paper focuses on the former part and surveys how the nlp field has evolved from rule based statistical to more context sensitive learned representations. for each embedding type we list their representation issues they addressed limitations and applications. this survey covers the history of text representations from the 1970s and onwards from regular expressions to the latest vector representations used to encode the raw text data. it demonstrates how the nlp field progressed from where it could comprehend just bits and pieces to all the significant aspects of the text over time.", "Pub Date": "2023-04-17"}
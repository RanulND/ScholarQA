{"Title": "Neural Authorship Attribution: Stylometric Analysis on Large Language Models", "Doi": "10.1109/CyberC58899.2023.00019", "Authors": ["t. kumarage", "h. liu"], "Key Words": ["neural authorship attribution", "large language models", "stylometric analysis"], "Abstract": "large language models  llms  such as gpt 4 palm and llama have significantly propelled the generation of ai crafted text. with rising concerns about their potential misuse there is a pressing need for ai generated text forensics. neural authorship attribution is a forensic effort seeking to trace aigenerated text back to its originating llm. the llm landscape can be divided into two primary categories  proprietary and open source. in this work we delve into these emerging categories of llms focusing on the nuances of neural authorship attribution. to enrich our understanding we carry out an empirical analysis of llm writing signatures highlighting the contrasts between proprietary and open source models and scrutinizing variations within each group. by integrating stylometric features across lexical syntactic and structural aspects of language we explore their potential to yield interpretable results and augment pre trained language model based classifiers utilized in neural authorship attribution. our findings based on a range of state of the art llms provide empirical insights into neural authorship attribution paving the way for future investigations aimed at mitigating the threats posed by ai generated misinformation.", "Pub Date": "2024-02-21"}
{"Title": "Neural Authorship Attribution: Stylometric Analysis on Large Language Models", "Doi": "10.1109/CyberC58899.2023.00019", "Authors": ["t. kumarage", "h. liu"], "Key Words": ["neural authorship attribution", "large language models", "stylometric analysis"], "Abstract": "large language models  large language model  such as gpt 4 palm and llama have significantly propelled the generation of artificial intelliegence crafted text. with rising concerns about their potential misuse there is a pressing need for artificial intelliegence generated text forensics. neural authorship attribution is a forensic effort seeking to trace aigenerated text back to its originating large language model. the large language model landscape can be divided into two primary categories  proprietary and open source. in this work we delve into these emerging categories of large language model focusing on the nuances of neural authorship attribution. to enrich our understanding we carry out an empirical analysis of large language model writing signatures highlighting the contrasts between proprietary and open source models and scrutinizing variations within each group. by integrating stylometric features across lexical syntactic and structural aspects of language we explore their potential to yield interpretable results and augment pre trained language model based classifiers utilized in neural authorship attribution. our findings based on a range of state of the art large language model provide empirical insights into neural authorship attribution paving the way for future investigations aimed at mitigating the threats posed by artificial intelliegence generated misinformation.", "Pub Date": "2024-02-21"}
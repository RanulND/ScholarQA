{"Title": "On Compressing Sequences for Self-Supervised Speech Models", "Doi": "10.1109/SLT54892.2023.10022991", "Authors": ["y. meng", "h. -j. chen", "j. shi", "s. watanabe", "p. garcia", "h. -y. lee", "h. tang"], "Key Words": ["self-supervised learning", "sequence length compression", "variable-length subsampling"], "Abstract": "compressing self supervised models has become increasingly necessary as self supervised models become larger. while previous approaches have primarily focused on compressing the model size shortening sequences is also effective in reducing the computational cost. in this work we study fixed length and variable length subsampling along the time axis in self supervised learning. we explore how individual downstream tasks are sensitive to input frame rates. subsampling while training self supervised models not only improves the overall performance on downstream tasks under certain frame rates but also brings significant speed up in inference. variable length subsampling performs particularly well under low frame rates. in addition if we have access to phonetic boundaries we find no degradation in performance for an average frame rate as low as 10 hz.", "Pub Date": "2023-01-27"}
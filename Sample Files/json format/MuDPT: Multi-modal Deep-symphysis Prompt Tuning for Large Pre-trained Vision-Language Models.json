{"Title": "MuDPT: Multi-modal Deep-symphysis Prompt Tuning for Large Pre-trained Vision-Language Models", "Doi": "10.1109/ICME55011.2023.00013", "Authors": ["y. miao", "s. li", "j. tang", "t. wang"], "Key Words": ["prompt tuning", "multi-modal", "prompt fusion", "few-shot learning"], "Abstract": "prompt tuning like coop has recently shown promising vision recognizing and transfer learning ability on various downstream tasks with the emergence of large pre trained vision language models like clip. however we identify that existing uni modal prompt tuning approaches may result in sub optimal performance since this uni modal design breaks the original alignment of textual and visual representations in the pre trained model. inspired by the nature of pre trained vision language models we aim to achieve completeness in prompt tuning and propose a novel approach called multi modal deep symphysis prompt tuning dubbed as mudpt which extends independent multi modal prompt tuning by additionally learning a model agnostic transformative network to allow deep hierarchical bi directional prompt fusion. we evaluate the effectiveness of mudpt on few shot vision recognition and out of domain generalization tasks. compared with the state of the art methods mudpt achieves better recognition and generalization ability with an apparent margin thanks to synergistic alignment of textual and visual representations. our code is available at  https //github.com mechrev0/mudpt.", "Pub Date": "2023-08-25"}
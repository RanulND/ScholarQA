{"Title": "Attention and DCT Based Global Context Modeling for Text-Independent Speaker Recognition", "Doi": "10.1109/TASLP.2023.3284521", "Authors": ["w. xia", "j. h. l. hansen"], "Key Words": ["speaker recognition", "speaker embedding", "attention", "global context modeling", "dct transformation"], "Abstract": "learning an effective speaker representation is crucial for achieving reliable performance in speaker verification tasks. speech signals are high dimensional long and variable length sequences containing diverse information at each time frequency  tf  location. the standard convolutional layer that operates on neighboring local regions often fails to capture the complex tf global information. our motivation is to alleviate these challenges by increasing the modeling capacity emphasizing significant information and suppressing possible redundancies. we aim to design a more robust and efficient speaker recognition system by incorporating the benefits of attention mechanisms and discrete cosine transform  dct  based signal processing techniques to effectively represent the global information in speech signals. to achieve this we propose a general global time frequency context modeling block for speaker modeling. first an attention based context model is introduced to capture the long range and non local relationship across different time frequency locations. second a 2d dct based context model is proposed to improve model efficiency and examine the benefits of signal modeling. a multi dct attention mechanism is presented to improve modeling power with alternate dct base forms. finally the global context information is used to recalibrate salient time frequency locations by computing the similarity between the global context and local features. this effectively improves the speaker verification performance compared to the standard resnet model and squeeze & excitation block by a large margin. our experimental results show that the proposed global context modeling method can efficiently improve the learned speaker representations by achieving channel wise and time frequency feature recalibration.", "Pub Date": "2023-07-19"}
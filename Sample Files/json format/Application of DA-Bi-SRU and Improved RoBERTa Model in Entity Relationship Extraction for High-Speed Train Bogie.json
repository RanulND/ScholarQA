{"Title": "Application of DA-Bi-SRU and Improved RoBERTa Model in Entity Relationship Extraction for High-Speed Train Bogie", "Doi": "10.1109/DSIT60026.2023.00023", "Authors": ["y. jiang", "z. zhang", "l. he", "t. gong", "j. du", "x. yin"], "Key Words": ["improved bert", "whole word masking", "bi-sru", "attention mechanism", "deep learning", "entity relationship extraction", "high-speed train bogie"], "Abstract": "due to the large number of professional terms and complex entity relationships in the field of high speed train  hst  bogie the accuracy of entity relationship extraction is low. in order to improve the efficiency and accuracy of entity relationship extraction in high speed train bogie domain we propose a novel entity relationship extraction model for the domain of high speed train  hst  bogie with the aim of improving the efficiency and accuracy of entity relationship extraction. the proposed model is based on roberta wwm  a robustly optimized bert pretraining approach with whole word masking  and da bi sru  double attention based bidirectional simple recurrent unit . to facilitate this we construct a new bogie relation extraction dataset comprising of 25000 statements collected from literature and professional annotations. the roberta wwm is employed to obtain dynamic word vectors from the input statements and optimized using the bogie dataset. subsequently a bi sru model based on dual attention mechanism is developed to capture bidirectional semantic information and contextual semantic linkage in a rapid manner. our experiments show that the roberta wwm da bi sru model outperforms bi lstm and rnn methods with a prediction accuracy of 88.53% and an f1 value of 86.60%. our proposed model thus demonstrates the potential to accurately extract entity relationships in the bogie knowledge graph of high speed trains simplifying the construction process.", "Pub Date": "2024-02-13"}
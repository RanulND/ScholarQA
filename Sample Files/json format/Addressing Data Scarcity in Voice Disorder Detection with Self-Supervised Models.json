{"Title": "Addressing Data Scarcity in Voice Disorder Detection with Self-Supervised Models", "Doi": "10.1109/ICASSP48485.2024.10446075", "Authors": ["r. gupta", "c. madill", "d. r. gunjawate", "d. d. nguyen", "c. t. jin"], "Key Words": ["voice disorder detection", "machine learning", "self-supervised models", "self-supervised latent features"], "Abstract": "machine learning  ml  has shown promising results in the field of voice disorder detection over the past decade. however the diversity of recording conditions audio content languages and the scarcity of examples for each of these combinations pose a challenge in building ml models that can reliably detect voice disorders. recent advancements in self supervised learning  ssl  offer hope by leveraging large datasets to pretrain models and extract audio features with high resilience for downstream tasks.in this paper we fairly exhaustively explore commonly used ssl model representations to assess their suitability for addressing the downstream task of voice disorder detection. using a combination of support vector machines  svm  and feedforward deep neural networks  dnn  we show  i  that the combination of vowels /a//i/ and /u/ perform better than individual vowels  ii  ssl based features generalize well to out of domain databases and iii  that while spectral features like mfcc perform equally well compared to ssl based features when trained and tested on the same database performances seems to deteriorate when training and testing across different databases.", "Pub Date": "2024-03-18"}
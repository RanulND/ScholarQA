{"Title": "Enhancing Large Language Models\u201a\u00c4\u00f4 Utility for Medical Question-Answering: A Patient Health Question Summarization Approach", "Doi": "10.1109/SITA60746.2023.10373720", "Authors": ["n. e. zekaoui", "s. yousfi", "m. mikram", "m. rhanoui"], "Key Words": ["question answering", "consumer health question summarization", "medical question understanding", "transformer-based models"], "Abstract": "large language models  large language model  offer tremendous potential for answering diverse questions and providing valuable insights. however to maximize their utility it is essential to formulate effective prompts or questions. this challenge is particularly pronounced when searching for health related information inundates the web with questions from consumers about their health. in fact patients with limited technical vocabulary and inadequate phrasing may struggle to submit questions that accurately convey their concerns resulting in a significantly higher occurrence of false positives in answer generation. to address this pressing issue we propose a solution for generating concise and understandable medical questions by summarizing consumer health questions  chqs . moreover our method leverages state of the art language models has shown effective results. specifically we fine tune a set of transformer based models including flan t5 on low resources using three different medical question summarization datasets. furthermore through ablation studies we demonstrate how generative configuration choices and instruction fine tuning can significantly impact the final results. our best english model achieves scores of 54.32% 38.08% and 51.98% in terms of rouge 1 rouge 2 and rouge l respectively outperforming exiting methods by 5.82 rouge-1 points and providing a potential means to craft good prompts.", "Pub Date": "2024-01-03"}
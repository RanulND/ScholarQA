{"Title": "Dynamic Edge Computation Offloading for Internet of Vehicles With Deep Reinforcement Learning", "Doi": "10.1109/TITS.2022.3178759", "Authors": ["l. yao", "x. xu", "m. bilal", "h. wang"], "Key Words": ["internet of vehicles", "deep reinforcement learning", "edge computing"], "Abstract": "recent developments in the internet of vehicles  iov  enabled the myriad emergence of a plethora of data intensive and latency sensitive vehicular applications posing significant difficulties to traditional cloud computing. vehicular edge computing  vec  as an emerging paradigm enables the vehicles to utilize the resources of the edge servers to reduce the data transfer burden and computing stress. although the utilization of vec is a favourable support for iov applications vehicle mobility and other factors further complicate the challenge of designing and implementing such systems leading to incremental delay and energy consumption. in recent times there have been attempts to integrate deep reinforcement learning  drl  approaches with iov based systems to facilitate real time decision making and prediction. we demonstrate the potential of such an approach in this paper. specifically the dynamic computation offloading problem is constructed as a markov decision process  mdp . then the twin delayed deep deterministic policy gradient  td3  algorithm is utilized to achieve the optimal offloading strategy. finally findings from the simulation demonstrate the potential of our proposed approach.", "Pub Date": "2023-11-01"}
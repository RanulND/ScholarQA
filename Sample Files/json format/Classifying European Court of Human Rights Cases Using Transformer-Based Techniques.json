{"Title": "Classifying European Court of Human Rights Cases Using Transformer-Based Techniques", "Doi": "10.1109/ACCESS.2023.3279034", "Authors": ["a. s. imran", "h. hodnefjeld", "z. kastrati", "n. fatima", "s. m. daudpota", "m. a. wani"], "Key Words": ["legal documents classification", "european court of human rights (echr) dataset", "natural language processing", "transformers", "bert", "bigbird", "electra", "xlnet", "legal-bert"], "Abstract": "in the field of text classification researchers have repeatedly shown the value of transformer based models such as bidirectional encoder representation from transformers  bert  and its variants. nonetheless these models are expensive in terms of memory and computational power but have not been utilized to classify long documents of several domains. in addition transformer models are also often pre trained on generalized languages making them less effective in language specific domains such as legal documents. in the natural language processing  nlp  domain there is a growing interest in creating newer models that can handle more complex input sequences and domain specific languages. keeping the power of nlp in mind this study proposes a legal documentation classifier that classifies the legal document by using the sliding window approach to increase the maximum sequence length of the model. we used the echr  european court of human rights  publicly available dataset which to a large extent is imbalanced. therefore to balance the dataset we have scrapped the case articles from the web and extracted the data. then we employed conventional machine learning techniques such as svm dt nb adaboost and transformer based neural networks models including bert legal bert roberta bigbird electra and xlnet for the classification task. the experimental findings show that roberta outperformed all the mentioned bert versions by obtaining precision recall and f1 score of 89.1% 86.2% and 86.7% respectively. while from conventional machine learning techniques adaboost outclasses svm dt and nb by achieving scores of 81.9% 81.5% and 81.7% for precision recall and f1 score respectively.", "Pub Date": "2023-06-08"}
{"Title": "Tibetan Punctuation is All You Need in Pretrained Language Model", "Doi": "10.1109/IMSE61332.2023.00041", "Authors": ["m. zhou", "z. daiqing", "n. qun", "z. nima", "t. nyima"], "Key Words": ["tibetan", "punctuation", "probability substitution algorithm", "tncc", "adapter", "cino"], "Abstract": "the article explores the significance of tibetan punctuation marks in tibetan natural language processing and investigates the use of a probability substitution algorithm in combination with the cino model to improve the handling of tibetan text data. in the tncc task we achieved an f1 score of 73.3% on the test set with faster convergence. existing large scale models in the tibetan language domain primarily rely on the tncc dataset which tokenizes text into syllables using spaces. however this differs from the common syllable separators and used in modern tibetan which may affect the testing accuracy of large models. to address this issue we propose two solutions  firstly employing a probability substitution algorithm to replace spaces with and   secondly randomly extracting a six class dataset from the dataset constructed by the utibetnlp team at the university of tibet which overlaps with the tncc categories. we achieved excellent results by using adapter lightweight fine tuning on the cino large v2 model. the publicly available address for the utibetnlp news 6 dataset is  https //github.com utibetnlp/prosubcino.", "Pub Date": "2024-04-02"}
{"Title": "Refactoring Programs Using Large Language Models with Few-Shot Examples", "Doi": "10.1109/APSEC60848.2023.00025", "Authors": ["a. shirafuji", "y. oda", "j. suzuki", "m. morishita", "y. watanobe"], "Key Words": ["code refactoring", "large language models", "few-shot prompting", "software complexity", "programming education"], "Abstract": "a less complex and more straightforward program is a crucial factor that enhances its maintainability and makes writing secure and bug free programs easier. however due to its heavy workload and the risks of breaking the working programs programmers are reluctant to do code refactoring and thus it also causes the loss of potential learning experiences. to mitigate this we demonstrate the application of using a large language model  large language model  gpt 3.5 to suggest less complex versions of the user written python program aiming to encourage users to learn how to write better programs. we propose a method to leverage the prompting with few shot examples of the large language model by selecting the best suited code refactoring examples for each target programming problem based on the prior evaluation of prompting with the one shot example. the quantitative evaluation shows that 95.68% of programs can be refactored by generating 10 candidates each resulting in a 17.35% reduction in the average cyclomatic complexity and a 25.84% decrease in the average number of lines after filtering only generated programs that are semantically correct. further more the qualitative evaluation shows outstanding capability in code formatting while unnecessary behaviors such as deleting or translating comments are also observed.", "Pub Date": "2024-04-02"}
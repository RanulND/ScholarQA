{"Title": "Better Patching Using LLM Prompting, via Self-Consistency", "Doi": "10.1109/ASE56229.2023.00065", "Authors": ["t. ahmed", "p. devanbu"], "Key Words": ["llms", "self-consistency", "program repair"], "Abstract": "large language models  llms  can be induced to solve non trivial problems with \u201a\u00e4\u00fafew shot\u201a\u00e4\u00f9 prompts including illustrative problem solution examples. now if the few shots also include \u201a\u00e4\u00fachain of thought\u201a\u00e4\u00f9  $\\mathcal{c}ot$  explanations which are of the form problem explanation solution llms will generate a \u201a\u00e4\u00faexplained\u201a\u00e4\u00f9 solution and perform even better. recently an exciting substantially better technique self consistency   $\\mathcal{s} c$  has emerged based on the intuition that there are many plausible explanations for the right solution  when the llm is sampled repeatedly to generate a pool of explanation solution pairs for a given problem the most frequently occurring solutions in the pool  ignoring the explanations  tend to be even more likely to be correct  unfortunately the use of this highly performant $\\mathcal{s} c$  or even $\\mathcal{c}ot$  approach in software engineering settings is hampered by the lack of explanations  most software datasets lack explanations. in this paper we describe an application of the $\\mathcal{s} c$ approach to program repair using the commit log on the fix as the explanation only in the illustrative few shots. we achieve state of the art results beating previous approaches to prompting based program repair on the modit dataset  we also find evidence suggesting that the correct commit messages are helping the llm learn to produce better patches.", "Pub Date": "2023-11-08"}
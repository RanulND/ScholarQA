{"Title": "Rewriting Conversational Utterances with Instructed Large Language Models", "Doi": "10.1109/WI-IAT59888.2023.00014", "Authors": ["e. galimzhanova", "c. i. muntean", "f. m. nardini", "r. perego", "g. rocchietti"], "Key Words": ["conversational systems", "query rewriting", "llms", "chatgpt", "information retrieval"], "Abstract": "many recent studies have shown the ability of large language models  llms  to achieve state of the art performance on many nlp tasks such as question answering text summarization coding and translation. in some cases the results provided by llms are on par with those of human experts. these models' most disruptive innovation is their ability to perform tasks via zero shot or few shot prompting. this capability has been successfully exploited to train instructed llms where reinforcement learning with human feedback is used to guide the model to follow the user requests directly. in this paper we investigate the ability of instructed llms to improve conversational search effectiveness by rewriting user questions in a conversational setting. we study which prompts provide the most informative rewritten utterances that lead to the best retrieval performance. reproducible experiments are conducted on publicly available trec cast datasets. the results show that rewriting conversational utterances with instructed llms achieves significant improvements of up to 25.2% in mrr 31.7% in precision@1 27% in ndcg@3 and 11.5% in recall@500 over state of the art techniques.", "Pub Date": "2023-12-19"}
{"Title": "Digital Twin Enabled Task Offloading for IoVs: A Learning-Based Approach", "Doi": "10.1109/TNSE.2023.3303461", "Authors": ["j. zheng", "y. zhang", "t. h. luan", "p. k. mu", "g. li", "m. dong", "y. wu"], "Key Words": ["task offloading", "digital twins", "reinforcement learning", "internet of vehicles"], "Abstract": "this article explores the optimal offloading strategy in the internet of vehicles  iovs  which is challenged by three issues. first the resources of edge servers are shared by multiple vehicles leading to random changes over time. second as a vehicle would drive across consecutive edge servers the offloading strategy needs to consider the overall edge resources along the trip. third at each vehicle the computing tasks arrive continuously when driving. this dictates the offloading strategy to consider not only the current status but also the futuristic computing tasks. to tackle these issues we propose a digital twin  dt  network framework. a dt network maintains dts in the cyber space to synchronize the real world activities of vehicles. therefore task offloading decisions can be benefited by combining both the global information aggregated from neighbor twins and historical information uploaded by vehicles. with comprehensive information the optimal offloading strategy can be determined. we characterize the offloading problem as a markov decision process  mdp  and develop an a3c based decision making algorithm which can learn optimal offloading actions that minimize the long term system costs. extensive experiments demonstrate the performance of our proposal in terms of fast convergence and low system costs when compared with other approaches.", "Pub Date": "2024-01-05"}
{"Title": "CodaMosa: Escaping Coverage Plateaus in Test Generation with Pre-trained Large Language Models", "Doi": "10.1109/ICSE48619.2023.00085", "Authors": ["c. lemieux", "j. p. inala", "s. k. lahiri", "s. sen"], "Key Words": ["search based software testing", "codex", "test suite generation", "python", "large language model", "automated testing"], "Abstract": "search based software testing  sbst  generates high coverage test cases for programs under test with a combination of test case generation and mutation. sbst performance relies on there being a reasonable probability of generating test cases that exercise the core logic of the program under test. given such test cases sbst can then explore the space around them to exercise various parts of the program. this paper explores whether large language models  large language model  of code such as openai codex can be used to help sbst exploration. our proposed algorithm codamosa conducts sbst until its coverage improvements stall then asks codex to provide example test cases for under covered functions. these examples help sbst redirect its search to more useful areas of the search space. on an evaluation over 486 benchmarks codamosa achieves statistically significantly higher coverage on many more benchmarks  173 and 279  than it reduces coverage on  10 and 4  compared to sbst and large language model only baselines.", "Pub Date": "2023-07-14"}
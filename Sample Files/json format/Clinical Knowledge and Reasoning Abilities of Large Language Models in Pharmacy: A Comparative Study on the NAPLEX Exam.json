{"Title": "Clinical Knowledge and Reasoning Abilities of Large Language Models in Pharmacy: A Comparative Study on the NAPLEX Exam", "Doi": "10.1109/SNAMS60348.2023.10375395", "Authors": ["m. angel", "a. patel", "a. alachkar", "p. baldi"], "Key Words": ["artificial intelligence", "llm", "chatgpt", "bard", "healthcare", "pharmacy"], "Abstract": "this study aims to evaluate the capabilities and limitations of three large language models  llms  gpt 3 gpt 4 and bard in the field of pharmacy by assessing their reasoning abilities on a sample of the north american pharmacist licensure examination  naplex . additionally we explore the potential impacts of llms on pharmacy education and practice. to evaluate the llms we utilized the sample of the naplex exam comprising 137 multiple choice questions. these questions were presented to gpt 3 gpt 4 and bard through their respective user interfaces and the answers generated by the llms were subsequently compared with the answer key. the results reveal a notable disparity in the performance of the llms. gpt-4 emerged as the top performer accurately answering 78.8% of the questions. this marked a substantial 11% and 27.7% improvement over bard and gpt 3 respectively. however when considering questions that required multiple selections the performance of each llm decreased significantly. gpt 4 gpt 3 and bard could only correctly respond to 53.6% 13.9% and 21.4% of such questions respectively. among the three llms evaluated gpt-4 was the only model capable of passing the naplex exam. nevertheless given the continuous evolution of llms it is reasonable to anticipate that future models will effortlessly excel in this context. this highlights the significant potential of llms to influence the field of pharmacy. hence we must evaluate both the positive and negative implications associated with the integration of llms in pharmacy education and practice.", "Pub Date": "2024-01-02"}
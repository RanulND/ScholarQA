{"Title": "Service Management and Energy Scheduling Toward Low-Carbon Edge Computing", "Doi": "10.1109/TSUSC.2022.3210564", "Authors": ["l. gu", "w. zhang", "z. wang", "d. zeng", "h. jin"], "Key Words": ["low-carbon edge computing", "deep reinforcement learning", "service management"], "Abstract": "edge computing has become an alternative low latency provision of cloud computing thanks to its close proximity to the users and the geo distribution nature of edge servers enables the utilization green energy from the environment on site. to pursue the goal of low carbon edge computing it is desirable to minimize the operational expenditure by scheduling the computing resource and green energy according to the spatially and temporally varying user demands. in this article inspired by the successful application of deep reinforcement learning  drl  in diverse domains we propose a drl based edge computing management strategy which continuously explores the states and adaptively makes decisions on service management and energy scheduling towards long term cost minimization. different from model based solutions our proposal is a model free method without any assumption on statistical knowledge as a priori and therefore is practical in implementation. to speedup the agent training procedure we further design a prioritized replay memory by utilizing the model based solution as a guideline to set the transition priority. extensive experiment results based on real world traces validate that our proposed drl based strategy can make considerably progress compared to the one shot greedy strategy and it can learn the system dynamically to manage the edge computing services at runtime.", "Pub Date": "2023-03-07"}
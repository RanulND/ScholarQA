{"Title": "Data Augmentation for Sentiment Analysis Enhancement: A Comparative Study", "Doi": "10.1109/ICCI61671.2024.10485144", "Authors": ["f. yasser", "s. hatem", "l. ayman", "l. mohamed", "a. mohammed"], "Key Words": ["data augmentation", "large language models", "comparative study", "deep neural networks"], "Abstract": "for many years researchers in the field of natural language processing have been exploring sentiment analysis a method for understanding human feelings and thoughts expressed in text. sentiment analysis works by first analyzing the sentiment of individual words or phrases using methods like dictionaries machine learning or natural language processing. in machine learning however the reliance on training data quality and quantity poses challenges including data scarcity and imbalanced label distribution. one possible way to increase the distribution of textual data is utilizing data augmentation methods in which the train data samples are artificially transformed to another data with similar context. one effective approach to generating a more extensive and varied textual samples involves utilizing the capabilities of large language models. thus this paper introduces a comparative study on evaluating the impact of various augmentation methods namely random deletion synonym replacement gpt3.5 generation and character swapping. we compare the performance across six deep learning models namely cnn lstm bi lstm bert tcn ensemble cnn bidirectional gru and deep neural network. the experimental results reveal that bert exhibits significant accuracy improvements across different augmentation methods showcasing gains of 14% in random deletion 12.9% in synonym replacement and 6.5% in character swapping.", "Pub Date": "2024-04-02"}
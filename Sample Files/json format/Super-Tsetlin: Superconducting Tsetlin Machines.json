{"Title": "Super-Tsetlin: Superconducting Tsetlin Machines", "Authors": ["r. cheng", "d. vasudevan", "c. kirst"], "Pub Date": "2024-04-12", "Abstract": "the recently proposed tsetlin machine  tm  is a low complexity and versatile machine learning architecture that learns a collection of propositional clauses to describe or classify data. each clause is constructed from a set of tsetlin automata  tas  which are used to update the model during learning. tms have been widely used including image analysis dimension reduction and intrusion detection and recommendation systems. tms provide interpretable results outperforming state of the art machine learning approaches on various tasks. existing hardware implementations of tms are mainly based on field programmable gate arrays  fpgas  and cmos accelerator integrated circuit  ic  modules. these hardware solutions show high power efficiencies and pattern recognition accuracies compared to traditional machine learning algorithms. in this work we explore the use of superconducting rapid single flux quantum  rsfq  technology to implement tms which would benefit from the ultra low power consumption and high processing speed of superconducting technology. we designed circuits for tas propositional clauses and the learning algorithm based on rsfq circuits. to demonstrate the hardware functionality in simulations we train the system to learn the noisy xor problem. we have also modeled larger tms with more complex applications such as image analysis. we estimate that the dynamic power dissipation is less than 0.5 mw for a tm with eight clauses and four tas per clause and processing speeds up to 10 ghz using mit ll sfq5ee process with a critical current density of 100 $\\mu$a/$\\mu$m$^{{\\text{2}}}$. these results show rsfq as a potential candidate for implementing tsetlin machine based massively parallel architectures.", "Doi": "10.1109/TASC.2024.3375275", "Key Words": ["machine learning", "rapid single-flux quantum (rsfq)", "tsetlin machines (tms)"]}
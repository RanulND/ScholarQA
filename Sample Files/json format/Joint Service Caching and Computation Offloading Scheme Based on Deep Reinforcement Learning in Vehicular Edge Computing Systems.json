{"Title": "Joint Service Caching and Computation Offloading Scheme Based on Deep Reinforcement Learning in Vehicular Edge Computing Systems", "Doi": "10.1109/TVT.2023.3234336", "Authors": ["z. xue", "c. liu", "c. liao", "g. han", "z. sheng"], "Key Words": ["vehicular edge computing", "service caching", "computation offloading", "deep reinforcement learning"], "Abstract": "vehicular edge computing  vec  is a new computing paradigm that enhances vehicular performance by introducing both computation offloading and service caching to resource constrained vehicles and ubiquitous edge servers. recent developments of autonomous vehicles enable a variety of applications that demand high computing resources and low latency such as automatic driving auto navigation etc. however the highly dynamic topology of vehicular networks and limited caching space at resource constrained edge servers calls for intelligent design of caching placement and computation offloading. meanwhile service caching decisions are highly correlated to the computation offloading decisions which pose a great challenge to effectively design service caching and computation offloading strategies. in this paper we investigate a joint optimization problem by integrating service caching and computation offloading in a general vec scenario with time varying task requests. to minimize the average task processing delay we formulate the problem using long term mixed integer non linear programming  minlp  and propose an algorithm based on deep reinforcement learning to obtain a suboptimal solution with low computation complexity. the simulation results demonstrate that our proposed scheme exhibits an effective performance improvement in task processing delay compared with other representative benchmark methods.", "Pub Date": "2023-05-15"}
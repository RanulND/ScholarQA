{"Title": "Deep Reinforcement Learning for Time-Energy Tradeoff Online Offloading in MEC-Enabled Industrial Internet of Things", "Doi": "10.1109/TNSE.2023.3263169", "Authors": ["x. jiao", "h. ou", "s. chen", "s. guo", "y. qu", "c. xiang", "j. shang"], "Key Words": ["deep reinforcement learning", "industrial internet of things", "mobile edge computing", "online offloading", "time-energy tradeoff"], "Abstract": "mobile edge computing  mec  has recently emerged as a promising technology to boost the integration ability of sensing transmission and computation in industrial internet of things  iiot . this paper investigates an mec enabled iiot system where multiple industrial devices may offload computation intensive tasks to an edge server through wireless communication. we focus on the online offloading problem to optimize the tradeoff of the task accomplishing time and energy consumption. time varying wireless channels random targeted task data sizes and dynamically changing residual energy as well as adaptively adjusted tradeoff weights make this problem highly challenging. conventional optimization methods may lead to inefficient or even infeasible solutions. to efficiently tackle this problem we leverage the deep reinforcement learning  drl  technology to propose a time energy tradeoff online offloading algorithm called teto. in teto the online offloading decision policies are empirically learned via a well designed drl framework. teto algorithm incorporates a stochastic strategy the crossover and mutation technology and a novel feasible suboptimal offloading method to expand the offloading action search space with the provable feasibility guarantee. extensive experimental results based on a real world dataset show that our teto algorithm performs better than existing baseline algorithms and obtains near optimal performance with low cpu execution latency.", "Pub Date": "2023-10-24"}
{"Title": "Language-Guided Music Recommendation for Video via Prompt Analogies", "Doi": "10.1109/CVPR52729.2023.01420", "Authors": ["d. mckee", "j. salamon", "j. sivic", "b. russell"], "Key Words": ["multi-modal learning"], "Abstract": "we propose a method to recommend music for an input video while allowing a user to guide music selection with free form natural language. a key challenge of this problem setting is that existing music video datasets provide the needed  video music  training pairs but lack text descriptions of the music. this work addresses this challenge with the following three contributions. first we propose a text synthesis approach that relies on an analogy based prompting procedure to generate natural language music descriptions from a large scale language model  bloom 176b  given pre trained music tagger outputs and a small number of human text descriptions. second we use these synthesized music descriptions to train a new trimodal model which fuses text and video input representations to query music samples. for training we introduce a text dropout regularization mechanism which we show is critical to model performance. our model design allows for the re trieved music audio to agree with the two input modalities by matching visual style depicted in the video and musical genre mood or instrumentation described in the natural language query. third to evaluate our approach we collect a testing dataset for our problem by annotating a subset of 4k clips from the yt8m music video dataset with natural language music descriptions which we make publicly available. we show that our approach can match or exceed the performance of prior methods on video to music retrieval while significantly improving retrieval accuracy when using text guidance.", "Pub Date": "2023-08-22"}
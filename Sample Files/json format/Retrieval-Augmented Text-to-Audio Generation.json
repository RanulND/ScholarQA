{"Title": "Retrieval-Augmented Text-to-Audio Generation", "Doi": "10.1109/ICASSP48485.2024.10447898", "Authors": ["y. yuan", "h. liu", "x. liu", "q. huang", "m. d. plumbley", "w. wang"], "Key Words": ["audio generation", "retrieval-information", "diffusion model", "deep learning", "long tail problem"], "Abstract": "despite recent progress in text to audio  tta  generation we show that the state of the art models such as audioldm trained on datasets with an imbalanced class distribution such as audiocaps are biased in their generation performance. specifically they excel in generating common audio classes while underperforming in the rare ones thus degrading the overall generation performance. we refer to this problem as long tailed text to audio generation. to address this issue we propose a simple retrieval augmented approach for tta models. specifically given an input text prompt we first leverage a contrastive language audio pretraining  clap  model to retrieve relevant text audio pairs. the features of the retrieved audio text data are then used as additional conditions to guide the learning of tta models. we enhance audioldm with our proposed approach and denote the resulting augmented system as re audioldm. on the audiocaps dataset re audioldm achieves a state of the art frechet audio distance  fad  of 1.37 outperforming the existing approaches by a large margin. furthermore we show that re audioldm can generate realistic audio for complex scenes rare audio classes and even unseen audio types indicating its potential in tta tasks.", "Pub Date": "2024-03-18"}
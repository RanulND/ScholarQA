{"Title": "Scenario-Based AI Benchmark Evaluation of Distributed Cloud/Edge Computing Systems", "Doi": "10.1109/TC.2022.3176803", "Authors": ["t. hao", "k. hwang", "j. zhan", "y. li", "y. cao"], "Key Words": ["computer benchmarks", "cloud/edge computing", "machine learning", "and artificial intelligence"], "Abstract": "distributed cloud edge  dce  platform has become popular in recent years. this paper proposes a new artificial intelliegence benchmark suite for assessing the performance of dce platforms in machine learning  ml  and cognitive science applications. the benchmark suite is custom designed to satisfy scenario based performance requirements namely the model training time inference speed model accuracy job response time quality of service and system reliability. these metrics are substantiated by intensive experiments with real life artificial intelliegence workloads. our work is specially tailored for supporting massive artificial intelliegence multitasking across distributed resources in the networking environment. our benchmark experiments were conducted on an artificial intelliegence oriented airs cloud built at the chinese university of hong kong shenzhen. we have tested a large number of ml dl programs to narrow down the inclusion of ten representative artificial intelliegence kernel codes in the benchmark suite. our benchmark results reveal the advantages of using the dce systems cost effectively in smart cities healthcare community surveillance and transportation services. our technical contributions are in the airs cloud architecture benchmark design testing and distributed artificial intelliegence computing requirements. our work will benefit computer system designers and artificial intelliegence application developers on clouds edge and mobile devices that are supported by 5g mobile networks and aiot resources.", "Pub Date": "2023-02-09"}
{"Title": "Extractive Question Answering for Kazakh Language", "Doi": "10.1109/SIST58284.2023.10223508", "Authors": ["m. shymbayev", "y. alimzhanov"], "Key Words": ["natural language processing", "question answering", "low resource languages", "large language models"], "Abstract": "this article provides research and development of an extractive question answering system based on the bert like model for the kazakh language. developing an extractive question answering system requires large training datasets   tens of thousands of annotated question answer pairs. such datasets are not available in the majority of languages including kazakh. to address this issue the kazakh question answering dataset  kazqa  is introduced which is based on the stanford question answering dataset  squad  and generated through machine translation using the google cloud translation api. different large pretrained contextual language models are used as the baseline models   albert and multilingual bert and are compared with the newly trained monolingual kazakh model kazbert. the results demonstrate that the proposed approach can effectively generate question answering systems in low resourced kazakh language.", "Pub Date": "2023-08-28"}
{"Title": "ChatGPT vs. Human Annotators: A Comprehensive Analysis of ChatGPT for Text Annotation", "Doi": "10.1109/ICMLA58977.2023.00089", "Authors": ["m. aldeen", "j. luo", "a. lian", "v. zheng", "a. hong", "p. yetukuri", "l. cheng"], "Key Words": ["chaptgpt", "data annotation", "large language models"], "Abstract": "in recent years the field of natural language processing  nlp  has witnessed a groundbreaking transformation with the emergence of large language models  llms . chatgpt stands out as an example among these llm models captivating considerable public interest due to its impressive language generation capabilities. researchers have been exploring the potential of using chatgpt for data annotation tasks aiming to discover more timesaving and cost effective approaches. in this paper we present a comprehensive evaluation of chatgpt data annotation capabilities across ten diverse datasets covering various subject areas and varied number of classes. to ensure the quality of our evaluation we leveraged datasets that were previously annotated by human experts providing a reliable benchmark for comparison. through rigorous experimentation we assessed the impact of different prompt strategies and model configurations on the annotation performance. our findings emphasize the capability of chatgpt in handling most data annotation tasks achieving average accuracy of 78.2% across various tasks. the banking queries dataset stands out with an impressive 95.9% accuracy while emotions classification presents challenges yielding an accuracy of 57.5%. our evaluation also highlights the impact of prompt strategies on annotation performance and reveals significant performance differences between gpt models with \u201a\u00e4\u00fagpt 4\u201a\u00e4\u00f9 achieving higher accuracy 79.2% on average compared to \u201a\u00e4\u00fagpt 3.5\u201a\u00e4\u00f9 of 74.6%. our research provides valuable insights into the capabilities and limitations of chatgpt in automating data annotation tasks.", "Pub Date": "2024-03-19"}
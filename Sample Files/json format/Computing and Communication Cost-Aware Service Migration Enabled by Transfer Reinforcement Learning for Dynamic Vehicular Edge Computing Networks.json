{"Title": "Computing and Communication Cost-Aware Service Migration Enabled by Transfer Reinforcement Learning for Dynamic Vehicular Edge Computing Networks", "Doi": "10.1109/TMC.2022.3225239", "Authors": ["y. peng", "x. tang", "y. zhou", "j. li", "y. qi", "l. liu", "h. lin"], "Key Words": ["vehicular edge computing", "service migration", "computing cost", "services\u201a\u00e4\u00f4 satisfaction degree", "fast transfer reinforcement learning"], "Abstract": "due to the high mobility of vehicles service migration is inevitable in vehicular edge computing  vec  networks. frequent service migrations incur prohibitive migration cost including the computing cost  e.g. increased computing delay  and communication cost  e.g. occupied backhaul bandwidth . yet existing service migration schemes are usually designed without considering the impact of the computing cost. this paper considers the impact of computing and communication cost jointly and proposes a computing and communication cost aware service migration scheme for vec networks  i.e. ca migration . taking the service delay as a qos metric for vec networks this paper formulates a migration optimization problem aiming to maximize the services\u201a\u00e4\u00f4 satisfaction degree of delay  i.e. the probability that the service delay is smaller than the service delay requirement  where both the communication cost and computing cost affect the services\u201a\u00e4\u00f4 satisfaction degree. since the optimization problem is a constrained non linear integer programming problem it is difficult to solve. moreover the vec networks are highly dynamic. thus a fast transfer reinforcement learning  fast trl  method combining transfer learning and reinforcement learning is proposed to provide an adaptive service migration scheme in dynamic vec networks. simulation results show that compared with existing schemes the proposed ca migration scheme can increase the satisfaction degree by up to 30% and needs 25% less training time to obtain the optimal service migration policy.", "Pub Date": "2023-12-05"}
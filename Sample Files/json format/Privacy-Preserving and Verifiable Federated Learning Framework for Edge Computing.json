{"Title": "Privacy-Preserving and Verifiable Federated Learning Framework for Edge Computing", "Doi": "10.1109/TIFS.2022.3227435", "Authors": ["h. zhou", "g. yang", "y. huang", "h. dai", "y. xiang"], "Key Words": ["federated learning", "differential privacy", "convergence performance", "verification", "edge computing"], "Abstract": "in federated learning  fl  each client collaboratively trains the global model through the cloud server  cs  without sharing its original dataset in edge computing. however cs can analyze and forge the uploaded parameters and infer the privacy of clients which calls for the necessity of verifying the integrity and protecting the privacy for aggregation. although there are some works to ensure the verifiability of aggregation results there is still a lack of work on analyzing the relationship between verification and dropout rate for edge computing. in this work we propose privacy preserving and verifiable federated learning  pvfl  with low communication and computation overhead for verification. we theoretically demonstrate that pvfl has three properties  1  the communication overhead for verification is independent of the dropouts and the dimension of the parameter vector  2  the computation overhead for verification is independent of the dropouts  3  the value of the loss function is negatively correlated with the number of dropouts. experimental results demonstrate the correctness of our theoretical results and practical performance with a high dropout rate thereby facilitating the design of privacy preserving and verifiable fl algorithms for edge computing with a high dimension of parameter vectors and a high dropout rate.", "Pub Date": "2022-12-16"}
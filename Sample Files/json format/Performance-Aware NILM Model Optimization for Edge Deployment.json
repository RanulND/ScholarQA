{"Title": "Performance-Aware NILM Model Optimization for Edge Deployment", "Doi": "10.1109/TGCN.2023.3244278", "Authors": ["s. sykiotis", "s. athanasoulias", "m. kaselimi", "a. doulamis", "n. doulamis", "l. stankovic", "v. stankovic"], "Key Words": ["edge inference", "non-intrusive load monitoring", "quantization", "pruning", "optimization", "resource management", "green computing"], "Abstract": "non intrusive load monitoring  nilm  describes the extraction of the individual consumption pattern of a domestic appliance from the aggregated household consumption. nowadays the nilm research focus is shifted towards practical nilm applications such as edge deployment to accelerate the transition towards a greener energy future. nilm applications at the edge eliminate privacy concerns and data transmission related problems. however edge resource restrictions pose additional challenges to nilm. nilm approaches are usually not designed to run on edge devices with limited computational capacity and therefore model optimization is required for better resource management. recent works have started investigating nilm model optimization but they utilize compression approaches arbitrarily without considering the trade off between model performance and computational cost. in this work we present a nilm model optimization framework for edge deployment. the proposed edge optimization engine optimizes a nilm model for edge deployment depending on the edge device\u201a\u00e4\u00f4s limitations and includes a novel performance aware algorithm to reduce the model\u201a\u00e4\u00f4s computational complexity. we validate our methodology on three edge application scenarios for four domestic appliances and four model architectures. experimental results demonstrate that the proposed optimization approach can lead up to a 36.3% average reduction of model computational complexity and a 75% reduction of storage requirements.", "Pub Date": "2023-08-18"}
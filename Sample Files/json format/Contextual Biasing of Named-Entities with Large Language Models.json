{"Title": "Contextual Biasing of Named-Entities with Large Language Models", "Doi": "10.1109/ICASSP48485.2024.10445918", "Authors": ["c. sun", "z. ahmed", "y. ma", "z. liu", "l. kabela", "y. pang", "o. kalinli"], "Key Words": ["contextual biasing", "large language models", "multi-task training", "dynamic prompting"], "Abstract": "we explore contextual biasing with large language models  llms  to enhance automatic speech recognition  asr  in second pass rescoring. our approach introduces the utilization of prompts for llms during rescoring without the need for fine tuning. these prompts incorporate a biasing list and a set of few shot examples serving as supplementary sources of information when evaluating the hypothesis score. furthermore we introduce multi task training for llms to predict entity class and the subsequent token. to address sequence length constraints and improve the efficiency of contextual biasing we propose dynamic prompting based on class tag predictions. through dynamic prompting we leverage the class tag predictions to identify the most probable entity class and subsequently utilize entities within this class as biasing context for the next token prediction. we evaluate the performance of proposed methods in terms of word error rate  wer  on an internal entity heavy and the slue voxpopuli datasets. our results show significant improvements  biasing lists and few shot examples achieved a relative improvement of 17.8% and 9.6% while multitask training and dynamic prompting achieved 20.0% and 11.3% relative wer improvement respectively.", "Pub Date": "2024-03-18"}
{"Title": "A lightweight biomedical named entity recognition with pre-trained model", "Doi": "10.1109/ICDSCA59871.2023.10392374", "Authors": ["y. gou", "c. jie"], "Key Words": ["transformer", "bioner", "bert", "bilstm"], "Abstract": "biomedical named entity recognition  bioner  is a specialized subfield of named entity recognition  ner  that focuses on identifying and classifying named entities in biomedical and clinical texts. the goal of bioner is to extract essential information such as genes proteins diseases drugs et al. from scientific literature electronic health records  ehrs  biomedical databases and other biomedical text sources. the recognition and classification of these entities are crucial for various biomedical and healthcare related tasks including information retrieval data integration knowledge extraction and drug discovery. traditional bioner methods typically involve rule based approaches or machine learning algorithms et al. these methods have been widely used before the advent of deep learning and transformer based models. bidirectional encoder representations from transformers  bert  is a groundbreaking transformer based language model. it has revolutionized various natural language processing  nlp  tasks by capturing contextual information and obtain optimal results in multiple benchmarks. a lightweight bioner optimized model from traditional bert  lwner  is proposed in this study which can capture contextual information and its knowledge transfer from pre training on large scale text corpora without relying heavily on feature engineering and handcrafted rules. fine tuning bert on biomedical specific data helps adapt the model to the nuances and terminology of the biomedical domain. we conduct the method lwner on biocreative dataset bc2gm bc4chemd bc5cdr especially the chemical entity in bc5cdr achieve f1  score 91.3%. we construct an online web tool based on lwner to identify the arbitrary text from scientific literatures for building knowledge graph.", "Pub Date": "2024-01-23"}
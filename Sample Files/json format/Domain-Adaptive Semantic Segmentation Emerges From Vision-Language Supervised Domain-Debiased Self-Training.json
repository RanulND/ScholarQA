{"Title": "Domain-Adaptive Semantic Segmentation Emerges From Vision-Language Supervised Domain-Debiased Self-Training", "Doi": "10.1109/ICASSP48485.2024.10447308", "Authors": ["h. wang", "z. jiang", "l. xie", "d. jiang", "w. shen", "q. tian"], "Key Words": ["unsupervised domain adaptation", "semantic segmentation", "vision language models", "clip", "feature distillation"], "Abstract": "unsupervised domain adaptive semantic segmentation leverages synthetic data to train a segmentation model and transfers it to unlabeled real images. due to the style difference the transferred model suffers from the domain gap. even worse some classes exhibit the extreme domain gap where the feature distributions undergo a complete shift between the two domains. to alleviate it we propose a domain debiased self training strategy with clip to distill its domain agnostic knowledge. specifically we enforce the consistency between the feature maps from our segmentation model and the image encoder of clip. meanwhile the text embeddings from the text encoder for each class serve as a domain agnostic classifier to support a domain debiased feature learning condition. experimental results under standard uda settings demonstrate that our proposed strategy consistently improves the uda segmentation performance based on different backbones and with different large pre trained models.", "Pub Date": "2024-03-18"}
{"Title": "AI Computing in Large-Scale Era: Pre-trillion-scale Neural Network Models and Exa-scale Supercomputing", "Doi": "10.1109/VLSI-TSA/VLSI-DAT57221.2023.10134466", "Authors": ["b. -s. liang"], "Key Words": ["ai computing", "large-scale model", "large-scale language model", "exa-scale supercomputing", "foundation model"], "Abstract": "the development of ai computing has reached a critical inflection point. the scale of large scale ai neural network model parameters has grown rapidly to \u201a\u00e4\u00fapre trillion scale\u201a\u00e4\u00f9 level. the computing needs of training large scale ai neural network models have reached \u201a\u00e4\u00faexa scale\u201a\u00e4\u00f9 level. besides ai foundation model also affects the correctness of ai applications and becoming a new information security issue. future ai development will be pushed by progress of computing power  supercomputer  algorithm  neural network model and parameter scale  and application  foundation model and downstream fine tuning . in particular the computational efficiency of ai will be a key factor in the commercialization and popularization of ai applications.", "Pub Date": "2023-05-31"}
{"Title": "AI Computing in Large-Scale Era: Pre-trillion-scale Neural Network Models and Exa-scale Supercomputing", "Doi": "10.1109/VLSI-TSA/VLSI-DAT57221.2023.10134466", "Authors": ["b. -s. liang"], "Key Words": ["ai computing", "large-scale model", "large-scale language model", "exa-scale supercomputing", "foundation model"], "Abstract": "the development of artificial intelliegence computing has reached a critical inflection point. the scale of large scale artificial intelliegence neural network model parameters has grown rapidly to \u201a\u00e4\u00fapre trillion scale\u201a\u00e4\u00f9 level. the computing needs of training large scale artificial intelliegence neural network models have reached \u201a\u00e4\u00faexa scale\u201a\u00e4\u00f9 level. besides artificial intelliegence foundation model also affects the correctness of artificial intelliegence applications and becoming a new information security issue. future artificial intelliegence development will be pushed by progress of computing power  supercomputer  algorithm  neural network model and parameter scale  and application  foundation model and downstream fine tuning . in particular the computational efficiency of artificial intelliegence will be a key factor in the commercialization and popularization of artificial intelliegence applications.", "Pub Date": "2023-05-31"}
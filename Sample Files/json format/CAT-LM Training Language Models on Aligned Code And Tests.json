{"Title": "CAT-LM Training Language Models on Aligned Code And Tests", "Doi": "10.1109/ASE56229.2023.00193", "Authors": ["n. rao", "k. jain", "u. alon", "c. l. goues", "v. j. hellendoorn"], "Key Words": ["test generation", "test completion", "large language models", "code-test alignment"], "Abstract": "testing is an integral but often neglected part of the software development process. classical test generation tools such as evosuite generate behavioral test suites by optimizing for coverage but tend to produce tests that are hard to understand. language models trained on code can generate code that is highly similar to that written by humans but current models are trained to generate each file separately as is standard practice in natural language processing and thus fail to consider the code under test context when producing a test file. in this work we propose the aligned code and tests language model  cat lm  a gpt style language model with 2.7 billion parameters trained on a corpus of python and java projects. we utilize a novel pretraining signal that explicitly considers the mapping between code and test files when available. we also drastically increase the maximum sequence length of inputs to 8192 tokens 4x more than typical code generation models to ensure that the code context is available to the model when generating test code. we analyze its usefulness for realistic applications showing that sampling with filtering  e.g. by compilability coverage  allows it to efficiently produce tests that achieve coverage similar to ones written by developers while resembling their writing style. by utilizing the code context cat lm generates more valid tests than even much larger language models trained with more data  codegen 16b and starcoder  and substantially outperforms a recent test specific model  teco  at test completion. overall our work highlights the importance of incorporating software specific insights when training language models for code and paves the way to more powerful automated test generation.", "Pub Date": "2023-11-08"}
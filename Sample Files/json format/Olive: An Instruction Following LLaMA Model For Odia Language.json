{"Title": "Olive: An Instruction Following LLaMA Model For Odia Language", "Doi": "10.1109/SILCON59133.2023.10404195", "Authors": ["s. parida", "s. sekhar", "s. panda", "s. jena", "a. parida", "s. k. sahoo", "s. r. dash"], "Key Words": ["generative ai", "llm", "fine-tuning"], "Abstract": "the ai community is experiencing a profound impact from large language models  llms  and the introduction of chatgpt and gpt-4 is prompting a reconsideration of the potential of artificial general intelligence agi . however most of the llms are trained in english and other high resource languages resulting in the unavailability of llm and its related technologies and services for many low resource languages. in india where only 10% of the population is proficient in english the need for llm models adapted to regional languages becomes crucial.in this paper we emphasized the need for llm for the low resource odia language by evaluating the available llm supporting odia language. we describe the development process of the instruction tuning llm model for odia. the developed instruction tuning odia llm is available freely for research and non commercial purposes.", "Pub Date": "2024-01-30"}
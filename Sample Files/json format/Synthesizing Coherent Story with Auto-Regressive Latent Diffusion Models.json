{"Title": "Synthesizing Coherent Story with Auto-Regressive Latent Diffusion Models", "Doi": "10.1109/WACV57701.2024.00290", "Authors": ["x. pan", "p. qin", "y. li", "h. xue", "w. chen"], "Key Words": ["algorithms", "generative models for image", "video", "3d", "etc.", "algorithms", "vision + language and/or other modalities", "applications", "visualization"], "Abstract": "conditioned diffusion models have demonstrated state of the art text to image synthesis capacity. recently most works focus on synthesizing independent images  while for real world applications it is common and necessary to generate a series of coherent images for story stelling. in this work we mainly focus on story visualization and continuation tasks and propose ar ldm a latent diffusion model auto regressively conditioned on history captions and generated images. moreover ar ldm can generalize to new characters through adaptation. to our best knowledge this is the first work successfully leveraging diffusion models for coherent visual story synthesizing. it also extends the text conditioned method to multimodal conditioning. quantitative results show that ar ldm achieves sota fid scores on pororosv flintstonessv and the adopted challenging dataset vist containing natural images. large scale human evaluations show that ar ldm has superior performance in terms of quality relevance and consistency. code available at this https url", "Pub Date": "2024-04-09"}
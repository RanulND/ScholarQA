{"Title": "CiCo: Domain-Aware Sign Language Retrieval via Cross-Lingual Contrastive Learning", "Doi": "10.1109/CVPR52729.2023.01823", "Authors": ["y. cheng", "f. wei", "j. bao", "d. chen", "w. zhang"], "Key Words": ["vision applications and systems"], "Abstract": "this work focuses on sign language retrieval\u201a\u00e4\u00eea recently proposed task for sign language understanding. sign language retrieval consists of two sub tasks  text to sign video  t2v  retrieval and sign video to text  v2t  retrieval. different from traditional video text retrieval sign language videos not only contain visual signals but also carry abundant semantic meanings by themselves due to the fact that sign languages are also natural languages. considering this character we formulate sign language retrieval as a cross lingual retrieval problem as well as a video text retrieval task. concretely we take into account the linguistic properties of both sign languages and natural languages and simultaneously identify the fine grained cross lingual  i.e. sign to word  mappings while contrasting the texts and the sign videos in a joint embedding space. this process is termed as cross lingual contrastive learning. another challenge is raised by the data scarcity issue\u201a\u00e4\u00eesign language datasets are orders of magnitude smaller in scale than that of speech recognition. we alleviate this issue by adopting a domain agnostic sign encoder pre trained on large scale sign videos into the target domain via pseudo labeling. our framework termed as domain aware sign language retrieval via cross lingual contrastive learning or cico for short outperforms the pioneering method by large margins on various datasets e.g. +22.4 t2v and +28.0 v2t r@1 improvements on how2sign dataset and +13.7 t2v and +17.1 v2t r@1 improvements on phoenix 2014t dataset. code and models are available at  https //github.com fangyunwei/slrt.", "Pub Date": "2023-08-22"}
{"Title": "Zero-shot Prompting for Code Complexity Prediction Using GitHub Copilot", "Doi": "10.1109/NLBSE59153.2023.00018", "Authors": ["m. l. siddiq", "a. samee", "s. r. azgor", "m. a. haider", "s. i. sawraz", "j. c. s. santos"], "Key Words": ["code generation", "computational complexity", "trans-former", "zero-shot prompting", "pre-trained model", "github copilot"], "Abstract": "code generation models are gaining popularity because they can produce correct code from a prompt speeding up the software development process. github copilot is currently one of the most commonly used tools for code generation. this tool is based on gpt3 a large language model  large language model  and can perform zero shot prompting tasks i.e. tasks for which the model is not specifically trained. in this paper we describe a preliminary study that investigates whether github copilot can predict the runtime complexity of a given program using zero  shot prompting. in our study we found that github copilot can correctly predict the runtime complexity 45.44% times in the first suggestion and 56.38 % times considering all suggestions. we also compared copilot to other machine learning neural network and transformer based approaches for code complexity prediction. we observed that copilot outperformed other approaches for predicting code with linear complexity $\\mathbf{o} n $.", "Pub Date": "2023-07-26"}
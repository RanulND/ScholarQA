{"Title": "DFF: Distributed Forward-Forward Algorithm for Large-Scale Model in Low-Performance Devices", "Doi": "10.1109/PRAI59366.2023.10332073", "Authors": ["q. deng", "g. jin", "y. noh", "s. yu", "d. lee"], "Key Words": ["distributed ai model", "forward-forward algorithm", "ros2 publisher-subscriber", "mnist", "cifar10"], "Abstract": "the advancement of artificial intelligence artificial intelliegence  technology especially with the success of large language models large language model  like chatgpt and image generation models such as stable diffusion signifies that artificial intelliegence has entered a new era of large scale models. however the rapid development of artificial intelliegence models has brought about the disaster of unlimited growth in model size such as the latest large language model model pangu sigma which has reached an astonishing size of 1085b. for ordinary individuals the enormous hardware costs for these large scale models make it impossible to train and infer a large model. fortunately geoffrey everest hinton has proposed the forward forward ff  algorithm which aims to deconstruct a large model into smaller layers and each layer updates its weights through its own backpropagation process which means that each layer is independent. therefore inspired by geoffrey hinton\u201a\u00e4\u00f4s work this paper introduces a new distributed forward forward dff  algorithm which distributes each layer of the forward forward algorithm model to different devices based on ros2\u201a\u00e4\u00f4s publisher subscriber communication mechanism. then the model can be computed across different devices. the distributed forward forward dff  algorithm system in this paper theoretically allows multiple low performance devices to jointly run large models that a single device is hard to run. classification model tests on mnist and cifar10 datasets show that the accuracy is 0.9292 and 0.4249 respectively which has the comparable performance of the pure forward forward algorithm  0.9315 and 0.4310 . our implementation is available at [github].", "Pub Date": "2023-12-04"}
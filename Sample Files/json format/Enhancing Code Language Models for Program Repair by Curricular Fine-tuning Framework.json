{"Title": "Enhancing Code Language Models for Program Repair by Curricular Fine-tuning Framework", "Doi": "10.1109/ICSME58846.2023.00024", "Authors": ["s. hao", "x. shi", "h. liu", "y. shu"], "Key Words": ["program repair", "large language models of code", "curriculum learning"], "Abstract": "automated program repair  automated program repair  is a key technique for enhancing software maintenance productivity by fixing buggy code automatically. recently large code language models  clms  have exhibited impressive capabilities in code generation. however for complex programming tasks especially program repair the success rate of clms is still low. one of the reasons is that clms are typically developed for general purpose and their potential for automated program repair applications has yet to be fully explored. in this paper we propose aprfit a general curricular fine tuning framework that improves the success rate of clms for automated program repair. firstly aprfit generates syntactically diverse but semantically equivalent bug fixing programs via code augmentation operators to enrich the diversity of bug fixing dataset automatically. secondly aprfit designs a curriculum learning based mechanism to help clms develop deep understanding of program semantics from these augmented bug fixing code variants and improve the effectiveness of fine tuning for automated program repair tasks. we implement aprfit on different clms and evaluate them on bugs2fix small and medium datasets. the extensive experiments demonstrate that the existing clms implemented with aprfit substantially outperform original models and generate 2.5 to 14.5 percent more correct patches than baselines both effectively and efficiently.", "Pub Date": "2023-12-11"}
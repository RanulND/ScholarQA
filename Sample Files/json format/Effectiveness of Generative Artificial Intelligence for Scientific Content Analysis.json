{"Title": "Effectiveness of Generative Artificial Intelligence for Scientific Content Analysis", "Doi": "10.1109/AICT59525.2023.10313167", "Authors": ["m. platt", "d. platt"], "Key Words": ["ai-assisted research", "literature screening", "content analysis", "prompt engineering", "classification performance"], "Abstract": "generative artificial intelligence  genai  in general and large language models  llms  in particular are highly fashionable. as they have the ability to generate coherent output based on prompts in natural language they are promoted as tools to free knowledge workers from tedious tasks such as content writing customer support and routine computer code generation. unsurprisingly their application is also attractive to professionals in the research domain where mundane and laborious tasks such as literature screening are commonplace. we evaluate vertex ai \u201a\u00e4\u00f2text bison\u201a\u00e4\u00f4 a foundational llm model in a real world academic scenario by replicating parts of a popular systematic review in the information management domain. by comparing the results of a zero shot llm based approach with those of the original study we gather evidence on the suitability of state of the art general purpose llms for the analysis of scientific content. we show that the llm based approach delivers good scientific content analysis performance for a general classification problem  acc =0.9  acceptable performance for a domain specific classification problem  acc =0.8  and borderline performance for a text comprehension problem  acc \u201a\u00e2\u00e00.69 . we conclude that some content analysis tasks with moderate accuracy requirements may be supported by current llms. as the technology will evolve rapidly in the foreseeable future studies on large corpora where some inaccuracies are tolerable or workflows that prepare large data sets for human processing may increasingly benefit from the capabilities of genai.", "Pub Date": "2023-11-13"}
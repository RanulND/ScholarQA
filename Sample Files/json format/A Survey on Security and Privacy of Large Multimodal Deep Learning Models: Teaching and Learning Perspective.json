{"Title": "A Survey on Security and Privacy of Large Multimodal Deep Learning Models: Teaching and Learning Perspective", "Doi": "10.1109/LT60077.2024.10469434", "Authors": ["m. a. rahman", "l. alqahtani", "a. albooq", "a. ainousah"], "Key Words": ["large language model", "large multimodal model", "multimedia", "generative ai"], "Abstract": "the proliferation of large language models  llms  epitomized by systems like chatgpt has catalyzed a paradigm shift in educational technologies fostering a robust human ai synergy. as the frontier expands multimodal ai models have burgeoned facilitating human interaction through varied channels from text to imagery and audio visual educational content. this dynamism has not only enriched educational interfaces but also transformed content generation curation and summarization in pedagogy heralding an unparalleled era in education. however the ascent of llms and their multimodal counterparts large multimodal models  lmms  has not been without challenges. they are increasingly found susceptible to adversarial manipulations potentially undermining the educational process integrity. this paper delves deep into the security privacy compliance and trustworthiness of llms and lmms offering a comprehensive survey of their vulnerabilities. we elucidate the myriad adversarial tactics targeting llms and proffer contemporary mitigation strategies.", "Pub Date": "2024-03-21"}
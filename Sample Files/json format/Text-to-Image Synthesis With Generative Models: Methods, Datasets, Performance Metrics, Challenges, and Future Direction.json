{"Title": "Text-to-Image Synthesis With Generative Models: Methods, Datasets, Performance Metrics, Challenges, and Future Direction", "Doi": "10.1109/ACCESS.2024.3365043", "Authors": ["s. k. alhabeeb", "a. a. al-shargabi"], "Key Words": ["deep learning", "diffusion model", "generative models", "generative adversarial network", "text-to-image synthesis"], "Abstract": "text to image synthesis the process of turning words into images opens up a world of creative possibilities and meets the growing need for engaging visual experiences in a world that is becoming more image based. as machine learning capabilities expanded the area progressed from simple tools and systems to robust deep learning models that can automatically generate realistic images from textual inputs. modern large scale text to image generation models have made significant progress in this direction producing diversified and high quality images from text description prompts. although several methods exist generative adversarial networks  gans  have long held a position of prominence. however diffusion models have recently emerged with results much beyond those achieved by gans. this study offers a concise overview of text to image generative models by examining the existing body of literature and providing a deeper understanding of this topic. this will be accomplished by providing a concise summary of the development of text to image synthesis previous tools and systems employed in this field key types of generative models as well as an exploration of the relevant research conducted on gans and diffusion models. additionally the study provides an overview of common datasets utilized for training the text to image model compares the evaluation metrics used for evaluating the models and addresses the challenges encountered in the field. finally concluding remarks are provided to summarize the findings and implications of the study and open issues for further research.", "Pub Date": "2024-02-16"}
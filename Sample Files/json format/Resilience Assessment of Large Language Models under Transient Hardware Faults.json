{"Title": "Resilience Assessment of Large Language Models under Transient Hardware Faults", "Doi": "10.1109/ISSRE59848.2023.00052", "Authors": ["u. k. agarwal", "a. chan", "k. pattabiraman"], "Key Words": ["error resilience", "llms", "soft errors"], "Abstract": "large language models  large language model  are transforming the field of natural language processing and revolutionizing the way machines interact with humans. large language model like chatgpt and google\u201a\u00e4\u00f4s bard have already made significant strides in conversational artificial intelliegence enabling machines to understand natural language and respond in a more human like manner. in addition to typical applications like sentiment analysis and text generation large language model are also used in safety critical applications such as code generation and speech comprehension in autonomous driving vehicles where reliability is important.in this work we investigate the resilience of large language model under transient hardware faults. specifically we used ir level fault injection  fi  to assess the reliability of five popular large language model including bert gpt2 and t5 under transient hardware faults. moreover we also investigate how the resilience of large language model varies with different pre training fine tuning objectives and the number of encoder and decoder blocks. we find that large language model are quite resilient to transient faults overall. we also find that the behavior of the large language model under transient faults varies significantly with the input large language model\u201a\u00e4\u00f4s architecture and the type of task  e.g. translation vs. fill in the blank . finally we find that the silent data corruption  sdc  rate varies with different fine tuning objectives and for the fill mask fine tuning objective the sdc rate also increases with the model size. overall our findings indicate that the use of large language model in safety critical applications needs further investigation.", "Pub Date": "2023-11-02"}
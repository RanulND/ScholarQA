{"Title": "Resilience Assessment of Large Language Models under Transient Hardware Faults", "Doi": "10.1109/ISSRE59848.2023.00052", "Authors": ["u. k. agarwal", "a. chan", "k. pattabiraman"], "Key Words": ["error resilience", "llms", "soft errors"], "Abstract": "large language models  llms  are transforming the field of natural language processing and revolutionizing the way machines interact with humans. llms like chatgpt and google\u201a\u00e4\u00f4s bard have already made significant strides in conversational ai enabling machines to understand natural language and respond in a more human like manner. in addition to typical applications like sentiment analysis and text generation llms are also used in safety critical applications such as code generation and speech comprehension in autonomous driving vehicles where reliability is important.in this work we investigate the resilience of llms under transient hardware faults. specifically we used ir level fault injection  fi  to assess the reliability of five popular llms including bert gpt2 and t5 under transient hardware faults. moreover we also investigate how the resilience of llms varies with different pre training fine tuning objectives and the number of encoder and decoder blocks. we find that llms are quite resilient to transient faults overall. we also find that the behavior of the llm under transient faults varies significantly with the input llm\u201a\u00e4\u00f4s architecture and the type of task  e.g. translation vs. fill in the blank . finally we find that the silent data corruption  sdc  rate varies with different fine tuning objectives and for the fill mask fine tuning objective the sdc rate also increases with the model size. overall our findings indicate that the use of llms in safety critical applications needs further investigation.", "Pub Date": "2023-11-02"}
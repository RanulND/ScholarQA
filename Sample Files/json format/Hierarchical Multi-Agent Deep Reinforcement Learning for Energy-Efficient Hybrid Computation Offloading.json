{"Title": "Hierarchical Multi-Agent Deep Reinforcement Learning for Energy-Efficient Hybrid Computation Offloading", "Doi": "10.1109/TVT.2022.3202525", "Authors": ["h. zhou", "y. long", "s. gong", "k. zhu", "d. t. hoang", "d. niyato"], "Key Words": ["backscatter communications", "mobile edge computing", "multi-agent deep reinforcement learning"], "Abstract": "mobile edge computing  mec  provides an economical way for the resource constrained edge users to offload computational workload to mec servers co located with the access point  ap . in this article we consider a hybrid computation offloading scheme that allows edge users to offload workloads by using active rf communications and backscatter communications. we aim to maximize the overall energy efficiency subject to the completion of all workload by jointly optimizing the ap beamforming and the users' offloading decisions. considering a dynamic environment we propose a hierarchical multi agent deep reinforcement learning  h madrl  framework to solve this problem. the high level agent resides in the ap and optimizes the beamforming strategy while the low level user agents learn and adapt individuals' offloading strategies. to further improve the learning efficiency we propose a novel optimization driven learning algorithm that allows the ap to estimate the low level users' actions by solving approximate optimization problem efficiently. then the action estimation can be shared with all users and drive them to update individuals' actions independently. simulation results reveal that our algorithm can improve the system performance by 50%. the learning efficiency and reliability are also improved significantly comparing to the model free learning methods.", "Pub Date": "2023-01-13"}
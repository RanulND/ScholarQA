{"Title": "ZDDR: A Zero-Shot Defender for Adversarial Samples Detection and Restoration", "Doi": "10.1109/ACCESS.2024.3356568", "Authors": ["m. chen", "g. he", "j. wu"], "Key Words": ["adversarial defense", "large language model", "natural language processing", "model security", "prompt engineering"], "Abstract": "natural language processing  nlp  models find extensive applications but face vulnerabilities against adversarial inputs. traditional defenses lean heavily on supervised detection techniques which makes them vulnerable to issues arising from training data quality inherent biases noise or adversarial inputs. this study observed common compromises in sentence fluency during aggression. on this basis the zero sample defender  zddr  is introduced for adversarial sample detection and recovery without relying on prior knowledge. zddr combines the log probability calculated by the model and the syntactic normative score of a large language model  large language model  to detect adversarial examples. furthermore using strategic prompts zddr guides large language model in rephrasing adversarial content maintaining clarity structure and meaning thereby restoring the sentence from the attack. benchmarking reveals a 9% improvement in area under receiver operating characteristic curve  auroc  for adversarial detection over existing techniques. post restoration model classification efficacy surges by 45% compared to the offensive inputs setting new performance standards against other restoration techniques.", "Pub Date": "2024-03-18"}
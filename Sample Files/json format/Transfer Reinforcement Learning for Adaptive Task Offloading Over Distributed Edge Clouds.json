{"Title": "Transfer Reinforcement Learning for Adaptive Task Offloading Over Distributed Edge Clouds", "Doi": "10.1109/TCC.2022.3192560", "Authors": ["k. shuai", "y. miao", "k. hwang", "z. li"], "Key Words": ["artificial intelligence", "domain adaptation", "edge computing", "reinforcement learning", "and task offloading"], "Abstract": "in the big data era resource constrained mobile devices generate an overwhelmingly large amount of data with complex tasks that demand distributed execution. offloading computation intensive tasks to nearby edge clouds is promising to solve this problem. however mobile end devices cannot handle heterogeneous or delay sensitive tasks. these end devices are also energy constrained with weak adaptability to environment changes. to address and tackle these problems we present a two module transfer reinforcement learning  trl  framework for adaptive task offloading. a domain adaptation module is used to align heterogeneous characteristics of mobile devices. the trl makes offloading decisions with a deep reinforcement learning  drl  module. we evaluate the performance of trl through real world experiments on edge clouds. our experiment results show that trl reduces the task processing time by a factor of 20% from using three well known drl methods. our method achieved  15.4$\\sim$\u201a\u00e0\u00ba40 % reduction in task drop rate over these methods. with domain adaptation the trl results in  50$\\sim$\u201a\u00e0\u00ba80 % reduction in model convergence time. these advantages in using the trl framework make it appealing in real life edge computing applications.", "Pub Date": "2023-06-06"}
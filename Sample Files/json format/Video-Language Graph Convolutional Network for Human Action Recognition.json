{"Title": "Video-Language Graph Convolutional Network for Human Action Recognition", "Doi": "10.1109/ICASSP48485.2024.10445852", "Authors": ["r. zhang", "x. yan"], "Key Words": ["graph convolutional network", "human action recognition", "video-language learning"], "Abstract": "transferring visual language models  vlms  from the image domain to the video domain has recently yielded great success on human action recognition tasks. however standard recognition paradigms overlook fine grained action parsing knowledge that could enhance the recognition accuracy. in this paper we propose a novel method that leverages both coarse grained and fine grained knowledge to recognize human actions in videos. our method consists of a video language graph convolutional network that integrates and fuses multi modal knowledge in a progressive manner. we evaluate our method on the kinetics tps a large scale action parsing dataset and demonstrate that it outperforms the state of the art methods by a significant margin. moreover our method achieves better results with less training data and competitive computational cost than the existing methods showing the effectiveness and efficiency of using fine grained knowledge for human video action recognition.", "Pub Date": "2024-03-18"}
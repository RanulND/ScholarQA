{"Title": "Abstractive Text Summarization for Resumes With Cutting Edge NLP Transformers and LSTM", "Doi": "10.1109/ASYU58738.2023.10296563", "Authors": ["\u221a\u00f1. b. mercan", "s. n. cavsak", "a. deliahmetoglu", "s. tanberk"], "Key Words": ["abstractive text summarization", "pre-trained language models", "rouge"], "Abstract": "text summarization is a fundamental task in natural language processing that aims to condense large amounts of textual information into concise and coherent summaries. with the exponential growth of content and the need to extract key information efficiently text summarization has gained significant attention in recent years. in this study lstm and pre trained t5 pegasus bart and bart large model performances were evaluated on the open source dataset  xsum cnn daily mail amazon fine food review and news summary  and the prepared resume dataset. this resume dataset consists of many information such as language education experience personal information skills and this data includes 75 resumes. the primary objective of this research was to summarize resume text. various techniques such as lstm pre trained models and fine tuned models were assessed using a dataset of resumes. the bart large model fine tuned with the custom resume dataset gave the best performance.", "Pub Date": "2023-10-31"}
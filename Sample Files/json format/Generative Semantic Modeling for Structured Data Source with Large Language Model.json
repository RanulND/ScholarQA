{"Title": "Generative Semantic Modeling for Structured Data Source with Large Language Model", "Doi": "10.1109/HPCC-DSS-SmartCity-DependSys60770.2023.00164", "Authors": ["n. ding", "w. mayer", "y. geng", "y. duan", "z. feng"], "Key Words": ["knowledge graph", "large language model", "graph neural network"], "Abstract": "the paper introduces a generative semantic model for representing human knowledge in a way that enables computer understanding and reasoning. the current approach to semantic modeling involves mapping between the space of plausible semantic models and the provided data source. however this approach has limitations as the score functions used to search for the best candidate semantic model are either trained on a specific integration knowledge graph or rely on manually designed features. to address these limitations the authors propose a new approach that combines an encoder made with a pre trained large language model  llm  with a graph decoder customized to generate semantics. the encoder decoder system is designed to be trained on knowledge graphs and the authors introduce an algorithm to generate training samples from the big knowledge graph by decomposing training samples into construction actions using a method similar to the transition system of the syntax parser. the proposed method is novel as it is the first time a generative method has been applied to the semantic modeling task empowered with an llm and trained on knowledge graphs to achieve better performance on standard benchmarks than in past work. in conclusion the proposed generative semantic model offers a promising new approach to representing and organizing human knowledge in a more generalizable way using a combination of a pre trained llm and a customized graph decoder trained on knowledge graphs. the approach has shown improved performance on standard benchmarks and has the potential to advance the field of semantic modeling.", "Pub Date": "2024-03-25"}
{"Title": "M3sum: A Novel Unsupervised Language-Guided Video Summarization", "Doi": "10.1109/ICASSP48485.2024.10447504", "Authors": ["h. wang", "b. zhou", "z. zhang", "y. du", "d. ho", "k. -f. wong"], "Key Words": ["video summarization", "chatgpt"], "Abstract": "language guided video summarization empowers users to use natural language queries to effortlessly summarize lengthy videos into concise and relevant summaries that cater specifically to their information needs which is more friendly to access and digest. however most of the previous works rely on tremendous  also expensive  annotated videos and complex designs to align different modals at the feature level. in this paper we first explore the combination of off the shelf models for each modal to solve the complex multi modal problem by proposing a novel unsupervised language guided video summarization method  modular multi modal summarization  m3sum  which does not require any training data or parameter updates. specifically instead of training an alignment module at the feature level we convert all modal information  e.g. audio and frames  into textual descriptions and design a parameter free alignment mechanism to fuse text descriptions from different modals. benefiting from the remarkable long context understanding capability of large language models  large language model  our approach demonstrates comparable performance to most unsupervised methods and even outperforms certain supervised methods.", "Pub Date": "2024-03-18"}
{"Title": "SCALE: Semantic Code Analysis via Learned Embeddings", "Doi": "10.1109/ICoABCD59879.2023.10390981", "Authors": ["j. abohwo", "o. nimase", "p. zhou", "k. liu", "n. zhang", "d. almanza", "a. mehra", "m. lutz"], "Key Words": ["code-code alignment", "large language models", "natural language processing"], "Abstract": "existing pre trained models in nlp have demonstrated impressive success surpassing previous benchmarks in various language related tasks. however when it comes to the field of code understanding these models still face notable limitations. code isomorphism which deals with determining functional similarity between pieces of code presents a challenging problem for nlp models. in this paper we explore two approaches to code isomorphism. our first approach dubbed scale ft formulates the problem as a binary classification task where we feed pairs of code snippets to a large language model  large language model  using the embeddings to predict whether the given code segments are equivalent. the second approach scaleclr adopts the simclr framework to generate embeddings for individual code snippets. by processing code samples with an large language model and observing the corresponding embeddings we assess the similarity of two code snippets. these approaches enable us to leverage function based code embeddings for various downstream tasks such as code optimization code comment alignment and code classification. our experiments on the codenet python800 benchmark demonstrate promising results for both approaches. notably our scale ft using babbage001  gpt 3  achieves state of the art performance surpassing various benchmark models such as gpt 3.5 turbo and gpt 4. additionally salesforce\u201a\u00e4\u00f4s 350 million parameter codegen when trained with the scale ft framework surpasses gpt 3.5 and gpt 4.", "Pub Date": "2024-01-16"}
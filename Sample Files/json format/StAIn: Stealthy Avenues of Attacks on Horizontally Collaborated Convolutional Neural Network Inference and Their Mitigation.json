{"Title": "StAIn: Stealthy Avenues of Attacks on Horizontally Collaborated Convolutional Neural Network Inference and Their Mitigation", "Doi": "10.1109/ACCESS.2023.3241096", "Authors": ["a. a. adeyemo", "j. j. sanderson", "t. a. odetola", "f. khalid", "s. r. hasan"], "Key Words": ["horizontal collaboration", "convolutional neural network", "machine learning security", "adversarial machine learning", "deep learning", "edge intelligence"], "Abstract": "with significant potential improvement in device to device  d2d  communication due to improved wireless link capacity  e.g. 5g and nextg systems  a collaboration of multiple edge devices  called horizontal collaboration  hc   is becoming a reality for real time edge intelligence  ei . the distributed nature of hc offers an advantage against traditional adversarial attacks because the adversary does not have access to the entire deep learning architecture  dla . due to the involvement of multiple untrusted edge devices in hc environment the possibility of malicious devices cannot be eliminated. in this paper we unearth some attacks that are very effective and stealthy even when the attacker has minimal knowledge of the dla as is the case in hc based dla. we are also providing novel filtering methods to mitigate such attacks. our novel attacks leverage local information available on output feature maps  fms  of a targeted edge device to modify the regular adversarial attacks  e.g. fast gradient signed method  fgsm  and jacobian based saliency map attack  jsma  . similarly a customized convolutional neural network  cnn  based filter is empirically designed developed and tested. four different cnn models  lenet capsulenet minivggnet and vgg16  are used to validate the proposed attacks and defense methodologies. our three attacks on four different cnn models  with two variations of each attack  show a substantial accuracy drop of 62% on average. the proposed filtering approach is able to mitigate the attack by recovering the actual accuracy back to 75.1% on average. to the best of our knowledge this is the first work that investigates the security vulnerability of dla in the hc environment and all three of our attacks are scalable and agnostic to the partition location within the dla.", "Pub Date": "2023-02-06"}
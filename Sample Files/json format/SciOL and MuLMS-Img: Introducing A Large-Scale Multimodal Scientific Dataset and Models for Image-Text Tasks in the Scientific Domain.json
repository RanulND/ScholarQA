{"Title": "SciOL and MuLMS-Img: Introducing A Large-Scale Multimodal Scientific Dataset and Models for Image-Text Tasks in the Scientific Domain", "Doi": "10.1109/WACV57701.2024.00450", "Authors": ["t. tarsi", "h. adel", "j. h. metzen", "d. zhang", "m. finco", "a. friedrich"], "Key Words": ["algorithms", "datasets and evaluations", "algorithms", "vision + language and/or other modalities"], "Abstract": "in scientific publications a substantial part of the information is expressed via figures containing images and diagrams. hence the retrieval of relevant figures given a natural language query is an important real world task. however due to the lack of training and evaluation data most existing approaches are either limited to one modality or focus on non scientific domains making their application to scientific publications challenging.in this paper we address this gap by introducing two novel datasets   1  sciol the largest openly licensed pre training corpus for multimodal models in the scientific domain covering multiple sciences including materials science physics and computer science and  2  mulms img a high quality dataset in the materials science domain manually annotated for various image text tasks. our experiments show that pre training large scale vision language models on sciol increases performance considerably across a broad variety of image text tasks including figure type classification optical character recognition captioning and figure retrieval. using mulms img we show that integrating text based features extracted via a fine tuned model for a specific domain can boost cross modal scientific figure retrieval performance by up to 50%.", "Pub Date": "2024-04-09"}
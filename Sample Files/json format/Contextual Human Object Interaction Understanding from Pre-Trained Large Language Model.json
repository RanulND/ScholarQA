{"Title": "Contextual Human Object Interaction Understanding from Pre-Trained Large Language Model", "Doi": "10.1109/ICASSP48485.2024.10447511", "Authors": ["j. gao", "k. -h. yap", "k. wu", "d. t. phan", "k. garg", "b. s. han"], "Key Words": ["human object interaction", "zero-shot learning", "vision-language model", "context learning", "interaction reasoning"], "Abstract": "existing human object interaction  hoi  detection methods have introduced zero shot learning techniques to recognize unseen interactions but they still have limitations in understanding context information and comprehensive reasoning. to overcome these limitations we propose a novel hoi learning framework contexthoi which serves as an effective contextual hoi detector to enhance contextual understanding and zero shot reasoning ability. the main contributions of the proposed contexthoi are a novel context mining decoder and a powerful interaction reasoning large language model  large language model . the context mining decoder aims to extract linguistic contextual information from a pre trained vision language model. based on the extracted context information the proposed interaction reasoning large language model further enhances the zero shot reasoning ability by leveraging rich linguistic knowledge. extensive evaluation demonstrates that our proposed framework outperforms existing zero shot methods on the hico det and swig hoi datasets as high as 19.34% map on unseen interaction can be achieved.", "Pub Date": "2024-03-18"}
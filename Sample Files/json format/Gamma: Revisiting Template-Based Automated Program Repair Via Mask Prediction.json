{"Title": "Gamma: Revisiting Template-Based Automated Program Repair Via Mask Prediction", "Doi": "10.1109/ASE56229.2023.00063", "Authors": ["q. zhang", "c. fang", "t. zhang", "b. yu", "w. sun", "z. chen"], "Key Words": ["automated program repair", "fix pattern", "pretrained model", "llm4se"], "Abstract": "automated program repair  automated program repair  aims to fix software bugs without manual debugging efforts and plays a crucial role in software development and maintenance. template based automated program repair has been widely investigated and shown promising results. however it is challenging for template based automated program repair to select the appropriate donor code which is an important repair ingredient for generating candidate patches. inappropriate donor code may cause plausible but incorrect patch generation even with correct fix patterns limiting the repair performance. in this paper we aim to revisit template based automated program repair and propose gamma to directly leverage large pre trained language models for donor code generation. our main insight is that instead of retrieving donor code in the local buggy file we can directly predict the correct code tokens based on the context code snippets and repair patterns by a cloze task. specifically  1  gamma revises a variety of fix templates from state of the art template based automated program repair techniques  i.e. tbar  and transforms them into mask patterns.  2  gamma adopts a pre trained language model to predict the correct code for masked code as a fill in the blank task. although our idea is general and can be built on various existing pre trained language models we have implemented gamma as a practical automated program repair tool based on the recent unixcoder model. the experimental results demonstrate that gamma correctly repairs 82 bugs on defects4j v1.2 which achieves 20.59%  14 bugs  and 26.15%  17 bugs  improvement over the previous state of the art template based approach tbar and learning based one recoder. furthermore gamma repairs 45 bugs and 22 bugs from the additional defects4j v2.0 and quixbugs indicating the generalizability of gamma in addressing the dataset overfitting issue. we also prove that adopting other pre trained language models can provide substantial advancement e.g. codebert based and chatgpt based gamma is able to fix 80 and 67 bugs on defects4j v1.2 indicating the scalability of gamma. overall our study highlights the promising future of adopting pre trained models to generate correct patches on top of fix patterns in practice.", "Pub Date": "2023-11-08"}
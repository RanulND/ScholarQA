{"Title": "Multitask Learning in Audio Captioning: A Sentence Embedding Regression Loss Acts as a Regularizer", "Doi": "10.23919/EUSIPCO58844.2023.10290108", "Authors": ["e. labb\u221a\u00a9", "j. pinquier", "t. pellegrini"], "Key Words": ["sound event description", "multitask learning", "audio language task", "overfitting", "sentence embedding regression loss", "semantic loss"], "Abstract": "in this work we propose to study the performance of a model trained with a sentence embedding regression loss component for the automated audio captioning task. this task aims to build systems that can describe audio content with a single sentence written in natural language. most systems are trained with the standard cross entropy loss which does not take into account the semantic closeness of the sentence. we found that adding a sentence embedding loss term reduces overfitting but also increased spider from 0.397 to 0.418 in our first setting on the audiocaps corpus. when we increased the weight decay value we found our model to be much closer to the current state of the art scores with a spider score up to 0.444 compared to a 0.475 score. moreover this model uses eight times less trainable parameters than the current state of the art method multi tta. in this training setting the sentence embedding loss has no more impact on the model performance.", "Pub Date": "2023-11-01"}
{"Title": "GraphLearner: An Approach to Sequence Recognition and Generation", "Doi": "10.1109/BigComp60711.2024.00098", "Authors": ["t. g. harrison", "t. b\u221a\u2202hme", "m. kubek", "h. unger"], "Key Words": ["natural language processing", "long term short term memory", "transformers", "markov models", "bloom filters", "neuromorphic ai"], "Abstract": "this paper presents graphlearner a neuromorphic sequence generator with similarities to markov chain models. graphlearner is proposed as an alternative to \u201a\u00e4\u00f2black box\u201a\u00e4\u00f4 deep neural network models which lack explainability and adaptability. bloom filters are used to simplify otherwise computationally expensive markov chain probability calculations. it is demonstrated with natural language processing tasks generating sentences of remarkable quality.", "Pub Date": "2024-04-11"}
{"Title": "LSFL: A Lightweight and Secure Federated Learning Scheme for Edge Computing", "Doi": "10.1109/TIFS.2022.3221899", "Authors": ["z. zhang", "l. wu", "c. ma", "j. li", "j. wang", "q. wang", "s. yu"], "Key Words": ["federated learning", "edge computing", "privacy-preserving", "byzantine-robustness", "data privacy"], "Abstract": "nowadays many edge computing service providers expect to leverage the computational power and data of edge nodes to improve their models without transmitting data. federated learning facilitates collaborative training of global models among distributed edge nodes without sharing their training data. unfortunately existing privacy preserving federated learning applied to this scenario still faces three challenges  1  it typically employs complex cryptographic algorithms which results in excessive training overhead  2  it cannot guarantee byzantine robustness while preserving data privacy  and 3  edge nodes have limited computing power and may drop out frequently. as a result the privacy preserving federated learning cannot be effectively applied to edge computing scenarios. therefore we propose a lightweight and secure federated learning scheme lsfl which combines the features of privacy preserving and byzantine robustness. specifically we design the lightweight two server secure aggregation protocol which utilizes two servers to enable secure byzantine robustness and model aggregation. this scheme protects data privacy and prevents byzantine nodes from influencing model aggregation. we implement and evaluate lsfl in a lan environment and the experiment results show that lsfl meets fidelity security and efficiency design goals and maintains model accuracy compared to the popular fedavg scheme.", "Pub Date": "2022-12-07"}
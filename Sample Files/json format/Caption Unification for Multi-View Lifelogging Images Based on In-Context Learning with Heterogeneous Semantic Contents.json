{"Title": "Caption Unification for Multi-View Lifelogging Images Based on In-Context Learning with Heterogeneous Semantic Contents", "Doi": "10.1109/ICASSP48485.2024.10445969", "Authors": ["m. sato", "k. maeda", "r. togo", "t. ogawa", "m. haseyama"], "Key Words": ["lifelogging data", "image captioning models", "caption unification", "in-context learning"], "Abstract": "this paper presents a new task of caption unification and a novel caption unification method for multi view lifelogging images based on in context learning with heterogeneous semantic contents. most of the existing image captioning models target a single image and do not consider the common semantic contents among multiple images. therefore they suffer from inconsistent captioning for multi view lifelogging images taken in the same scene i.e. the images that have common semantic contents regardless of the viewpoints. the proposed method enables training the common semantic contents of multiple images and generating captions that comprehensively contain the semantic contents of the images based on in context learning. the proposed method has the following two contributions. first we identify the problem of existing image captioning models and consider caption unification as a new task for multi view lifelogging images. second we generate unified captions based on in context learning with heterogeneous semantic contents and evaluate the captions from two perspectives uniformity and retainability. the experimental results demonstrate that the proposed method realizes successful caption unification.", "Pub Date": "2024-03-18"}
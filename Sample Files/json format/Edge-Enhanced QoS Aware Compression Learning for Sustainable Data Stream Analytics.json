{"Title": "Edge-Enhanced QoS Aware Compression Learning for Sustainable Data Stream Analytics", "Doi": "10.1109/TSUSC.2023.3252039", "Authors": ["m. u. amaizu", "m. k. ali", "a. anjum", "l. liu", "a. liotta", "o. rana"], "Key Words": ["cloud computing", "data compression", "deep autoencoders", "edge computing", "real-time analytics", "quality of service", "transmission optimisation"], "Abstract": "existing cloud systems involve large volumes of data streams being sent to a centralised data centre for monitoring storage and analytics. however migrating all the data to the cloud is often not feasible due to cost privacy and performance concerns. however machine learning  ml  algorithms typically require significant computational resources hence cannot be directly deployed on resource constrained edge devices for learning and analytics. edge enhanced compressive offloading becomes a sustainable solution that allows data to be compressed at the edge and offloaded to the cloud for further analysis reducing bandwidth consumption and communication latency. the design and implementation of a learning method for discovering compression techniques that offer the best qos for an application is described. the approach uses a novel modularisation approach that maps features to models and classifies them for a range of quality of service  qos  features. an automated qos aware orchestrator has been designed to select the best autoencoder model in real time for compressive offloading in edge enhanced clouds based on changing qos requirements. the orchestrator has been designed to have diagnostic capabilities to search appropriate parameters that give the best compression. a key novelty of this work is harnessing the capabilities of autoencoders for edge enhanced compressive offloading based on portable encodings latent space splitting and fine tuning network weights. considering how the combination of features lead to different qos models the system is capable of processing a large number of user requests in a given time. the proposed hyperparameter search strategy  over the neural architectural space  reduces the computational cost of search through the entire space by up to 89%. when deployed on an edge enhanced cloud using an azure iot testbed the approach saves up to 70% data transfer costs and takes 32% less time for job completion. it eliminates the additional computational cost of decompression thereby reducing the processing cost by up to 30%.", "Pub Date": "2023-09-08"}
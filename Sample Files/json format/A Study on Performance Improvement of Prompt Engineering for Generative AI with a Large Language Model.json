{"Title": "A Study on Performance Improvement of Prompt Engineering for Generative AI with a Large Language Model", "Doi": "10.13052/jwe1540-9589.2285", "Authors": ["d. park", "g. -t. an", "c. kamyod", "c. g. kim"], "Key Words": ["ai", "large language model", "generative ai", "few-shot learning", "prompt engineering", "ai chatbot"], "Abstract": "in the realm of generative ai where various models are introduced prompt engineering emerges as a significant technique within natural language processing based generative ai. its primary function lies in effectively enhancing the results of sentence generation by large language models  llms . notably prompt engineering has gained attention as a method capable of improving llm performance by modifying the structure of input prompts alone. in this study we apply prompt engineering to korean based llms presenting an efficient approach for generating specific conversational responses with less data. we achieve this through the utilization of the query transformation module  qtm . our proposed qtm transforms input prompt sentences into three distinct query methods breaking them down into objectives and key points making them more comprehensible for llms. for performance validation we employ korean versions of llms specifically skt gpt-2 and kakaobrain kogpt 3. we compare four different query methods including the original unmodified query using google ssa to assess the naturalness and specificity of generated sentences. the results demonstrate an average improvement of 11.46% when compared to the unmodified query underscoring the efficacy of the proposed qtm in achieving enhanced performance.", "Pub Date": "2024-02-27"}
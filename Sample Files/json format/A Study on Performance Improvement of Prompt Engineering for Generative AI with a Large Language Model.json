{"Title": "A Study on Performance Improvement of Prompt Engineering for Generative AI with a Large Language Model", "Doi": "10.13052/jwe1540-9589.2285", "Authors": ["d. park", "g. -t. an", "c. kamyod", "c. g. kim"], "Key Words": ["ai", "large language model", "generative ai", "few-shot learning", "prompt engineering", "ai chatbot"], "Abstract": "in the realm of generative artificial intelliegence where various models are introduced prompt engineering emerges as a significant technique within natural language processing based generative artificial intelliegence. its primary function lies in effectively enhancing the results of sentence generation by large language models  large language model . notably prompt engineering has gained attention as a method capable of improving large language model performance by modifying the structure of input prompts alone. in this study we apply prompt engineering to korean based large language model presenting an efficient approach for generating specific conversational responses with less data. we achieve this through the utilization of the query transformation module  qtm . our proposed qtm transforms input prompt sentences into three distinct query methods breaking them down into objectives and key points making them more comprehensible for large language model. for performance validation we employ korean versions of large language model specifically skt gpt-2 and kakaobrain kogpt 3. we compare four different query methods including the original unmodified query using google ssa to assess the naturalness and specificity of generated sentences. the results demonstrate an average improvement of 11.46% when compared to the unmodified query underscoring the efficacy of the proposed qtm in achieving enhanced performance.", "Pub Date": "2024-02-27"}